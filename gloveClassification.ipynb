{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from flair.data_fetcher import NLPTaskDataFetcher\n",
    "from flair.embeddings import WordEmbeddings, FlairEmbeddings, DocumentLSTMEmbeddings, BertEmbeddings\n",
    "from flair.models import TextClassifier\n",
    "from flair.trainers import ModelTrainer\n",
    "from pathlib import Path\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "ps = nltk.PorterStemmer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>ham</td>\n",
       "      <td>You busy or can I come by at some point and fi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5315</td>\n",
       "      <td>ham</td>\n",
       "      <td>Hahaha..use your brain dear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1236</td>\n",
       "      <td>ham</td>\n",
       "      <td>How much are we getting?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>951</td>\n",
       "      <td>ham</td>\n",
       "      <td>Shb b ok lor... Thanx...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1085</td>\n",
       "      <td>ham</td>\n",
       "      <td>FR'NDSHIP is like a needle of a clock. Though ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     label                                               text\n",
       "1100   ham  You busy or can I come by at some point and fi...\n",
       "5315   ham                        Hahaha..use your brain dear\n",
       "1236   ham                           How much are we getting?\n",
       "951    ham                           Shb b ok lor... Thanx...\n",
       "1085   ham  FR'NDSHIP is like a needle of a clock. Though ..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"./spam.csv\", encoding='latin-1').sample(frac=1).drop_duplicates()\n",
    "data = data[['v1', 'v2']].rename(columns={\"v1\":\"label\", \"v2\":\"text\"})\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning\n",
    "#### Remove the Punctuations, stopwords, Lemmatize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>cleaned_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>ham</td>\n",
       "      <td>You busy or can I come by at some point and fi...</td>\n",
       "      <td>busi come point figur tomorrow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5315</td>\n",
       "      <td>ham</td>\n",
       "      <td>Hahaha..use your brain dear</td>\n",
       "      <td>hahahaus brain dear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1236</td>\n",
       "      <td>ham</td>\n",
       "      <td>How much are we getting?</td>\n",
       "      <td>much get</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>951</td>\n",
       "      <td>ham</td>\n",
       "      <td>Shb b ok lor... Thanx...</td>\n",
       "      <td>shb b ok lor thanx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1085</td>\n",
       "      <td>ham</td>\n",
       "      <td>FR'NDSHIP is like a needle of a clock. Though ...</td>\n",
       "      <td>frndship like needl clock though v r clock v r...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     label                                               text  \\\n",
       "1100   ham  You busy or can I come by at some point and fi...   \n",
       "5315   ham                        Hahaha..use your brain dear   \n",
       "1236   ham                           How much are we getting?   \n",
       "951    ham                           Shb b ok lor... Thanx...   \n",
       "1085   ham  FR'NDSHIP is like a needle of a clock. Though ...   \n",
       "\n",
       "                                           cleaned_text  \n",
       "1100                     busi come point figur tomorrow  \n",
       "5315                                hahahaus brain dear  \n",
       "1236                                           much get  \n",
       "951                                  shb b ok lor thanx  \n",
       "1085  frndship like needl clock though v r clock v r...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def clean_text(text):\n",
    "    text = \"\".join([word.lower() for word in text if word not in string.punctuation])\n",
    "    tokens = re.split('\\W+', text)\n",
    "    text = \" \".join([ps.stem(word) for word in tokens if word not in stopwords])\n",
    "    return text\n",
    "\n",
    "data['cleaned_text'] = data['text'].apply(lambda x: clean_text(x))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>cleaned_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>ham</td>\n",
       "      <td>busi come point figur tomorrow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5315</td>\n",
       "      <td>ham</td>\n",
       "      <td>hahahaus brain dear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1236</td>\n",
       "      <td>ham</td>\n",
       "      <td>much get</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>951</td>\n",
       "      <td>ham</td>\n",
       "      <td>shb b ok lor thanx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1085</td>\n",
       "      <td>ham</td>\n",
       "      <td>frndship like needl clock though v r clock v r...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     label                                       cleaned_text\n",
       "1100   ham                     busi come point figur tomorrow\n",
       "5315   ham                                hahahaus brain dear\n",
       "1236   ham                                           much get\n",
       "951    ham                                 shb b ok lor thanx\n",
       "1085   ham  frndship like needl clock though v r clock v r..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=data.drop([\"text\"],axis=1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test and Train Dataset Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['label'] = '__label__' + data['label'].astype(str)\n",
    "data.iloc[0:int(len(data)*0.8)].to_csv('train.csv', sep='\\t', index = False, header = False)\n",
    "data.iloc[int(len(data)*0.8):int(len(data)*0.9)].to_csv('test.csv', sep='\\t', index = False, header = False)\n",
    "data.iloc[int(len(data)*0.9):].to_csv('dev.csv', sep='\\t', index = False, header = False);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use Glove Embeddings and Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated function (or staticmethod) load_classification_corpus. (Use 'flair.datasets' instead.) -- Deprecated since version 0.4.1.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-02-05 12:11:34,496 Reading data from .\n",
      "2020-02-05 12:11:34,497 Train: train.csv\n",
      "2020-02-05 12:11:34,498 Dev: dev.csv\n",
      "2020-02-05 12:11:34,499 Test: test.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\flair\\data_fetcher.py:447: DeprecationWarning: Call to deprecated function (or staticmethod) read_text_classification_file. (Use 'flair.datasets' instead.) -- Deprecated since version 0.4.1.\n",
      "  max_tokens_per_doc=max_tokens_per_doc,\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\flair\\data_fetcher.py:454: DeprecationWarning: Call to deprecated function (or staticmethod) read_text_classification_file. (Use 'flair.datasets' instead.) -- Deprecated since version 0.4.1.\n",
      "  max_tokens_per_doc=max_tokens_per_doc,\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\flair\\data_fetcher.py:463: DeprecationWarning: Call to deprecated function (or staticmethod) read_text_classification_file. (Use 'flair.datasets' instead.) -- Deprecated since version 0.4.1.\n",
      "  max_tokens_per_doc=max_tokens_per_doc,\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: DeprecationWarning: Call to deprecated class DocumentLSTMEmbeddings. (The functionality of this class is moved to 'DocumentRNNEmbeddings') -- Deprecated since version 0.4.\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-02-05 12:11:40,781 Computing label dictionary. Progress:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 4130/4130 [00:00<00:00, 344198.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-02-05 12:11:40,807 [b'ham', b'spam']\n",
      "2020-02-05 12:11:40,811 ----------------------------------------------------------------------------------------------------\n",
      "2020-02-05 12:11:40,813 Model: \"TextClassifier(\n",
      "  (document_embeddings): DocumentLSTMEmbeddings(\n",
      "    (embeddings): StackedEmbeddings(\n",
      "      (list_embedding_0): WordEmbeddings('glove')\n",
      "      (list_embedding_1): FlairEmbeddings(\n",
      "        (lm): LanguageModel(\n",
      "          (drop): Dropout(p=0.25)\n",
      "          (encoder): Embedding(275, 100)\n",
      "          (rnn): LSTM(100, 1024)\n",
      "          (decoder): Linear(in_features=1024, out_features=275, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (list_embedding_2): FlairEmbeddings(\n",
      "        (lm): LanguageModel(\n",
      "          (drop): Dropout(p=0.25)\n",
      "          (encoder): Embedding(275, 100)\n",
      "          (rnn): LSTM(100, 1024)\n",
      "          (decoder): Linear(in_features=1024, out_features=275, bias=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (word_reprojection_map): Linear(in_features=2148, out_features=256, bias=True)\n",
      "    (rnn): GRU(256, 512)\n",
      "    (dropout): Dropout(p=0.5)\n",
      "  )\n",
      "  (decoder): Linear(in_features=512, out_features=2, bias=True)\n",
      "  (loss_function): CrossEntropyLoss()\n",
      ")\"\n",
      "2020-02-05 12:11:40,814 ----------------------------------------------------------------------------------------------------\n",
      "2020-02-05 12:11:40,815 Corpus: \"Corpus: 4130 train + 517 dev + 517 test sentences\"\n",
      "2020-02-05 12:11:40,816 ----------------------------------------------------------------------------------------------------\n",
      "2020-02-05 12:11:40,817 Parameters:\n",
      "2020-02-05 12:11:40,818  - learning_rate: \"0.1\"\n",
      "2020-02-05 12:11:40,819  - mini_batch_size: \"32\"\n",
      "2020-02-05 12:11:40,820  - patience: \"3\"\n",
      "2020-02-05 12:11:40,821  - anneal_factor: \"0.5\"\n",
      "2020-02-05 12:11:40,822  - max_epochs: \"100\"\n",
      "2020-02-05 12:11:40,823  - shuffle: \"True\"\n",
      "2020-02-05 12:11:40,824  - train_with_dev: \"False\"\n",
      "2020-02-05 12:11:40,825 ----------------------------------------------------------------------------------------------------\n",
      "2020-02-05 12:11:40,826 Model training base path: \".\"\n",
      "2020-02-05 12:11:40,827 ----------------------------------------------------------------------------------------------------\n",
      "2020-02-05 12:11:40,827 Device: cuda:0\n",
      "2020-02-05 12:11:40,828 ----------------------------------------------------------------------------------------------------\n",
      "2020-02-05 12:11:40,830 Embeddings storage mode: cpu\n",
      "2020-02-05 12:11:40,832 ----------------------------------------------------------------------------------------------------\n",
      "2020-02-05 12:11:40,984 epoch 1 - iter 0/130 - loss 0.70441234 - samples/sec: 2773.39\n",
      "2020-02-05 12:11:43,178 epoch 1 - iter 13/130 - loss 0.35722363 - samples/sec: 223.78\n",
      "2020-02-05 12:11:47,825 epoch 1 - iter 26/130 - loss 0.29542972 - samples/sec: 201.46\n",
      "2020-02-05 12:11:49,886 epoch 1 - iter 39/130 - loss 0.24758872 - samples/sec: 212.90\n",
      "2020-02-05 12:11:51,999 epoch 1 - iter 52/130 - loss 0.21935796 - samples/sec: 206.87\n",
      "2020-02-05 12:11:54,360 epoch 1 - iter 65/130 - loss 0.20138778 - samples/sec: 187.73\n",
      "2020-02-05 12:11:56,420 epoch 1 - iter 78/130 - loss 0.18957511 - samples/sec: 212.25\n",
      "2020-02-05 12:11:58,524 epoch 1 - iter 91/130 - loss 0.18280801 - samples/sec: 207.70\n",
      "2020-02-05 12:12:00,657 epoch 1 - iter 104/130 - loss 0.17214105 - samples/sec: 204.83\n",
      "2020-02-05 12:12:02,791 epoch 1 - iter 117/130 - loss 0.16050480 - samples/sec: 204.63\n",
      "2020-02-05 12:12:04,615 ----------------------------------------------------------------------------------------------------\n",
      "2020-02-05 12:12:04,616 EPOCH 1 done: loss 0.1515 - lr 0.1000\n",
      "2020-02-05 12:12:06,733 DEV : loss 0.04725637286901474 - score 0.9865\n",
      "2020-02-05 12:12:06,754 BAD EPOCHS (no improvement): 0\n",
      "2020-02-05 12:12:10,847 ----------------------------------------------------------------------------------------------------\n",
      "2020-02-05 12:12:10,912 epoch 2 - iter 0/130 - loss 0.00430072 - samples/sec: 6603.48\n",
      "2020-02-05 12:12:11,895 epoch 2 - iter 13/130 - loss 0.07738790 - samples/sec: 470.08\n",
      "2020-02-05 12:12:12,947 epoch 2 - iter 26/130 - loss 0.07074546 - samples/sec: 435.62\n",
      "2020-02-05 12:12:14,015 epoch 2 - iter 39/130 - loss 0.09488513 - samples/sec: 428.00\n",
      "2020-02-05 12:12:16,246 epoch 2 - iter 52/130 - loss 0.09847839 - samples/sec: 527.94\n",
      "2020-02-05 12:12:17,181 epoch 2 - iter 65/130 - loss 0.10264866 - samples/sec: 502.43\n",
      "2020-02-05 12:12:18,332 epoch 2 - iter 78/130 - loss 0.09943996 - samples/sec: 395.45\n",
      "2020-02-05 12:12:19,311 epoch 2 - iter 91/130 - loss 0.09393782 - samples/sec: 477.63\n",
      "2020-02-05 12:12:20,393 epoch 2 - iter 104/130 - loss 0.09062122 - samples/sec: 426.68\n",
      "2020-02-05 12:12:21,331 epoch 2 - iter 117/130 - loss 0.08594044 - samples/sec: 500.02\n",
      "2020-02-05 12:12:22,151 ----------------------------------------------------------------------------------------------------\n",
      "2020-02-05 12:12:22,153 EPOCH 2 done: loss 0.0848 - lr 0.1000\n",
      "2020-02-05 12:12:23,003 DEV : loss 0.03785226121544838 - score 0.9884\n",
      "2020-02-05 12:12:23,023 BAD EPOCHS (no improvement): 0\n",
      "2020-02-05 12:12:29,656 ----------------------------------------------------------------------------------------------------\n",
      "2020-02-05 12:12:29,710 epoch 3 - iter 0/130 - loss 0.01414243 - samples/sec: 8000.14\n",
      "2020-02-05 12:12:30,523 epoch 3 - iter 13/130 - loss 0.08399157 - samples/sec: 580.22\n",
      "2020-02-05 12:12:31,402 epoch 3 - iter 26/130 - loss 0.08303397 - samples/sec: 531.31\n",
      "2020-02-05 12:12:32,212 epoch 3 - iter 39/130 - loss 0.07339267 - samples/sec: 583.47\n",
      "2020-02-05 12:12:33,121 epoch 3 - iter 52/130 - loss 0.06922450 - samples/sec: 512.33\n",
      "2020-02-05 12:12:33,970 epoch 3 - iter 65/130 - loss 0.06584784 - samples/sec: 560.67\n",
      "2020-02-05 12:12:34,890 epoch 3 - iter 78/130 - loss 0.07128426 - samples/sec: 503.65\n",
      "2020-02-05 12:12:35,784 epoch 3 - iter 91/130 - loss 0.07071765 - samples/sec: 526.60\n",
      "2020-02-05 12:12:36,678 epoch 3 - iter 104/130 - loss 0.07535295 - samples/sec: 520.02\n",
      "2020-02-05 12:12:37,794 epoch 3 - iter 117/130 - loss 0.07534464 - samples/sec: 495.26\n",
      "2020-02-05 12:12:38,564 ----------------------------------------------------------------------------------------------------\n",
      "2020-02-05 12:12:38,566 EPOCH 3 done: loss 0.0754 - lr 0.1000\n",
      "2020-02-05 12:12:39,319 DEV : loss 0.04255327954888344 - score 0.9826\n",
      "2020-02-05 12:12:39,338 BAD EPOCHS (no improvement): 1\n",
      "2020-02-05 12:12:39,340 ----------------------------------------------------------------------------------------------------\n",
      "2020-02-05 12:12:39,388 epoch 4 - iter 0/130 - loss 0.02857477 - samples/sec: 8851.66\n",
      "2020-02-05 12:12:40,268 epoch 4 - iter 13/130 - loss 0.07115362 - samples/sec: 531.31\n",
      "2020-02-05 12:12:41,176 epoch 4 - iter 26/130 - loss 0.07519251 - samples/sec: 534.72\n",
      "2020-02-05 12:12:42,060 epoch 4 - iter 39/130 - loss 0.08192987 - samples/sec: 529.28\n",
      "2020-02-05 12:12:43,020 epoch 4 - iter 52/130 - loss 0.07232067 - samples/sec: 483.74\n",
      "2020-02-05 12:12:44,002 epoch 4 - iter 65/130 - loss 0.06613324 - samples/sec: 483.18\n",
      "2020-02-05 12:12:45,177 epoch 4 - iter 78/130 - loss 0.06236014 - samples/sec: 387.35\n",
      "2020-02-05 12:12:46,124 epoch 4 - iter 91/130 - loss 0.06736694 - samples/sec: 490.58\n",
      "2020-02-05 12:12:46,999 epoch 4 - iter 104/130 - loss 0.06313038 - samples/sec: 535.41\n",
      "2020-02-05 12:12:47,996 epoch 4 - iter 117/130 - loss 0.06814300 - samples/sec: 464.30\n",
      "2020-02-05 12:12:48,818 ----------------------------------------------------------------------------------------------------\n",
      "2020-02-05 12:12:48,820 EPOCH 4 done: loss 0.0704 - lr 0.1000\n",
      "2020-02-05 12:12:49,643 DEV : loss 0.040959905833005905 - score 0.9845\n",
      "2020-02-05 12:12:49,664 BAD EPOCHS (no improvement): 2\n",
      "2020-02-05 12:12:49,666 ----------------------------------------------------------------------------------------------------\n",
      "2020-02-05 12:12:49,725 epoch 5 - iter 0/130 - loss 0.08538155 - samples/sec: 7172.79\n",
      "2020-02-05 12:12:50,683 epoch 5 - iter 13/130 - loss 0.05151341 - samples/sec: 484.87\n",
      "2020-02-05 12:12:51,679 epoch 5 - iter 26/130 - loss 0.05814348 - samples/sec: 464.30\n",
      "2020-02-05 12:12:52,606 epoch 5 - iter 39/130 - loss 0.05898358 - samples/sec: 502.43\n",
      "2020-02-05 12:12:53,519 epoch 5 - iter 52/130 - loss 0.06485941 - samples/sec: 527.27\n",
      "2020-02-05 12:12:54,438 epoch 5 - iter 65/130 - loss 0.07394494 - samples/sec: 507.96\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-02-05 12:12:55,340 epoch 5 - iter 78/130 - loss 0.07078366 - samples/sec: 520.02\n",
      "2020-02-05 12:12:56,384 epoch 5 - iter 91/130 - loss 0.07353638 - samples/sec: 458.67\n",
      "2020-02-05 12:12:57,284 epoch 5 - iter 104/130 - loss 0.06773369 - samples/sec: 520.02\n",
      "2020-02-05 12:12:58,197 epoch 5 - iter 117/130 - loss 0.06554612 - samples/sec: 518.08\n",
      "2020-02-05 12:12:59,003 ----------------------------------------------------------------------------------------------------\n",
      "2020-02-05 12:12:59,004 EPOCH 5 done: loss 0.0638 - lr 0.1000\n",
      "2020-02-05 12:12:59,828 DEV : loss 0.03729836270213127 - score 0.9865\n",
      "2020-02-05 12:12:59,848 BAD EPOCHS (no improvement): 3\n",
      "2020-02-05 12:12:59,849 ----------------------------------------------------------------------------------------------------\n",
      "2020-02-05 12:12:59,917 epoch 6 - iter 0/130 - loss 0.00584695 - samples/sec: 6303.49\n",
      "2020-02-05 12:13:00,866 epoch 6 - iter 13/130 - loss 0.06112595 - samples/sec: 495.26\n",
      "2020-02-05 12:13:01,914 epoch 6 - iter 26/130 - loss 0.05486189 - samples/sec: 439.76\n",
      "2020-02-05 12:13:02,909 epoch 6 - iter 39/130 - loss 0.06601833 - samples/sec: 464.82\n",
      "2020-02-05 12:13:03,753 epoch 6 - iter 52/130 - loss 0.05952331 - samples/sec: 562.18\n",
      "2020-02-05 12:13:04,667 epoch 6 - iter 65/130 - loss 0.06204026 - samples/sec: 513.60\n",
      "2020-02-05 12:13:05,557 epoch 6 - iter 78/130 - loss 0.06552453 - samples/sec: 531.99\n",
      "2020-02-05 12:13:06,432 epoch 6 - iter 91/130 - loss 0.06574649 - samples/sec: 536.10\n",
      "2020-02-05 12:13:07,473 epoch 6 - iter 104/130 - loss 0.06420774 - samples/sec: 442.11\n",
      "2020-02-05 12:13:08,340 epoch 6 - iter 117/130 - loss 0.06162393 - samples/sec: 541.69\n",
      "2020-02-05 12:13:09,159 ----------------------------------------------------------------------------------------------------\n",
      "2020-02-05 12:13:09,161 EPOCH 6 done: loss 0.0591 - lr 0.1000\n",
      "2020-02-05 12:13:09,968 DEV : loss 0.03811544552445412 - score 0.9845\n",
      "Epoch     5: reducing learning rate of group 0 to 5.0000e-02.\n",
      "2020-02-05 12:13:09,990 BAD EPOCHS (no improvement): 4\n",
      "2020-02-05 12:13:09,992 ----------------------------------------------------------------------------------------------------\n",
      "2020-02-05 12:13:10,050 epoch 7 - iter 0/130 - loss 0.01830505 - samples/sec: 7298.65\n",
      "2020-02-05 12:13:10,955 epoch 7 - iter 13/130 - loss 0.04197812 - samples/sec: 516.79\n",
      "2020-02-05 12:13:11,948 epoch 7 - iter 26/130 - loss 0.04938825 - samples/sec: 491.16\n",
      "2020-02-05 12:13:12,986 epoch 7 - iter 39/130 - loss 0.04555786 - samples/sec: 443.51\n",
      "2020-02-05 12:13:13,943 epoch 7 - iter 52/130 - loss 0.05266264 - samples/sec: 486.00\n",
      "2020-02-05 12:13:14,913 epoch 7 - iter 65/130 - loss 0.04649703 - samples/sec: 477.08\n",
      "2020-02-05 12:13:15,907 epoch 7 - iter 78/130 - loss 0.04598814 - samples/sec: 463.79\n",
      "2020-02-05 12:13:16,779 epoch 7 - iter 91/130 - loss 0.05270939 - samples/sec: 543.81\n",
      "2020-02-05 12:13:17,635 epoch 7 - iter 104/130 - loss 0.05100792 - samples/sec: 549.56\n",
      "2020-02-05 12:13:18,497 epoch 7 - iter 117/130 - loss 0.05160184 - samples/sec: 544.52\n",
      "2020-02-05 12:13:19,317 ----------------------------------------------------------------------------------------------------\n",
      "2020-02-05 12:13:19,318 EPOCH 7 done: loss 0.0493 - lr 0.0500\n",
      "2020-02-05 12:13:20,139 DEV : loss 0.03515477105975151 - score 0.9865\n",
      "2020-02-05 12:13:20,159 BAD EPOCHS (no improvement): 1\n",
      "2020-02-05 12:13:20,161 ----------------------------------------------------------------------------------------------------\n",
      "2020-02-05 12:13:20,223 epoch 8 - iter 0/130 - loss 0.01725903 - samples/sec: 6819.79\n",
      "2020-02-05 12:13:21,147 epoch 8 - iter 13/130 - loss 0.05683053 - samples/sec: 504.26\n",
      "2020-02-05 12:13:22,315 epoch 8 - iter 26/130 - loss 0.06046263 - samples/sec: 389.16\n",
      "2020-02-05 12:13:23,226 epoch 8 - iter 39/130 - loss 0.05610640 - samples/sec: 514.23\n",
      "2020-02-05 12:13:24,244 epoch 8 - iter 52/130 - loss 0.05698804 - samples/sec: 450.72\n",
      "2020-02-05 12:13:25,140 epoch 8 - iter 65/130 - loss 0.05087170 - samples/sec: 523.95\n",
      "2020-02-05 12:13:26,098 epoch 8 - iter 78/130 - loss 0.04827396 - samples/sec: 484.30\n",
      "2020-02-05 12:13:27,082 epoch 8 - iter 91/130 - loss 0.05001151 - samples/sec: 473.82\n",
      "2020-02-05 12:13:28,020 epoch 8 - iter 104/130 - loss 0.04918636 - samples/sec: 496.44\n",
      "2020-02-05 12:13:28,889 epoch 8 - iter 117/130 - loss 0.04840287 - samples/sec: 543.81\n",
      "2020-02-05 12:13:29,681 ----------------------------------------------------------------------------------------------------\n",
      "2020-02-05 12:13:29,682 EPOCH 8 done: loss 0.0487 - lr 0.0500\n",
      "2020-02-05 12:13:30,496 DEV : loss 0.04250277951359749 - score 0.9865\n",
      "2020-02-05 12:13:30,516 BAD EPOCHS (no improvement): 2\n",
      "2020-02-05 12:13:30,518 ----------------------------------------------------------------------------------------------------\n",
      "2020-02-05 12:13:30,576 epoch 9 - iter 0/130 - loss 0.01252595 - samples/sec: 7428.92\n",
      "2020-02-05 12:13:31,463 epoch 9 - iter 13/130 - loss 0.02963999 - samples/sec: 527.94\n",
      "2020-02-05 12:13:32,424 epoch 9 - iter 26/130 - loss 0.04588618 - samples/sec: 483.74\n",
      "2020-02-05 12:13:33,419 epoch 9 - iter 39/130 - loss 0.04371450 - samples/sec: 464.30\n",
      "2020-02-05 12:13:34,366 epoch 9 - iter 52/130 - loss 0.04994222 - samples/sec: 490.01\n",
      "2020-02-05 12:13:35,245 epoch 9 - iter 65/130 - loss 0.04665968 - samples/sec: 562.18\n",
      "2020-02-05 12:13:36,212 epoch 9 - iter 78/130 - loss 0.04343040 - samples/sec: 479.28\n",
      "2020-02-05 12:13:37,095 epoch 9 - iter 91/130 - loss 0.04582268 - samples/sec: 529.93\n",
      "2020-02-05 12:13:38,041 epoch 9 - iter 104/130 - loss 0.04587168 - samples/sec: 518.72\n",
      "2020-02-05 12:13:38,998 epoch 9 - iter 117/130 - loss 0.04383432 - samples/sec: 485.43\n",
      "2020-02-05 12:13:39,856 ----------------------------------------------------------------------------------------------------\n",
      "2020-02-05 12:13:39,857 EPOCH 9 done: loss 0.0471 - lr 0.0500\n",
      "2020-02-05 12:13:40,691 DEV : loss 0.03516753762960434 - score 0.9865\n",
      "2020-02-05 12:13:40,710 BAD EPOCHS (no improvement): 3\n",
      "2020-02-05 12:13:40,712 ----------------------------------------------------------------------------------------------------\n",
      "2020-02-05 12:13:40,765 epoch 10 - iter 0/130 - loss 0.02077643 - samples/sec: 8157.57\n",
      "2020-02-05 12:13:41,701 epoch 10 - iter 13/130 - loss 0.01349416 - samples/sec: 495.85\n",
      "2020-02-05 12:13:42,530 epoch 10 - iter 26/130 - loss 0.02881286 - samples/sec: 570.67\n",
      "2020-02-05 12:13:43,526 epoch 10 - iter 39/130 - loss 0.03568055 - samples/sec: 462.24\n",
      "2020-02-05 12:13:44,408 epoch 10 - iter 52/130 - loss 0.03383186 - samples/sec: 531.31\n",
      "2020-02-05 12:13:45,363 epoch 10 - iter 65/130 - loss 0.03818206 - samples/sec: 487.71\n",
      "2020-02-05 12:13:46,384 epoch 10 - iter 78/130 - loss 0.03809622 - samples/sec: 466.39\n",
      "2020-02-05 12:13:47,295 epoch 10 - iter 91/130 - loss 0.03869470 - samples/sec: 510.45\n",
      "2020-02-05 12:13:48,203 epoch 10 - iter 104/130 - loss 0.03893261 - samples/sec: 512.97\n",
      "2020-02-05 12:13:49,445 epoch 10 - iter 117/130 - loss 0.04225749 - samples/sec: 363.33\n",
      "2020-02-05 12:13:50,237 ----------------------------------------------------------------------------------------------------\n",
      "2020-02-05 12:13:50,239 EPOCH 10 done: loss 0.0435 - lr 0.0500\n",
      "2020-02-05 12:13:51,048 DEV : loss 0.040322039276361465 - score 0.9845\n",
      "Epoch     9: reducing learning rate of group 0 to 2.5000e-02.\n",
      "2020-02-05 12:13:51,071 BAD EPOCHS (no improvement): 4\n",
      "2020-02-05 12:13:51,073 ----------------------------------------------------------------------------------------------------\n",
      "2020-02-05 12:13:51,141 epoch 11 - iter 0/130 - loss 0.10098494 - samples/sec: 6303.51\n",
      "2020-02-05 12:13:52,030 epoch 11 - iter 13/130 - loss 0.03026121 - samples/sec: 525.27\n",
      "2020-02-05 12:13:53,004 epoch 11 - iter 26/130 - loss 0.03320093 - samples/sec: 475.44\n",
      "2020-02-05 12:13:53,949 epoch 11 - iter 39/130 - loss 0.03701030 - samples/sec: 493.49\n",
      "2020-02-05 12:13:54,902 epoch 11 - iter 52/130 - loss 0.03446725 - samples/sec: 489.43\n",
      "2020-02-05 12:13:55,878 epoch 11 - iter 65/130 - loss 0.03961534 - samples/sec: 486.00\n",
      "2020-02-05 12:13:56,737 epoch 11 - iter 78/130 - loss 0.04111506 - samples/sec: 545.24\n",
      "2020-02-05 12:13:57,635 epoch 11 - iter 91/130 - loss 0.03791846 - samples/sec: 520.02\n",
      "2020-02-05 12:13:58,631 epoch 11 - iter 104/130 - loss 0.03888271 - samples/sec: 481.50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-02-05 12:13:59,592 epoch 11 - iter 117/130 - loss 0.03831725 - samples/sec: 482.62\n",
      "2020-02-05 12:14:00,330 ----------------------------------------------------------------------------------------------------\n",
      "2020-02-05 12:14:00,331 EPOCH 11 done: loss 0.0401 - lr 0.0250\n",
      "2020-02-05 12:14:01,140 DEV : loss 0.038682375103235245 - score 0.9845\n",
      "2020-02-05 12:14:01,159 BAD EPOCHS (no improvement): 1\n",
      "2020-02-05 12:14:01,161 ----------------------------------------------------------------------------------------------------\n",
      "2020-02-05 12:14:01,211 epoch 12 - iter 0/130 - loss 0.01665125 - samples/sec: 8667.25\n",
      "2020-02-05 12:14:02,158 epoch 12 - iter 13/130 - loss 0.03941630 - samples/sec: 488.86\n",
      "2020-02-05 12:14:03,063 epoch 12 - iter 26/130 - loss 0.05276949 - samples/sec: 516.79\n",
      "2020-02-05 12:14:04,096 epoch 12 - iter 39/130 - loss 0.04524029 - samples/sec: 459.69\n",
      "2020-02-05 12:14:04,962 epoch 12 - iter 52/130 - loss 0.03841266 - samples/sec: 543.81\n",
      "2020-02-05 12:14:05,875 epoch 12 - iter 65/130 - loss 0.03783899 - samples/sec: 512.34\n",
      "2020-02-05 12:14:06,851 epoch 12 - iter 78/130 - loss 0.03633013 - samples/sec: 491.74\n",
      "2020-02-05 12:14:08,019 epoch 12 - iter 91/130 - loss 0.03300882 - samples/sec: 388.08\n",
      "2020-02-05 12:14:08,951 epoch 12 - iter 104/130 - loss 0.03371461 - samples/sec: 499.42\n",
      "2020-02-05 12:14:09,880 epoch 12 - iter 117/130 - loss 0.03576887 - samples/sec: 501.22\n",
      "2020-02-05 12:14:10,634 ----------------------------------------------------------------------------------------------------\n",
      "2020-02-05 12:14:10,635 EPOCH 12 done: loss 0.0372 - lr 0.0250\n",
      "2020-02-05 12:14:11,447 DEV : loss 0.036402761936187744 - score 0.9865\n",
      "2020-02-05 12:14:11,467 BAD EPOCHS (no improvement): 2\n",
      "2020-02-05 12:14:11,468 ----------------------------------------------------------------------------------------------------\n",
      "2020-02-05 12:14:11,534 epoch 13 - iter 0/130 - loss 0.03077605 - samples/sec: 6500.37\n",
      "2020-02-05 12:14:12,484 epoch 13 - iter 13/130 - loss 0.04445138 - samples/sec: 487.71\n",
      "2020-02-05 12:14:13,388 epoch 13 - iter 26/130 - loss 0.04816148 - samples/sec: 517.43\n",
      "2020-02-05 12:14:14,560 epoch 13 - iter 39/130 - loss 0.04461919 - samples/sec: 387.35\n",
      "2020-02-05 12:14:15,428 epoch 13 - iter 52/130 - loss 0.04349442 - samples/sec: 542.39\n",
      "2020-02-05 12:14:16,422 epoch 13 - iter 65/130 - loss 0.04126051 - samples/sec: 479.83\n",
      "2020-02-05 12:14:17,365 epoch 13 - iter 78/130 - loss 0.03939044 - samples/sec: 493.49\n",
      "2020-02-05 12:14:18,202 epoch 13 - iter 91/130 - loss 0.03892697 - samples/sec: 563.71\n",
      "2020-02-05 12:14:19,097 epoch 13 - iter 104/130 - loss 0.03944211 - samples/sec: 534.72\n",
      "2020-02-05 12:14:19,993 epoch 13 - iter 117/130 - loss 0.03752367 - samples/sec: 522.63\n",
      "2020-02-05 12:14:20,767 ----------------------------------------------------------------------------------------------------\n",
      "2020-02-05 12:14:20,768 EPOCH 13 done: loss 0.0366 - lr 0.0250\n",
      "2020-02-05 12:14:21,581 DEV : loss 0.03692431002855301 - score 0.9865\n",
      "2020-02-05 12:14:21,601 BAD EPOCHS (no improvement): 3\n",
      "2020-02-05 12:14:21,603 ----------------------------------------------------------------------------------------------------\n",
      "2020-02-05 12:14:21,659 epoch 14 - iter 0/130 - loss 0.00553139 - samples/sec: 7704.13\n",
      "2020-02-05 12:14:22,610 epoch 14 - iter 13/130 - loss 0.03290019 - samples/sec: 491.16\n",
      "2020-02-05 12:14:23,911 epoch 14 - iter 26/130 - loss 0.02734438 - samples/sec: 347.26\n",
      "2020-02-05 12:14:24,907 epoch 14 - iter 39/130 - loss 0.02967152 - samples/sec: 464.30\n",
      "2020-02-05 12:14:25,842 epoch 14 - iter 52/130 - loss 0.02584171 - samples/sec: 499.42\n",
      "2020-02-05 12:14:26,732 epoch 14 - iter 65/130 - loss 0.02699344 - samples/sec: 526.60\n",
      "2020-02-05 12:14:27,590 epoch 14 - iter 78/130 - loss 0.03193020 - samples/sec: 548.11\n",
      "2020-02-05 12:14:28,558 epoch 14 - iter 91/130 - loss 0.03239995 - samples/sec: 480.39\n",
      "2020-02-05 12:14:29,521 epoch 14 - iter 104/130 - loss 0.03494798 - samples/sec: 482.62\n",
      "2020-02-05 12:14:30,476 epoch 14 - iter 117/130 - loss 0.03592782 - samples/sec: 487.14\n",
      "2020-02-05 12:14:31,276 ----------------------------------------------------------------------------------------------------\n",
      "2020-02-05 12:14:31,277 EPOCH 14 done: loss 0.0357 - lr 0.0250\n",
      "2020-02-05 12:14:32,098 DEV : loss 0.04011701047420502 - score 0.9826\n",
      "Epoch    13: reducing learning rate of group 0 to 1.2500e-02.\n",
      "2020-02-05 12:14:32,120 BAD EPOCHS (no improvement): 4\n",
      "2020-02-05 12:14:32,122 ----------------------------------------------------------------------------------------------------\n",
      "2020-02-05 12:14:32,192 epoch 15 - iter 0/130 - loss 0.01157196 - samples/sec: 6118.11\n",
      "2020-02-05 12:14:33,174 epoch 15 - iter 13/130 - loss 0.03969217 - samples/sec: 471.67\n",
      "2020-02-05 12:14:34,053 epoch 15 - iter 26/130 - loss 0.03595332 - samples/sec: 535.41\n",
      "2020-02-05 12:14:35,069 epoch 15 - iter 39/130 - loss 0.03834857 - samples/sec: 453.67\n",
      "2020-02-05 12:14:35,907 epoch 15 - iter 52/130 - loss 0.03473400 - samples/sec: 563.71\n",
      "2020-02-05 12:14:36,781 epoch 15 - iter 65/130 - loss 0.03473938 - samples/sec: 536.10\n",
      "2020-02-05 12:14:37,777 epoch 15 - iter 78/130 - loss 0.03237510 - samples/sec: 463.78\n",
      "2020-02-05 12:14:38,744 epoch 15 - iter 91/130 - loss 0.03172587 - samples/sec: 492.33\n",
      "2020-02-05 12:14:39,656 epoch 15 - iter 104/130 - loss 0.03398927 - samples/sec: 511.71\n",
      "2020-02-05 12:14:40,524 epoch 15 - iter 117/130 - loss 0.03438802 - samples/sec: 543.10\n",
      "2020-02-05 12:14:41,463 ----------------------------------------------------------------------------------------------------\n",
      "2020-02-05 12:14:41,464 EPOCH 15 done: loss 0.0335 - lr 0.0125\n",
      "2020-02-05 12:14:42,272 DEV : loss 0.04032047092914581 - score 0.9807\n",
      "2020-02-05 12:14:42,292 BAD EPOCHS (no improvement): 1\n",
      "2020-02-05 12:14:42,294 ----------------------------------------------------------------------------------------------------\n",
      "2020-02-05 12:14:42,352 epoch 16 - iter 0/130 - loss 0.01254297 - samples/sec: 7298.50\n",
      "2020-02-05 12:14:43,347 epoch 16 - iter 13/130 - loss 0.02596611 - samples/sec: 464.30\n",
      "2020-02-05 12:14:44,215 epoch 16 - iter 26/130 - loss 0.02850712 - samples/sec: 542.39\n",
      "2020-02-05 12:14:45,098 epoch 16 - iter 39/130 - loss 0.03366837 - samples/sec: 531.31\n",
      "2020-02-05 12:14:45,995 epoch 16 - iter 52/130 - loss 0.03584392 - samples/sec: 521.98\n",
      "2020-02-05 12:14:46,910 epoch 16 - iter 65/130 - loss 0.03615523 - samples/sec: 521.98\n",
      "2020-02-05 12:14:47,875 epoch 16 - iter 78/130 - loss 0.03530591 - samples/sec: 480.39\n",
      "2020-02-05 12:14:48,875 epoch 16 - iter 91/130 - loss 0.03450057 - samples/sec: 461.73\n",
      "2020-02-05 12:14:49,879 epoch 16 - iter 104/130 - loss 0.03355258 - samples/sec: 459.69\n",
      "2020-02-05 12:14:50,785 epoch 16 - iter 117/130 - loss 0.03572265 - samples/sec: 516.15\n",
      "2020-02-05 12:14:51,973 ----------------------------------------------------------------------------------------------------\n",
      "2020-02-05 12:14:51,974 EPOCH 16 done: loss 0.0342 - lr 0.0125\n",
      "2020-02-05 12:14:52,787 DEV : loss 0.039912570267915726 - score 0.9807\n",
      "2020-02-05 12:14:52,807 BAD EPOCHS (no improvement): 2\n",
      "2020-02-05 12:14:52,810 ----------------------------------------------------------------------------------------------------\n",
      "2020-02-05 12:14:52,876 epoch 17 - iter 0/130 - loss 0.22393191 - samples/sec: 6400.35\n",
      "2020-02-05 12:14:53,898 epoch 17 - iter 13/130 - loss 0.02977042 - samples/sec: 451.21\n",
      "2020-02-05 12:14:54,869 epoch 17 - iter 26/130 - loss 0.02386352 - samples/sec: 477.08\n",
      "2020-02-05 12:14:55,776 epoch 17 - iter 39/130 - loss 0.03044439 - samples/sec: 514.87\n",
      "2020-02-05 12:14:56,619 epoch 17 - iter 52/130 - loss 0.03238731 - samples/sec: 559.91\n",
      "2020-02-05 12:14:57,476 epoch 17 - iter 65/130 - loss 0.03371026 - samples/sec: 549.56\n",
      "2020-02-05 12:14:58,350 epoch 17 - iter 78/130 - loss 0.03152859 - samples/sec: 536.80\n",
      "2020-02-05 12:14:59,382 epoch 17 - iter 91/130 - loss 0.03209855 - samples/sec: 446.37\n",
      "2020-02-05 12:15:00,308 epoch 17 - iter 104/130 - loss 0.03345736 - samples/sec: 504.26\n",
      "2020-02-05 12:15:01,295 epoch 17 - iter 117/130 - loss 0.03387255 - samples/sec: 469.01\n",
      "2020-02-05 12:15:02,132 ----------------------------------------------------------------------------------------------------\n",
      "2020-02-05 12:15:02,133 EPOCH 17 done: loss 0.0324 - lr 0.0125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-02-05 12:15:02,945 DEV : loss 0.045219484716653824 - score 0.9845\n",
      "2020-02-05 12:15:02,965 BAD EPOCHS (no improvement): 3\n",
      "2020-02-05 12:15:02,967 ----------------------------------------------------------------------------------------------------\n",
      "2020-02-05 12:15:03,023 epoch 18 - iter 0/130 - loss 0.01824516 - samples/sec: 7704.16\n",
      "2020-02-05 12:15:03,965 epoch 18 - iter 13/130 - loss 0.02105071 - samples/sec: 501.83\n",
      "2020-02-05 12:15:04,800 epoch 18 - iter 26/130 - loss 0.02830622 - samples/sec: 566.78\n",
      "2020-02-05 12:15:05,806 epoch 18 - iter 39/130 - loss 0.02507509 - samples/sec: 459.18\n",
      "2020-02-05 12:15:06,807 epoch 18 - iter 52/130 - loss 0.02393810 - samples/sec: 461.73\n",
      "2020-02-05 12:15:07,703 epoch 18 - iter 65/130 - loss 0.02902818 - samples/sec: 523.29\n",
      "2020-02-05 12:15:08,575 epoch 18 - iter 78/130 - loss 0.02703849 - samples/sec: 538.88\n",
      "2020-02-05 12:15:09,476 epoch 18 - iter 91/130 - loss 0.03068408 - samples/sec: 520.67\n",
      "2020-02-05 12:15:10,387 epoch 18 - iter 104/130 - loss 0.02940826 - samples/sec: 513.60\n",
      "2020-02-05 12:15:11,280 epoch 18 - iter 117/130 - loss 0.02890462 - samples/sec: 525.27\n",
      "2020-02-05 12:15:12,180 ----------------------------------------------------------------------------------------------------\n",
      "2020-02-05 12:15:12,181 EPOCH 18 done: loss 0.0343 - lr 0.0125\n",
      "2020-02-05 12:15:13,319 DEV : loss 0.03880710154771805 - score 0.9865\n",
      "Epoch    17: reducing learning rate of group 0 to 6.2500e-03.\n",
      "2020-02-05 12:15:13,341 BAD EPOCHS (no improvement): 4\n",
      "2020-02-05 12:15:13,343 ----------------------------------------------------------------------------------------------------\n",
      "2020-02-05 12:15:13,404 epoch 19 - iter 0/130 - loss 0.09221341 - samples/sec: 6933.81\n",
      "2020-02-05 12:15:14,324 epoch 19 - iter 13/130 - loss 0.04969099 - samples/sec: 508.58\n",
      "2020-02-05 12:15:15,233 epoch 19 - iter 26/130 - loss 0.04061122 - samples/sec: 515.51\n",
      "2020-02-05 12:15:16,171 epoch 19 - iter 39/130 - loss 0.03628816 - samples/sec: 497.03\n",
      "2020-02-05 12:15:17,139 epoch 19 - iter 52/130 - loss 0.03517772 - samples/sec: 498.82\n",
      "2020-02-05 12:15:18,038 epoch 19 - iter 65/130 - loss 0.03307118 - samples/sec: 522.63\n",
      "2020-02-05 12:15:18,983 epoch 19 - iter 78/130 - loss 0.03287535 - samples/sec: 491.75\n",
      "2020-02-05 12:15:19,983 epoch 19 - iter 91/130 - loss 0.03134455 - samples/sec: 473.28\n",
      "2020-02-05 12:15:20,887 epoch 19 - iter 104/130 - loss 0.02889649 - samples/sec: 523.29\n",
      "2020-02-05 12:15:21,834 epoch 19 - iter 117/130 - loss 0.03408716 - samples/sec: 491.16\n",
      "2020-02-05 12:15:22,632 ----------------------------------------------------------------------------------------------------\n",
      "2020-02-05 12:15:22,633 EPOCH 19 done: loss 0.0330 - lr 0.0063\n",
      "2020-02-05 12:15:23,464 DEV : loss 0.04424068704247475 - score 0.9826\n",
      "2020-02-05 12:15:23,484 BAD EPOCHS (no improvement): 1\n",
      "2020-02-05 12:15:23,487 ----------------------------------------------------------------------------------------------------\n",
      "2020-02-05 12:15:23,550 epoch 20 - iter 0/130 - loss 0.06000844 - samples/sec: 6709.98\n",
      "2020-02-05 12:15:24,591 epoch 20 - iter 13/130 - loss 0.03957625 - samples/sec: 441.63\n",
      "2020-02-05 12:15:25,517 epoch 20 - iter 26/130 - loss 0.03180156 - samples/sec: 504.26\n",
      "2020-02-05 12:15:26,515 epoch 20 - iter 39/130 - loss 0.03055334 - samples/sec: 470.08\n",
      "2020-02-05 12:15:27,442 epoch 20 - iter 52/130 - loss 0.03293383 - samples/sec: 503.65\n",
      "2020-02-05 12:15:28,361 epoch 20 - iter 65/130 - loss 0.03124496 - samples/sec: 506.10\n",
      "2020-02-05 12:15:29,287 epoch 20 - iter 78/130 - loss 0.02774632 - samples/sec: 503.04\n",
      "2020-02-05 12:15:30,190 epoch 20 - iter 91/130 - loss 0.02586132 - samples/sec: 516.79\n",
      "2020-02-05 12:15:31,070 epoch 20 - iter 104/130 - loss 0.03049943 - samples/sec: 533.36\n",
      "2020-02-05 12:15:32,025 epoch 20 - iter 117/130 - loss 0.03044733 - samples/sec: 485.43\n",
      "2020-02-05 12:15:32,838 ----------------------------------------------------------------------------------------------------\n",
      "2020-02-05 12:15:32,839 EPOCH 20 done: loss 0.0322 - lr 0.0063\n",
      "2020-02-05 12:15:33,666 DEV : loss 0.049331746995449066 - score 0.9865\n",
      "2020-02-05 12:15:33,686 BAD EPOCHS (no improvement): 2\n",
      "2020-02-05 12:15:33,688 ----------------------------------------------------------------------------------------------------\n",
      "2020-02-05 12:15:33,750 epoch 21 - iter 0/130 - loss 0.01411499 - samples/sec: 6819.87\n",
      "2020-02-05 12:15:34,673 epoch 21 - iter 13/130 - loss 0.02738045 - samples/sec: 505.49\n",
      "2020-02-05 12:15:35,519 epoch 21 - iter 26/130 - loss 0.02038092 - samples/sec: 556.92\n",
      "2020-02-05 12:15:36,480 epoch 21 - iter 39/130 - loss 0.02142473 - samples/sec: 482.06\n",
      "2020-02-05 12:15:37,400 epoch 21 - iter 52/130 - loss 0.02694040 - samples/sec: 511.08\n",
      "2020-02-05 12:15:38,346 epoch 21 - iter 65/130 - loss 0.02560359 - samples/sec: 490.59\n",
      "2020-02-05 12:15:39,964 epoch 21 - iter 78/130 - loss 0.02358724 - samples/sec: 279.02\n",
      "2020-02-05 12:15:40,974 epoch 21 - iter 91/130 - loss 0.02715477 - samples/sec: 457.16\n",
      "2020-02-05 12:15:41,825 epoch 21 - iter 104/130 - loss 0.03116417 - samples/sec: 553.74\n",
      "2020-02-05 12:15:42,752 epoch 21 - iter 117/130 - loss 0.03122788 - samples/sec: 503.04\n",
      "2020-02-05 12:15:43,591 ----------------------------------------------------------------------------------------------------\n",
      "2020-02-05 12:15:43,592 EPOCH 21 done: loss 0.0313 - lr 0.0063\n",
      "2020-02-05 12:15:44,410 DEV : loss 0.04399297758936882 - score 0.9826\n",
      "2020-02-05 12:15:44,430 BAD EPOCHS (no improvement): 3\n",
      "2020-02-05 12:15:44,431 ----------------------------------------------------------------------------------------------------\n",
      "2020-02-05 12:15:44,496 epoch 22 - iter 0/130 - loss 0.01225263 - samples/sec: 6709.91\n",
      "2020-02-05 12:15:45,420 epoch 22 - iter 13/130 - loss 0.01976165 - samples/sec: 503.65\n",
      "2020-02-05 12:15:46,232 epoch 22 - iter 26/130 - loss 0.02459391 - samples/sec: 583.47\n",
      "2020-02-05 12:15:47,217 epoch 22 - iter 39/130 - loss 0.02680694 - samples/sec: 469.54\n",
      "2020-02-05 12:15:48,177 epoch 22 - iter 52/130 - loss 0.02638105 - samples/sec: 486.57\n",
      "2020-02-05 12:15:49,187 epoch 22 - iter 65/130 - loss 0.02568148 - samples/sec: 456.66\n",
      "2020-02-05 12:15:50,159 epoch 22 - iter 78/130 - loss 0.02943298 - samples/sec: 476.54\n",
      "2020-02-05 12:15:51,035 epoch 22 - iter 91/130 - loss 0.02836201 - samples/sec: 536.10\n",
      "2020-02-05 12:15:51,873 epoch 22 - iter 104/130 - loss 0.02920675 - samples/sec: 562.94\n",
      "2020-02-05 12:15:52,813 epoch 22 - iter 117/130 - loss 0.03098114 - samples/sec: 495.85\n",
      "2020-02-05 12:15:53,681 ----------------------------------------------------------------------------------------------------\n",
      "2020-02-05 12:15:53,683 EPOCH 22 done: loss 0.0305 - lr 0.0063\n",
      "2020-02-05 12:15:54,490 DEV : loss 0.04313424229621887 - score 0.9826\n",
      "Epoch    21: reducing learning rate of group 0 to 3.1250e-03.\n",
      "2020-02-05 12:15:54,511 BAD EPOCHS (no improvement): 4\n",
      "2020-02-05 12:15:54,513 ----------------------------------------------------------------------------------------------------\n",
      "2020-02-05 12:15:54,568 epoch 23 - iter 0/130 - loss 0.00380826 - samples/sec: 7704.13\n",
      "2020-02-05 12:15:55,512 epoch 23 - iter 13/130 - loss 0.01708476 - samples/sec: 490.59\n",
      "2020-02-05 12:15:56,410 epoch 23 - iter 26/130 - loss 0.04701787 - samples/sec: 520.02\n",
      "2020-02-05 12:15:57,258 epoch 23 - iter 39/130 - loss 0.04167856 - samples/sec: 555.43\n",
      "2020-02-05 12:15:58,133 epoch 23 - iter 52/130 - loss 0.03398996 - samples/sec: 536.80\n",
      "2020-02-05 12:15:58,989 epoch 23 - iter 65/130 - loss 0.03188760 - samples/sec: 550.29\n",
      "2020-02-05 12:16:00,027 epoch 23 - iter 78/130 - loss 0.03232586 - samples/sec: 443.04\n",
      "2020-02-05 12:16:00,921 epoch 23 - iter 91/130 - loss 0.03102585 - samples/sec: 528.61\n",
      "2020-02-05 12:16:01,766 epoch 23 - iter 104/130 - loss 0.03419598 - samples/sec: 556.92\n",
      "2020-02-05 12:16:02,726 epoch 23 - iter 117/130 - loss 0.03216258 - samples/sec: 484.30\n",
      "2020-02-05 12:16:03,584 ----------------------------------------------------------------------------------------------------\n",
      "2020-02-05 12:16:03,585 EPOCH 23 done: loss 0.0308 - lr 0.0031\n",
      "2020-02-05 12:16:04,392 DEV : loss 0.042752623558044434 - score 0.9826\n",
      "2020-02-05 12:16:04,412 BAD EPOCHS (no improvement): 1\n",
      "2020-02-05 12:16:04,414 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-02-05 12:16:04,475 epoch 24 - iter 0/130 - loss 0.01913757 - samples/sec: 6933.64\n",
      "2020-02-05 12:16:05,365 epoch 24 - iter 13/130 - loss 0.04099698 - samples/sec: 524.62\n",
      "2020-02-05 12:16:06,255 epoch 24 - iter 26/130 - loss 0.03547525 - samples/sec: 525.27\n",
      "2020-02-05 12:16:07,222 epoch 24 - iter 39/130 - loss 0.02913978 - samples/sec: 478.18\n",
      "2020-02-05 12:16:08,188 epoch 24 - iter 52/130 - loss 0.02988509 - samples/sec: 479.83\n",
      "2020-02-05 12:16:09,052 epoch 24 - iter 65/130 - loss 0.02770262 - samples/sec: 544.52\n",
      "2020-02-05 12:16:10,048 epoch 24 - iter 78/130 - loss 0.03079952 - samples/sec: 464.30\n",
      "2020-02-05 12:16:10,945 epoch 24 - iter 91/130 - loss 0.02906139 - samples/sec: 521.98\n",
      "2020-02-05 12:16:11,815 epoch 24 - iter 104/130 - loss 0.02931496 - samples/sec: 540.28\n",
      "2020-02-05 12:16:12,718 epoch 24 - iter 117/130 - loss 0.03222856 - samples/sec: 516.79\n",
      "2020-02-05 12:16:13,597 ----------------------------------------------------------------------------------------------------\n",
      "2020-02-05 12:16:13,598 EPOCH 24 done: loss 0.0301 - lr 0.0031\n",
      "2020-02-05 12:16:14,423 DEV : loss 0.04623366892337799 - score 0.9845\n",
      "2020-02-05 12:16:14,443 BAD EPOCHS (no improvement): 2\n",
      "2020-02-05 12:16:14,445 ----------------------------------------------------------------------------------------------------\n",
      "2020-02-05 12:16:14,505 epoch 25 - iter 0/130 - loss 0.03344208 - samples/sec: 7172.64\n",
      "2020-02-05 12:16:15,502 epoch 25 - iter 13/130 - loss 0.04628255 - samples/sec: 463.27\n",
      "2020-02-05 12:16:16,425 epoch 25 - iter 26/130 - loss 0.03714939 - samples/sec: 506.75\n",
      "2020-02-05 12:16:17,491 epoch 25 - iter 39/130 - loss 0.03203237 - samples/sec: 430.21\n",
      "2020-02-05 12:16:18,386 epoch 25 - iter 52/130 - loss 0.03110502 - samples/sec: 523.95\n",
      "2020-02-05 12:16:19,315 epoch 25 - iter 65/130 - loss 0.03111998 - samples/sec: 518.66\n",
      "2020-02-05 12:16:20,209 epoch 25 - iter 78/130 - loss 0.02923766 - samples/sec: 523.95\n",
      "2020-02-05 12:16:21,256 epoch 25 - iter 91/130 - loss 0.03166120 - samples/sec: 438.37\n",
      "2020-02-05 12:16:22,353 epoch 25 - iter 104/130 - loss 0.03209989 - samples/sec: 424.07\n",
      "2020-02-05 12:16:23,309 epoch 25 - iter 117/130 - loss 0.03251519 - samples/sec: 485.43\n",
      "2020-02-05 12:16:24,098 ----------------------------------------------------------------------------------------------------\n",
      "2020-02-05 12:16:24,099 EPOCH 25 done: loss 0.0317 - lr 0.0031\n",
      "2020-02-05 12:16:24,921 DEV : loss 0.0438360795378685 - score 0.9826\n",
      "2020-02-05 12:16:24,941 BAD EPOCHS (no improvement): 3\n",
      "2020-02-05 12:16:24,943 ----------------------------------------------------------------------------------------------------\n",
      "2020-02-05 12:16:25,000 epoch 26 - iter 0/130 - loss 0.01435011 - samples/sec: 7429.36\n",
      "2020-02-05 12:16:25,945 epoch 26 - iter 13/130 - loss 0.02312088 - samples/sec: 491.74\n",
      "2020-02-05 12:16:26,789 epoch 26 - iter 26/130 - loss 0.02015776 - samples/sec: 558.41\n",
      "2020-02-05 12:16:27,740 epoch 26 - iter 39/130 - loss 0.02467196 - samples/sec: 492.33\n",
      "2020-02-05 12:16:28,621 epoch 26 - iter 52/130 - loss 0.03004210 - samples/sec: 531.99\n",
      "2020-02-05 12:16:29,555 epoch 26 - iter 65/130 - loss 0.02686168 - samples/sec: 498.82\n",
      "2020-02-05 12:16:30,528 epoch 26 - iter 78/130 - loss 0.03091443 - samples/sec: 475.45\n",
      "2020-02-05 12:16:31,438 epoch 26 - iter 91/130 - loss 0.03154912 - samples/sec: 513.60\n",
      "2020-02-05 12:16:32,351 epoch 26 - iter 104/130 - loss 0.03262633 - samples/sec: 510.45\n",
      "2020-02-05 12:16:33,387 epoch 26 - iter 117/130 - loss 0.03182521 - samples/sec: 444.46\n",
      "2020-02-05 12:16:34,142 ----------------------------------------------------------------------------------------------------\n",
      "2020-02-05 12:16:34,143 EPOCH 26 done: loss 0.0306 - lr 0.0031\n",
      "2020-02-05 12:16:34,978 DEV : loss 0.04232383519411087 - score 0.9826\n",
      "Epoch    25: reducing learning rate of group 0 to 1.5625e-03.\n",
      "2020-02-05 12:16:34,999 BAD EPOCHS (no improvement): 4\n",
      "2020-02-05 12:16:35,001 ----------------------------------------------------------------------------------------------------\n",
      "2020-02-05 12:16:35,064 epoch 27 - iter 0/130 - loss 0.00960393 - samples/sec: 6819.85\n",
      "2020-02-05 12:16:36,062 epoch 27 - iter 13/130 - loss 0.04492438 - samples/sec: 463.27\n",
      "2020-02-05 12:16:37,105 epoch 27 - iter 26/130 - loss 0.02975374 - samples/sec: 441.16\n",
      "2020-02-05 12:16:38,054 epoch 27 - iter 39/130 - loss 0.02594864 - samples/sec: 490.01\n",
      "2020-02-05 12:16:38,993 epoch 27 - iter 52/130 - loss 0.02802858 - samples/sec: 495.85\n",
      "2020-02-05 12:16:39,897 epoch 27 - iter 65/130 - loss 0.02980777 - samples/sec: 534.73\n",
      "2020-02-05 12:16:40,805 epoch 27 - iter 78/130 - loss 0.02810468 - samples/sec: 514.23\n",
      "2020-02-05 12:16:41,733 epoch 27 - iter 91/130 - loss 0.02634675 - samples/sec: 501.83\n",
      "2020-02-05 12:16:42,639 epoch 27 - iter 104/130 - loss 0.02787725 - samples/sec: 531.99\n",
      "2020-02-05 12:16:43,824 epoch 27 - iter 117/130 - loss 0.03018875 - samples/sec: 383.07\n",
      "2020-02-05 12:16:44,681 ----------------------------------------------------------------------------------------------------\n",
      "2020-02-05 12:16:44,682 EPOCH 27 done: loss 0.0288 - lr 0.0016\n",
      "2020-02-05 12:16:45,490 DEV : loss 0.042767707258462906 - score 0.9826\n",
      "2020-02-05 12:16:45,510 BAD EPOCHS (no improvement): 1\n",
      "2020-02-05 12:16:45,511 ----------------------------------------------------------------------------------------------------\n",
      "2020-02-05 12:16:45,569 epoch 28 - iter 0/130 - loss 0.07542222 - samples/sec: 7428.89\n",
      "2020-02-05 12:16:46,437 epoch 28 - iter 13/130 - loss 0.04123509 - samples/sec: 540.98\n",
      "2020-02-05 12:16:47,332 epoch 28 - iter 26/130 - loss 0.02843060 - samples/sec: 522.63\n",
      "2020-02-05 12:16:48,260 epoch 28 - iter 39/130 - loss 0.02686693 - samples/sec: 520.67\n",
      "2020-02-05 12:16:49,251 epoch 28 - iter 52/130 - loss 0.02916166 - samples/sec: 466.91\n",
      "2020-02-05 12:16:50,148 epoch 28 - iter 65/130 - loss 0.02869287 - samples/sec: 522.63\n",
      "2020-02-05 12:16:51,052 epoch 28 - iter 78/130 - loss 0.03198423 - samples/sec: 518.06\n",
      "2020-02-05 12:16:52,004 epoch 28 - iter 91/130 - loss 0.02959260 - samples/sec: 487.71\n",
      "2020-02-05 12:16:52,965 epoch 28 - iter 104/130 - loss 0.02890033 - samples/sec: 484.31\n",
      "2020-02-05 12:16:53,946 epoch 28 - iter 117/130 - loss 0.02863701 - samples/sec: 472.74\n",
      "2020-02-05 12:16:54,734 ----------------------------------------------------------------------------------------------------\n",
      "2020-02-05 12:16:54,735 EPOCH 28 done: loss 0.0290 - lr 0.0016\n",
      "2020-02-05 12:16:55,552 DEV : loss 0.043214935809373856 - score 0.9826\n",
      "2020-02-05 12:16:55,572 BAD EPOCHS (no improvement): 2\n",
      "2020-02-05 12:16:55,574 ----------------------------------------------------------------------------------------------------\n",
      "2020-02-05 12:16:55,617 epoch 29 - iter 0/130 - loss 0.01638669 - samples/sec: 9905.48\n",
      "2020-02-05 12:16:56,620 epoch 29 - iter 13/130 - loss 0.02071867 - samples/sec: 459.69\n",
      "2020-02-05 12:16:57,595 epoch 29 - iter 26/130 - loss 0.02928891 - samples/sec: 474.36\n",
      "2020-02-05 12:16:58,547 epoch 29 - iter 39/130 - loss 0.02705864 - samples/sec: 486.57\n",
      "2020-02-05 12:16:59,444 epoch 29 - iter 52/130 - loss 0.02836377 - samples/sec: 521.97\n",
      "2020-02-05 12:17:00,389 epoch 29 - iter 65/130 - loss 0.03048385 - samples/sec: 492.91\n",
      "2020-02-05 12:17:01,362 epoch 29 - iter 78/130 - loss 0.02944036 - samples/sec: 475.99\n",
      "2020-02-05 12:17:02,233 epoch 29 - iter 91/130 - loss 0.03020774 - samples/sec: 539.58\n",
      "2020-02-05 12:17:03,084 epoch 29 - iter 104/130 - loss 0.03016071 - samples/sec: 553.95\n",
      "2020-02-05 12:17:04,096 epoch 29 - iter 117/130 - loss 0.03069060 - samples/sec: 456.16\n",
      "2020-02-05 12:17:04,920 ----------------------------------------------------------------------------------------------------\n",
      "2020-02-05 12:17:04,922 EPOCH 29 done: loss 0.0303 - lr 0.0016\n",
      "2020-02-05 12:17:05,735 DEV : loss 0.04266028478741646 - score 0.9826\n",
      "2020-02-05 12:17:05,755 BAD EPOCHS (no improvement): 3\n",
      "2020-02-05 12:17:05,757 ----------------------------------------------------------------------------------------------------\n",
      "2020-02-05 12:17:05,814 epoch 30 - iter 0/130 - loss 0.00689885 - samples/sec: 7428.86\n",
      "2020-02-05 12:17:06,738 epoch 30 - iter 13/130 - loss 0.03271592 - samples/sec: 503.65\n",
      "2020-02-05 12:17:07,658 epoch 30 - iter 26/130 - loss 0.02507154 - samples/sec: 532.67\n",
      "2020-02-05 12:17:08,643 epoch 30 - iter 39/130 - loss 0.03308328 - samples/sec: 472.74\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-02-05 12:17:09,876 epoch 30 - iter 52/130 - loss 0.03205360 - samples/sec: 366.86\n",
      "2020-02-05 12:17:10,835 epoch 30 - iter 65/130 - loss 0.03539614 - samples/sec: 482.62\n",
      "2020-02-05 12:17:11,819 epoch 30 - iter 78/130 - loss 0.03661937 - samples/sec: 490.01\n",
      "2020-02-05 12:17:12,735 epoch 30 - iter 91/130 - loss 0.03641513 - samples/sec: 510.45\n",
      "2020-02-05 12:17:13,655 epoch 30 - iter 104/130 - loss 0.03407164 - samples/sec: 505.49\n",
      "2020-02-05 12:17:14,637 epoch 30 - iter 117/130 - loss 0.03281042 - samples/sec: 472.21\n",
      "2020-02-05 12:17:15,430 ----------------------------------------------------------------------------------------------------\n",
      "2020-02-05 12:17:15,432 EPOCH 30 done: loss 0.0310 - lr 0.0016\n",
      "2020-02-05 12:17:16,249 DEV : loss 0.04347774758934975 - score 0.9826\n",
      "Epoch    29: reducing learning rate of group 0 to 7.8125e-04.\n",
      "2020-02-05 12:17:16,270 BAD EPOCHS (no improvement): 4\n",
      "2020-02-05 12:17:16,272 ----------------------------------------------------------------------------------------------------\n",
      "2020-02-05 12:17:16,323 epoch 31 - iter 0/130 - loss 0.00892714 - samples/sec: 8490.41\n",
      "2020-02-05 12:17:17,320 epoch 31 - iter 13/130 - loss 0.02969817 - samples/sec: 466.39\n",
      "2020-02-05 12:17:18,165 epoch 31 - iter 26/130 - loss 0.03341152 - samples/sec: 556.92\n",
      "2020-02-05 12:17:19,184 epoch 31 - iter 39/130 - loss 0.02653102 - samples/sec: 453.67\n",
      "2020-02-05 12:17:20,183 epoch 31 - iter 52/130 - loss 0.02420706 - samples/sec: 514.23\n",
      "2020-02-05 12:17:21,112 epoch 31 - iter 65/130 - loss 0.02701175 - samples/sec: 501.23\n",
      "2020-02-05 12:17:22,037 epoch 31 - iter 78/130 - loss 0.02741385 - samples/sec: 503.65\n",
      "2020-02-05 12:17:22,981 epoch 31 - iter 91/130 - loss 0.02581210 - samples/sec: 504.26\n",
      "2020-02-05 12:17:23,960 epoch 31 - iter 104/130 - loss 0.02604136 - samples/sec: 472.21\n",
      "2020-02-05 12:17:24,840 epoch 31 - iter 117/130 - loss 0.02605254 - samples/sec: 534.73\n",
      "2020-02-05 12:17:25,644 ----------------------------------------------------------------------------------------------------\n",
      "2020-02-05 12:17:25,646 EPOCH 31 done: loss 0.0287 - lr 0.0008\n",
      "2020-02-05 12:17:26,470 DEV : loss 0.04327356815338135 - score 0.9826\n",
      "2020-02-05 12:17:26,490 BAD EPOCHS (no improvement): 1\n",
      "2020-02-05 12:17:26,494 ----------------------------------------------------------------------------------------------------\n",
      "2020-02-05 12:17:26,570 epoch 32 - iter 0/130 - loss 0.06670611 - samples/sec: 5546.86\n",
      "2020-02-05 12:17:27,528 epoch 32 - iter 13/130 - loss 0.02909239 - samples/sec: 483.74\n",
      "2020-02-05 12:17:28,361 epoch 32 - iter 26/130 - loss 0.03420117 - samples/sec: 567.55\n",
      "2020-02-05 12:17:29,279 epoch 32 - iter 39/130 - loss 0.03338127 - samples/sec: 507.34\n",
      "2020-02-05 12:17:30,178 epoch 32 - iter 52/130 - loss 0.02971442 - samples/sec: 520.02\n",
      "2020-02-05 12:17:31,044 epoch 32 - iter 65/130 - loss 0.02790830 - samples/sec: 542.39\n",
      "2020-02-05 12:17:31,974 epoch 32 - iter 78/130 - loss 0.02599671 - samples/sec: 500.02\n",
      "2020-02-05 12:17:32,942 epoch 32 - iter 91/130 - loss 0.02667062 - samples/sec: 480.94\n",
      "2020-02-05 12:17:33,869 epoch 32 - iter 104/130 - loss 0.02902516 - samples/sec: 501.83\n",
      "2020-02-05 12:17:34,993 epoch 32 - iter 117/130 - loss 0.02905452 - samples/sec: 405.47\n",
      "2020-02-05 12:17:35,753 ----------------------------------------------------------------------------------------------------\n",
      "2020-02-05 12:17:35,754 EPOCH 32 done: loss 0.0293 - lr 0.0008\n",
      "2020-02-05 12:17:36,761 DEV : loss 0.043595802038908005 - score 0.9826\n",
      "2020-02-05 12:17:36,781 BAD EPOCHS (no improvement): 2\n",
      "2020-02-05 12:17:36,783 ----------------------------------------------------------------------------------------------------\n",
      "2020-02-05 12:17:36,864 epoch 33 - iter 0/130 - loss 0.01240306 - samples/sec: 5200.36\n",
      "2020-02-05 12:17:37,835 epoch 33 - iter 13/130 - loss 0.01376293 - samples/sec: 473.82\n",
      "2020-02-05 12:17:38,738 epoch 33 - iter 26/130 - loss 0.01891162 - samples/sec: 517.43\n",
      "2020-02-05 12:17:39,676 epoch 33 - iter 39/130 - loss 0.02559583 - samples/sec: 494.67\n",
      "2020-02-05 12:17:40,555 epoch 33 - iter 52/130 - loss 0.02594447 - samples/sec: 532.67\n",
      "2020-02-05 12:17:41,476 epoch 33 - iter 65/130 - loss 0.02861185 - samples/sec: 515.51\n",
      "2020-02-05 12:17:42,419 epoch 33 - iter 78/130 - loss 0.03372799 - samples/sec: 492.91\n",
      "2020-02-05 12:17:43,418 epoch 33 - iter 91/130 - loss 0.03212965 - samples/sec: 462.76\n",
      "2020-02-05 12:17:44,441 epoch 33 - iter 104/130 - loss 0.03232688 - samples/sec: 450.23\n",
      "2020-02-05 12:17:45,343 epoch 33 - iter 117/130 - loss 0.03022183 - samples/sec: 518.08\n",
      "2020-02-05 12:17:46,211 ----------------------------------------------------------------------------------------------------\n",
      "2020-02-05 12:17:46,212 EPOCH 33 done: loss 0.0295 - lr 0.0008\n",
      "2020-02-05 12:17:47,024 DEV : loss 0.043722525238990784 - score 0.9826\n",
      "2020-02-05 12:17:47,044 BAD EPOCHS (no improvement): 3\n",
      "2020-02-05 12:17:47,046 ----------------------------------------------------------------------------------------------------\n",
      "2020-02-05 12:17:47,162 epoch 34 - iter 0/130 - loss 0.00681650 - samples/sec: 3681.56\n",
      "2020-02-05 12:17:48,117 epoch 34 - iter 13/130 - loss 0.02548377 - samples/sec: 486.00\n",
      "2020-02-05 12:17:49,018 epoch 34 - iter 26/130 - loss 0.02604704 - samples/sec: 518.08\n",
      "2020-02-05 12:17:49,965 epoch 34 - iter 39/130 - loss 0.02850883 - samples/sec: 492.33\n",
      "2020-02-05 12:17:50,908 epoch 34 - iter 52/130 - loss 0.03179164 - samples/sec: 492.91\n",
      "2020-02-05 12:17:51,784 epoch 34 - iter 65/130 - loss 0.02956158 - samples/sec: 535.41\n",
      "2020-02-05 12:17:52,646 epoch 34 - iter 78/130 - loss 0.03017669 - samples/sec: 545.14\n",
      "2020-02-05 12:17:53,505 epoch 34 - iter 91/130 - loss 0.03035336 - samples/sec: 547.39\n",
      "2020-02-05 12:17:54,487 epoch 34 - iter 104/130 - loss 0.03278677 - samples/sec: 470.59\n",
      "2020-02-05 12:17:55,492 epoch 34 - iter 117/130 - loss 0.03108629 - samples/sec: 458.67\n",
      "2020-02-05 12:17:56,497 ----------------------------------------------------------------------------------------------------\n",
      "2020-02-05 12:17:56,499 EPOCH 34 done: loss 0.0295 - lr 0.0008\n",
      "2020-02-05 12:17:57,407 DEV : loss 0.043520595878362656 - score 0.9826\n",
      "Epoch    33: reducing learning rate of group 0 to 3.9063e-04.\n",
      "2020-02-05 12:17:57,428 BAD EPOCHS (no improvement): 4\n",
      "2020-02-05 12:17:57,430 ----------------------------------------------------------------------------------------------------\n",
      "2020-02-05 12:17:57,491 epoch 35 - iter 0/130 - loss 0.00950545 - samples/sec: 6933.64\n",
      "2020-02-05 12:17:58,385 epoch 35 - iter 13/130 - loss 0.01443810 - samples/sec: 522.63\n",
      "2020-02-05 12:17:59,382 epoch 35 - iter 26/130 - loss 0.01792434 - samples/sec: 486.00\n",
      "2020-02-05 12:18:00,269 epoch 35 - iter 39/130 - loss 0.02093885 - samples/sec: 530.63\n",
      "2020-02-05 12:18:01,150 epoch 35 - iter 52/130 - loss 0.02327941 - samples/sec: 543.10\n",
      "2020-02-05 12:18:02,157 epoch 35 - iter 65/130 - loss 0.02550619 - samples/sec: 485.43\n",
      "2020-02-05 12:18:03,008 epoch 35 - iter 78/130 - loss 0.02795139 - samples/sec: 553.21\n",
      "2020-02-05 12:18:03,972 epoch 35 - iter 91/130 - loss 0.02955692 - samples/sec: 482.06\n",
      "2020-02-05 12:18:04,959 epoch 35 - iter 104/130 - loss 0.02960790 - samples/sec: 469.01\n",
      "2020-02-05 12:18:06,002 epoch 35 - iter 117/130 - loss 0.03045680 - samples/sec: 441.63\n",
      "2020-02-05 12:18:06,849 ----------------------------------------------------------------------------------------------------\n",
      "2020-02-05 12:18:06,850 EPOCH 35 done: loss 0.0298 - lr 0.0004\n",
      "2020-02-05 12:18:07,668 DEV : loss 0.04363781958818436 - score 0.9826\n",
      "2020-02-05 12:18:07,688 BAD EPOCHS (no improvement): 1\n",
      "2020-02-05 12:18:07,690 ----------------------------------------------------------------------------------------------------\n",
      "2020-02-05 12:18:07,746 epoch 36 - iter 0/130 - loss 0.00520116 - samples/sec: 7704.36\n",
      "2020-02-05 12:18:08,599 epoch 36 - iter 13/130 - loss 0.01463601 - samples/sec: 553.95\n",
      "2020-02-05 12:18:09,601 epoch 36 - iter 26/130 - loss 0.02650843 - samples/sec: 467.96\n",
      "2020-02-05 12:18:10,550 epoch 36 - iter 39/130 - loss 0.03070449 - samples/sec: 491.16\n",
      "2020-02-05 12:18:11,723 epoch 36 - iter 52/130 - loss 0.02961394 - samples/sec: 386.99\n",
      "2020-02-05 12:18:12,697 epoch 36 - iter 65/130 - loss 0.02761941 - samples/sec: 475.99\n",
      "2020-02-05 12:18:13,601 epoch 36 - iter 78/130 - loss 0.02820917 - samples/sec: 517.43\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-02-05 12:18:14,507 epoch 36 - iter 91/130 - loss 0.02831085 - samples/sec: 516.15\n",
      "2020-02-05 12:18:15,435 epoch 36 - iter 104/130 - loss 0.02845038 - samples/sec: 504.87\n",
      "2020-02-05 12:18:16,405 epoch 36 - iter 117/130 - loss 0.03000542 - samples/sec: 479.28\n",
      "2020-02-05 12:18:17,228 ----------------------------------------------------------------------------------------------------\n",
      "2020-02-05 12:18:17,229 EPOCH 36 done: loss 0.0308 - lr 0.0004\n",
      "2020-02-05 12:18:18,049 DEV : loss 0.04392469674348831 - score 0.9826\n",
      "2020-02-05 12:18:18,073 BAD EPOCHS (no improvement): 2\n",
      "2020-02-05 12:18:18,075 ----------------------------------------------------------------------------------------------------\n",
      "2020-02-05 12:18:18,192 epoch 37 - iter 0/130 - loss 0.03444128 - samples/sec: 3617.59\n",
      "2020-02-05 12:18:19,161 epoch 37 - iter 13/130 - loss 0.03070795 - samples/sec: 478.73\n",
      "2020-02-05 12:18:20,080 epoch 37 - iter 26/130 - loss 0.02965951 - samples/sec: 507.95\n",
      "2020-02-05 12:18:20,991 epoch 37 - iter 39/130 - loss 0.02759056 - samples/sec: 514.24\n",
      "2020-02-05 12:18:21,909 epoch 37 - iter 52/130 - loss 0.02662981 - samples/sec: 509.20\n",
      "2020-02-05 12:18:22,840 epoch 37 - iter 65/130 - loss 0.02459049 - samples/sec: 501.83\n",
      "2020-02-05 12:18:23,828 epoch 37 - iter 78/130 - loss 0.02286222 - samples/sec: 469.02\n",
      "2020-02-05 12:18:24,738 epoch 37 - iter 91/130 - loss 0.02590961 - samples/sec: 513.60\n",
      "2020-02-05 12:18:25,682 epoch 37 - iter 104/130 - loss 0.02853917 - samples/sec: 494.08\n",
      "2020-02-05 12:18:26,576 epoch 37 - iter 117/130 - loss 0.02759323 - samples/sec: 524.61\n",
      "2020-02-05 12:18:27,574 ----------------------------------------------------------------------------------------------------\n",
      "2020-02-05 12:18:27,575 EPOCH 37 done: loss 0.0277 - lr 0.0004\n",
      "2020-02-05 12:18:28,333 DEV : loss 0.0440140999853611 - score 0.9826\n",
      "2020-02-05 12:18:28,353 BAD EPOCHS (no improvement): 3\n",
      "2020-02-05 12:18:28,355 ----------------------------------------------------------------------------------------------------\n",
      "2020-02-05 12:18:28,419 epoch 38 - iter 0/130 - loss 0.01169556 - samples/sec: 6603.58\n",
      "2020-02-05 12:18:29,851 epoch 38 - iter 13/130 - loss 0.01902104 - samples/sec: 326.29\n",
      "2020-02-05 12:18:30,842 epoch 38 - iter 26/130 - loss 0.02098699 - samples/sec: 482.62\n",
      "2020-02-05 12:18:32,044 epoch 38 - iter 39/130 - loss 0.02373925 - samples/sec: 379.92\n",
      "2020-02-05 12:18:33,006 epoch 38 - iter 52/130 - loss 0.02190470 - samples/sec: 488.86\n",
      "2020-02-05 12:18:33,932 epoch 38 - iter 65/130 - loss 0.02644361 - samples/sec: 511.71\n",
      "2020-02-05 12:18:34,913 epoch 38 - iter 78/130 - loss 0.03028194 - samples/sec: 477.08\n",
      "2020-02-05 12:18:35,888 epoch 38 - iter 91/130 - loss 0.03082455 - samples/sec: 479.83\n",
      "2020-02-05 12:18:36,886 epoch 38 - iter 104/130 - loss 0.02880570 - samples/sec: 467.96\n",
      "2020-02-05 12:18:37,871 epoch 38 - iter 117/130 - loss 0.02794440 - samples/sec: 476.54\n",
      "2020-02-05 12:18:38,763 ----------------------------------------------------------------------------------------------------\n",
      "2020-02-05 12:18:38,764 EPOCH 38 done: loss 0.0300 - lr 0.0004\n",
      "2020-02-05 12:18:39,642 DEV : loss 0.043687257915735245 - score 0.9826\n",
      "Epoch    37: reducing learning rate of group 0 to 1.9531e-04.\n",
      "2020-02-05 12:18:39,668 BAD EPOCHS (no improvement): 4\n",
      "2020-02-05 12:18:39,671 ----------------------------------------------------------------------------------------------------\n",
      "2020-02-05 12:18:39,734 epoch 39 - iter 0/130 - loss 0.06747469 - samples/sec: 6709.91\n",
      "2020-02-05 12:18:40,734 epoch 39 - iter 13/130 - loss 0.03818785 - samples/sec: 475.99\n",
      "2020-02-05 12:18:41,638 epoch 39 - iter 26/130 - loss 0.03448957 - samples/sec: 516.15\n",
      "2020-02-05 12:18:42,612 epoch 39 - iter 39/130 - loss 0.03063160 - samples/sec: 477.63\n",
      "2020-02-05 12:18:43,571 epoch 39 - iter 52/130 - loss 0.02811275 - samples/sec: 485.43\n",
      "2020-02-05 12:18:44,558 epoch 39 - iter 65/130 - loss 0.02588537 - samples/sec: 476.53\n",
      "2020-02-05 12:18:45,575 epoch 39 - iter 78/130 - loss 0.02358075 - samples/sec: 454.66\n",
      "2020-02-05 12:18:46,525 epoch 39 - iter 91/130 - loss 0.02776750 - samples/sec: 488.86\n",
      "2020-02-05 12:18:47,482 epoch 39 - iter 104/130 - loss 0.02700647 - samples/sec: 491.74\n",
      "2020-02-05 12:18:48,379 epoch 39 - iter 117/130 - loss 0.02914236 - samples/sec: 520.67\n",
      "2020-02-05 12:18:49,212 ----------------------------------------------------------------------------------------------------\n",
      "2020-02-05 12:18:49,214 EPOCH 39 done: loss 0.0298 - lr 0.0002\n",
      "2020-02-05 12:18:50,028 DEV : loss 0.04361652582883835 - score 0.9826\n",
      "2020-02-05 12:18:50,049 BAD EPOCHS (no improvement): 1\n",
      "2020-02-05 12:18:50,051 ----------------------------------------------------------------------------------------------------\n",
      "2020-02-05 12:18:50,125 epoch 40 - iter 0/130 - loss 0.01049433 - samples/sec: 5859.32\n",
      "2020-02-05 12:18:51,127 epoch 40 - iter 13/130 - loss 0.02640144 - samples/sec: 459.69\n",
      "2020-02-05 12:18:51,969 epoch 40 - iter 26/130 - loss 0.01822519 - samples/sec: 560.67\n",
      "2020-02-05 12:18:52,875 epoch 40 - iter 39/130 - loss 0.01921346 - samples/sec: 514.87\n",
      "2020-02-05 12:18:53,772 epoch 40 - iter 52/130 - loss 0.02053975 - samples/sec: 523.29\n",
      "2020-02-05 12:18:54,667 epoch 40 - iter 65/130 - loss 0.02272580 - samples/sec: 523.95\n",
      "2020-02-05 12:18:55,577 epoch 40 - iter 78/130 - loss 0.02419528 - samples/sec: 512.34\n",
      "2020-02-05 12:18:56,438 epoch 40 - iter 91/130 - loss 0.02576658 - samples/sec: 545.24\n",
      "2020-02-05 12:18:57,364 epoch 40 - iter 104/130 - loss 0.02748097 - samples/sec: 503.04\n",
      "2020-02-05 12:18:58,327 epoch 40 - iter 117/130 - loss 0.02858127 - samples/sec: 482.06\n",
      "2020-02-05 12:18:59,268 ----------------------------------------------------------------------------------------------------\n",
      "2020-02-05 12:18:59,270 EPOCH 40 done: loss 0.0293 - lr 0.0002\n",
      "2020-02-05 12:19:00,080 DEV : loss 0.04369335621595383 - score 0.9826\n",
      "2020-02-05 12:19:00,100 BAD EPOCHS (no improvement): 2\n",
      "2020-02-05 12:19:00,102 ----------------------------------------------------------------------------------------------------\n",
      "2020-02-05 12:19:00,162 epoch 41 - iter 0/130 - loss 0.03633076 - samples/sec: 7051.59\n",
      "2020-02-05 12:19:01,061 epoch 41 - iter 13/130 - loss 0.03708499 - samples/sec: 518.72\n",
      "2020-02-05 12:19:01,935 epoch 41 - iter 26/130 - loss 0.02982106 - samples/sec: 535.41\n",
      "2020-02-05 12:19:02,786 epoch 41 - iter 39/130 - loss 0.02849785 - samples/sec: 553.95\n",
      "2020-02-05 12:19:03,701 epoch 41 - iter 52/130 - loss 0.03589282 - samples/sec: 509.82\n",
      "2020-02-05 12:19:04,736 epoch 41 - iter 65/130 - loss 0.03330650 - samples/sec: 444.46\n",
      "2020-02-05 12:19:05,635 epoch 41 - iter 78/130 - loss 0.03121018 - samples/sec: 520.02\n",
      "2020-02-05 12:19:06,630 epoch 41 - iter 91/130 - loss 0.03202389 - samples/sec: 470.63\n",
      "2020-02-05 12:19:07,563 epoch 41 - iter 104/130 - loss 0.03239170 - samples/sec: 498.82\n",
      "2020-02-05 12:19:08,474 epoch 41 - iter 117/130 - loss 0.03063506 - samples/sec: 511.70\n",
      "2020-02-05 12:19:09,422 ----------------------------------------------------------------------------------------------------\n",
      "2020-02-05 12:19:09,424 EPOCH 41 done: loss 0.0302 - lr 0.0002\n",
      "2020-02-05 12:19:10,251 DEV : loss 0.043794285506010056 - score 0.9826\n",
      "2020-02-05 12:19:10,270 BAD EPOCHS (no improvement): 3\n",
      "2020-02-05 12:19:10,272 ----------------------------------------------------------------------------------------------------\n",
      "2020-02-05 12:19:10,333 epoch 42 - iter 0/130 - loss 0.03725953 - samples/sec: 6933.62\n",
      "2020-02-05 12:19:11,265 epoch 42 - iter 13/130 - loss 0.02677402 - samples/sec: 503.65\n",
      "2020-02-05 12:19:12,190 epoch 42 - iter 26/130 - loss 0.02927882 - samples/sec: 529.96\n",
      "2020-02-05 12:19:13,091 epoch 42 - iter 39/130 - loss 0.03303127 - samples/sec: 517.43\n",
      "2020-02-05 12:19:14,005 epoch 42 - iter 52/130 - loss 0.03117285 - samples/sec: 511.08\n",
      "2020-02-05 12:19:14,874 epoch 42 - iter 65/130 - loss 0.03114937 - samples/sec: 540.28\n",
      "2020-02-05 12:19:15,754 epoch 42 - iter 78/130 - loss 0.02971427 - samples/sec: 534.04\n",
      "2020-02-05 12:19:16,808 epoch 42 - iter 91/130 - loss 0.02801798 - samples/sec: 435.16\n",
      "2020-02-05 12:19:17,897 epoch 42 - iter 104/130 - loss 0.03085559 - samples/sec: 420.22\n",
      "2020-02-05 12:19:18,854 epoch 42 - iter 117/130 - loss 0.03006031 - samples/sec: 494.08\n",
      "2020-02-05 12:19:19,649 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-02-05 12:19:19,650 EPOCH 42 done: loss 0.0300 - lr 0.0002\n",
      "2020-02-05 12:19:20,468 DEV : loss 0.04379584640264511 - score 0.9826\n",
      "Epoch    41: reducing learning rate of group 0 to 9.7656e-05.\n",
      "2020-02-05 12:19:20,488 BAD EPOCHS (no improvement): 4\n",
      "2020-02-05 12:19:20,490 ----------------------------------------------------------------------------------------------------\n",
      "2020-02-05 12:19:20,491 ----------------------------------------------------------------------------------------------------\n",
      "2020-02-05 12:19:20,492 learning rate too small - quitting training!\n",
      "2020-02-05 12:19:20,493 ----------------------------------------------------------------------------------------------------\n",
      "2020-02-05 12:19:24,579 ----------------------------------------------------------------------------------------------------\n",
      "2020-02-05 12:19:24,582 Testing using best model ...\n",
      "2020-02-05 12:19:24,583 loading file best-model.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\serialization.py:574: DeprecationWarning: Call to deprecated class DocumentLSTMEmbeddings. (The functionality of this class is moved to 'DocumentRNNEmbeddings') -- Deprecated since version 0.4.\n",
      "  result = unpickler.load()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-02-05 12:19:27,941 0.9961\t0.9961\t0.9961\n",
      "2020-02-05 12:19:27,943 \n",
      "MICRO_AVG: acc 0.9923 - f1-score 0.9961\n",
      "MACRO_AVG: acc 0.9809 - f1-score 0.9903\n",
      "ham        tp: 458 - fp: 1 - fn: 1 - tn: 57 - precision: 0.9978 - recall: 0.9978 - accuracy: 0.9957 - f1-score: 0.9978\n",
      "spam       tp: 57 - fp: 1 - fn: 1 - tn: 458 - precision: 0.9828 - recall: 0.9828 - accuracy: 0.9661 - f1-score: 0.9828\n",
      "2020-02-05 12:19:27,944 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_score': 0.9961,\n",
       " 'dev_score_history': [0.9865,\n",
       "  0.9884,\n",
       "  0.9826,\n",
       "  0.9845,\n",
       "  0.9865,\n",
       "  0.9845,\n",
       "  0.9865,\n",
       "  0.9865,\n",
       "  0.9865,\n",
       "  0.9845,\n",
       "  0.9845,\n",
       "  0.9865,\n",
       "  0.9865,\n",
       "  0.9826,\n",
       "  0.9807,\n",
       "  0.9807,\n",
       "  0.9845,\n",
       "  0.9865,\n",
       "  0.9826,\n",
       "  0.9865,\n",
       "  0.9826,\n",
       "  0.9826,\n",
       "  0.9826,\n",
       "  0.9845,\n",
       "  0.9826,\n",
       "  0.9826,\n",
       "  0.9826,\n",
       "  0.9826,\n",
       "  0.9826,\n",
       "  0.9826,\n",
       "  0.9826,\n",
       "  0.9826,\n",
       "  0.9826,\n",
       "  0.9826,\n",
       "  0.9826,\n",
       "  0.9826,\n",
       "  0.9826,\n",
       "  0.9826,\n",
       "  0.9826,\n",
       "  0.9826,\n",
       "  0.9826,\n",
       "  0.9826],\n",
       " 'train_loss_history': [0.15148688282531042,\n",
       "  0.0848426594470556,\n",
       "  0.07535099587761439,\n",
       "  0.07040915398930128,\n",
       "  0.06383458686849246,\n",
       "  0.059092580570051303,\n",
       "  0.049271565632751355,\n",
       "  0.04867712014283125,\n",
       "  0.04706459092692687,\n",
       "  0.04353121120769244,\n",
       "  0.04010398012514298,\n",
       "  0.03722284267871426,\n",
       "  0.036603732765294036,\n",
       "  0.03572221935655062,\n",
       "  0.033504460537089754,\n",
       "  0.03420523538325842,\n",
       "  0.032365413540257855,\n",
       "  0.03432311093291411,\n",
       "  0.03301021218156586,\n",
       "  0.032221247313114314,\n",
       "  0.03131773202465131,\n",
       "  0.03045689035923435,\n",
       "  0.030824355258104893,\n",
       "  0.030122705828398467,\n",
       "  0.03169607180528916,\n",
       "  0.030624972713681368,\n",
       "  0.028816295701723834,\n",
       "  0.028971870673390535,\n",
       "  0.030331876881134052,\n",
       "  0.030962581316439006,\n",
       "  0.02869078701791855,\n",
       "  0.029311155642454442,\n",
       "  0.029525754414498805,\n",
       "  0.029509723114852723,\n",
       "  0.029756520573909467,\n",
       "  0.03077026458027271,\n",
       "  0.02769508732912632,\n",
       "  0.030037804771787847,\n",
       "  0.029796444495710044,\n",
       "  0.029307806162306896,\n",
       "  0.030173611612274095,\n",
       "  0.030022555303115112],\n",
       " 'dev_loss_history': [tensor(0.0473, device='cuda:0'),\n",
       "  tensor(0.0379, device='cuda:0'),\n",
       "  tensor(0.0426, device='cuda:0'),\n",
       "  tensor(0.0410, device='cuda:0'),\n",
       "  tensor(0.0373, device='cuda:0'),\n",
       "  tensor(0.0381, device='cuda:0'),\n",
       "  tensor(0.0352, device='cuda:0'),\n",
       "  tensor(0.0425, device='cuda:0'),\n",
       "  tensor(0.0352, device='cuda:0'),\n",
       "  tensor(0.0403, device='cuda:0'),\n",
       "  tensor(0.0387, device='cuda:0'),\n",
       "  tensor(0.0364, device='cuda:0'),\n",
       "  tensor(0.0369, device='cuda:0'),\n",
       "  tensor(0.0401, device='cuda:0'),\n",
       "  tensor(0.0403, device='cuda:0'),\n",
       "  tensor(0.0399, device='cuda:0'),\n",
       "  tensor(0.0452, device='cuda:0'),\n",
       "  tensor(0.0388, device='cuda:0'),\n",
       "  tensor(0.0442, device='cuda:0'),\n",
       "  tensor(0.0493, device='cuda:0'),\n",
       "  tensor(0.0440, device='cuda:0'),\n",
       "  tensor(0.0431, device='cuda:0'),\n",
       "  tensor(0.0428, device='cuda:0'),\n",
       "  tensor(0.0462, device='cuda:0'),\n",
       "  tensor(0.0438, device='cuda:0'),\n",
       "  tensor(0.0423, device='cuda:0'),\n",
       "  tensor(0.0428, device='cuda:0'),\n",
       "  tensor(0.0432, device='cuda:0'),\n",
       "  tensor(0.0427, device='cuda:0'),\n",
       "  tensor(0.0435, device='cuda:0'),\n",
       "  tensor(0.0433, device='cuda:0'),\n",
       "  tensor(0.0436, device='cuda:0'),\n",
       "  tensor(0.0437, device='cuda:0'),\n",
       "  tensor(0.0435, device='cuda:0'),\n",
       "  tensor(0.0436, device='cuda:0'),\n",
       "  tensor(0.0439, device='cuda:0'),\n",
       "  tensor(0.0440, device='cuda:0'),\n",
       "  tensor(0.0437, device='cuda:0'),\n",
       "  tensor(0.0436, device='cuda:0'),\n",
       "  tensor(0.0437, device='cuda:0'),\n",
       "  tensor(0.0438, device='cuda:0'),\n",
       "  tensor(0.0438, device='cuda:0')]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = NLPTaskDataFetcher.load_classification_corpus(Path('./'), test_file='test.csv', dev_file='dev.csv', train_file='train.csv')\n",
    "word_embeddings = [WordEmbeddings('glove'), FlairEmbeddings('news-forward-fast'), FlairEmbeddings('news-backward-fast')]\n",
    "#word_embeddings = [BertEmbeddings(), FlairEmbeddings('news-forward-fast'), FlairEmbeddings('news-backward-fast')]\n",
    "document_embeddings = DocumentLSTMEmbeddings(word_embeddings, hidden_size=512, reproject_words=True, reproject_words_dimension=256)\n",
    "classifier = TextClassifier(document_embeddings, label_dictionary=corpus.make_label_dictionary(), multi_label=False)\n",
    "trainer = ModelTrainer(classifier, corpus)\n",
    "trainer.train('./', max_epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
