{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from flair.data_fetcher import NLPTaskDataFetcher\n",
    "from flair.embeddings import WordEmbeddings, FlairEmbeddings, DocumentLSTMEmbeddings, BertEmbeddings\n",
    "from flair.models import TextClassifier\n",
    "from flair.trainers import ModelTrainer\n",
    "from pathlib import Path\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "ps = nltk.PorterStemmer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>4044</td>\n",
       "      <td>ham</td>\n",
       "      <td>If You mean the website. Yes.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3849</td>\n",
       "      <td>ham</td>\n",
       "      <td>I to am looking forward to all the sex cuddlin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1714</td>\n",
       "      <td>ham</td>\n",
       "      <td>Yeah I don't see why not</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2241</td>\n",
       "      <td>ham</td>\n",
       "      <td>U buy newspapers already?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3582</td>\n",
       "      <td>ham</td>\n",
       "      <td>I sent your maga that money yesterday oh.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     label                                               text\n",
       "4044   ham                      If You mean the website. Yes.\n",
       "3849   ham  I to am looking forward to all the sex cuddlin...\n",
       "1714   ham                           Yeah I don't see why not\n",
       "2241   ham                          U buy newspapers already?\n",
       "3582   ham          I sent your maga that money yesterday oh."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"./spam.csv\", encoding='latin-1').sample(frac=1).drop_duplicates()\n",
    "data = data[['v1', 'v2']].rename(columns={\"v1\":\"label\", \"v2\":\"text\"})\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning\n",
    "#### Remove the Punctuations, stopwords, Lemmatize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>cleaned_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>4044</td>\n",
       "      <td>ham</td>\n",
       "      <td>If You mean the website. Yes.</td>\n",
       "      <td>mean websit ye</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3849</td>\n",
       "      <td>ham</td>\n",
       "      <td>I to am looking forward to all the sex cuddlin...</td>\n",
       "      <td>look forward sex cuddl two sleep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1714</td>\n",
       "      <td>ham</td>\n",
       "      <td>Yeah I don't see why not</td>\n",
       "      <td>yeah dont see</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2241</td>\n",
       "      <td>ham</td>\n",
       "      <td>U buy newspapers already?</td>\n",
       "      <td>u buy newspap alreadi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3582</td>\n",
       "      <td>ham</td>\n",
       "      <td>I sent your maga that money yesterday oh.</td>\n",
       "      <td>sent maga money yesterday oh</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     label                                               text  \\\n",
       "4044   ham                      If You mean the website. Yes.   \n",
       "3849   ham  I to am looking forward to all the sex cuddlin...   \n",
       "1714   ham                           Yeah I don't see why not   \n",
       "2241   ham                          U buy newspapers already?   \n",
       "3582   ham          I sent your maga that money yesterday oh.   \n",
       "\n",
       "                           cleaned_text  \n",
       "4044                     mean websit ye  \n",
       "3849  look forward sex cuddl two sleep   \n",
       "1714                      yeah dont see  \n",
       "2241              u buy newspap alreadi  \n",
       "3582       sent maga money yesterday oh  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def clean_text(text):\n",
    "    text = \"\".join([word.lower() for word in text if word not in string.punctuation])\n",
    "    tokens = re.split('\\W+', text)\n",
    "    text = \" \".join([ps.stem(word) for word in tokens if word not in stopwords])\n",
    "    return text\n",
    "\n",
    "data['cleaned_text'] = data['text'].apply(lambda x: clean_text(x))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data=data.drop([\"text\"],axis=1)\n",
    "#data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test and Train Dataset Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['label'] = '__label__' + data['label'].astype(str)\n",
    "data.iloc[0:int(len(data)*0.8)].to_csv('train.csv', sep='\\t', index = False, header = False)\n",
    "data.iloc[int(len(data)*0.8):int(len(data)*0.9)].to_csv('test.csv', sep='\\t', index = False, header = False)\n",
    "data.iloc[int(len(data)*0.9):].to_csv('dev.csv', sep='\\t', index = False, header = False);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use BERT Embeddings and Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated function (or staticmethod) load_classification_corpus. (Use 'flair.datasets' instead.) -- Deprecated since version 0.4.1.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-02-05 12:12:34,689 Reading data from .\n",
      "2020-02-05 12:12:34,690 Train: train.csv\n",
      "2020-02-05 12:12:34,691 Dev: dev.csv\n",
      "2020-02-05 12:12:34,692 Test: test.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\flair\\data_fetcher.py:447: DeprecationWarning: Call to deprecated function (or staticmethod) read_text_classification_file. (Use 'flair.datasets' instead.) -- Deprecated since version 0.4.1.\n",
      "  max_tokens_per_doc=max_tokens_per_doc,\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\flair\\data_fetcher.py:454: DeprecationWarning: Call to deprecated function (or staticmethod) read_text_classification_file. (Use 'flair.datasets' instead.) -- Deprecated since version 0.4.1.\n",
      "  max_tokens_per_doc=max_tokens_per_doc,\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\flair\\data_fetcher.py:463: DeprecationWarning: Call to deprecated function (or staticmethod) read_text_classification_file. (Use 'flair.datasets' instead.) -- Deprecated since version 0.4.1.\n",
      "  max_tokens_per_doc=max_tokens_per_doc,\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: DeprecationWarning: Call to deprecated class DocumentLSTMEmbeddings. (The functionality of this class is moved to 'DocumentRNNEmbeddings') -- Deprecated since version 0.4.\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-02-05 12:12:44,526 Computing label dictionary. Progress:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 4135/4135 [00:00<00:00, 318123.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-02-05 12:12:44,543 [b'ham', b'spam']\n",
      "2020-02-05 12:12:44,548 ----------------------------------------------------------------------------------------------------\n",
      "2020-02-05 12:12:44,551 Model: \"TextClassifier(\n",
      "  (document_embeddings): DocumentLSTMEmbeddings(\n",
      "    (embeddings): StackedEmbeddings(\n",
      "      (list_embedding_0): BertEmbeddings(\n",
      "        (model): BertModel(\n",
      "          (embeddings): BertEmbeddings(\n",
      "            (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
      "            (position_embeddings): Embedding(512, 768)\n",
      "            (token_type_embeddings): Embedding(2, 768)\n",
      "            (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1)\n",
      "          )\n",
      "          (encoder): BertEncoder(\n",
      "            (layer): ModuleList(\n",
      "              (0): BertLayer(\n",
      "                (attention): BertAttention(\n",
      "                  (self): BertSelfAttention(\n",
      "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (dropout): Dropout(p=0.1)\n",
      "                  )\n",
      "                  (output): BertSelfOutput(\n",
      "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
      "                    (dropout): Dropout(p=0.1)\n",
      "                  )\n",
      "                )\n",
      "                (intermediate): BertIntermediate(\n",
      "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                )\n",
      "                (output): BertOutput(\n",
      "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1)\n",
      "                )\n",
      "              )\n",
      "              (1): BertLayer(\n",
      "                (attention): BertAttention(\n",
      "                  (self): BertSelfAttention(\n",
      "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (dropout): Dropout(p=0.1)\n",
      "                  )\n",
      "                  (output): BertSelfOutput(\n",
      "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
      "                    (dropout): Dropout(p=0.1)\n",
      "                  )\n",
      "                )\n",
      "                (intermediate): BertIntermediate(\n",
      "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                )\n",
      "                (output): BertOutput(\n",
      "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1)\n",
      "                )\n",
      "              )\n",
      "              (2): BertLayer(\n",
      "                (attention): BertAttention(\n",
      "                  (self): BertSelfAttention(\n",
      "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (dropout): Dropout(p=0.1)\n",
      "                  )\n",
      "                  (output): BertSelfOutput(\n",
      "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
      "                    (dropout): Dropout(p=0.1)\n",
      "                  )\n",
      "                )\n",
      "                (intermediate): BertIntermediate(\n",
      "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                )\n",
      "                (output): BertOutput(\n",
      "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1)\n",
      "                )\n",
      "              )\n",
      "              (3): BertLayer(\n",
      "                (attention): BertAttention(\n",
      "                  (self): BertSelfAttention(\n",
      "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (dropout): Dropout(p=0.1)\n",
      "                  )\n",
      "                  (output): BertSelfOutput(\n",
      "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
      "                    (dropout): Dropout(p=0.1)\n",
      "                  )\n",
      "                )\n",
      "                (intermediate): BertIntermediate(\n",
      "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                )\n",
      "                (output): BertOutput(\n",
      "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1)\n",
      "                )\n",
      "              )\n",
      "              (4): BertLayer(\n",
      "                (attention): BertAttention(\n",
      "                  (self): BertSelfAttention(\n",
      "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (dropout): Dropout(p=0.1)\n",
      "                  )\n",
      "                  (output): BertSelfOutput(\n",
      "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
      "                    (dropout): Dropout(p=0.1)\n",
      "                  )\n",
      "                )\n",
      "                (intermediate): BertIntermediate(\n",
      "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                )\n",
      "                (output): BertOutput(\n",
      "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1)\n",
      "                )\n",
      "              )\n",
      "              (5): BertLayer(\n",
      "                (attention): BertAttention(\n",
      "                  (self): BertSelfAttention(\n",
      "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (dropout): Dropout(p=0.1)\n",
      "                  )\n",
      "                  (output): BertSelfOutput(\n",
      "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
      "                    (dropout): Dropout(p=0.1)\n",
      "                  )\n",
      "                )\n",
      "                (intermediate): BertIntermediate(\n",
      "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                )\n",
      "                (output): BertOutput(\n",
      "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1)\n",
      "                )\n",
      "              )\n",
      "              (6): BertLayer(\n",
      "                (attention): BertAttention(\n",
      "                  (self): BertSelfAttention(\n",
      "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (dropout): Dropout(p=0.1)\n",
      "                  )\n",
      "                  (output): BertSelfOutput(\n",
      "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
      "                    (dropout): Dropout(p=0.1)\n",
      "                  )\n",
      "                )\n",
      "                (intermediate): BertIntermediate(\n",
      "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                )\n",
      "                (output): BertOutput(\n",
      "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1)\n",
      "                )\n",
      "              )\n",
      "              (7): BertLayer(\n",
      "                (attention): BertAttention(\n",
      "                  (self): BertSelfAttention(\n",
      "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (dropout): Dropout(p=0.1)\n",
      "                  )\n",
      "                  (output): BertSelfOutput(\n",
      "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
      "                    (dropout): Dropout(p=0.1)\n",
      "                  )\n",
      "                )\n",
      "                (intermediate): BertIntermediate(\n",
      "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                )\n",
      "                (output): BertOutput(\n",
      "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1)\n",
      "                )\n",
      "              )\n",
      "              (8): BertLayer(\n",
      "                (attention): BertAttention(\n",
      "                  (self): BertSelfAttention(\n",
      "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (dropout): Dropout(p=0.1)\n",
      "                  )\n",
      "                  (output): BertSelfOutput(\n",
      "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
      "                    (dropout): Dropout(p=0.1)\n",
      "                  )\n",
      "                )\n",
      "                (intermediate): BertIntermediate(\n",
      "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                )\n",
      "                (output): BertOutput(\n",
      "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1)\n",
      "                )\n",
      "              )\n",
      "              (9): BertLayer(\n",
      "                (attention): BertAttention(\n",
      "                  (self): BertSelfAttention(\n",
      "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (dropout): Dropout(p=0.1)\n",
      "                  )\n",
      "                  (output): BertSelfOutput(\n",
      "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
      "                    (dropout): Dropout(p=0.1)\n",
      "                  )\n",
      "                )\n",
      "                (intermediate): BertIntermediate(\n",
      "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                )\n",
      "                (output): BertOutput(\n",
      "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1)\n",
      "                )\n",
      "              )\n",
      "              (10): BertLayer(\n",
      "                (attention): BertAttention(\n",
      "                  (self): BertSelfAttention(\n",
      "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (dropout): Dropout(p=0.1)\n",
      "                  )\n",
      "                  (output): BertSelfOutput(\n",
      "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
      "                    (dropout): Dropout(p=0.1)\n",
      "                  )\n",
      "                )\n",
      "                (intermediate): BertIntermediate(\n",
      "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                )\n",
      "                (output): BertOutput(\n",
      "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1)\n",
      "                )\n",
      "              )\n",
      "              (11): BertLayer(\n",
      "                (attention): BertAttention(\n",
      "                  (self): BertSelfAttention(\n",
      "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (dropout): Dropout(p=0.1)\n",
      "                  )\n",
      "                  (output): BertSelfOutput(\n",
      "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
      "                    (dropout): Dropout(p=0.1)\n",
      "                  )\n",
      "                )\n",
      "                (intermediate): BertIntermediate(\n",
      "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                )\n",
      "                (output): BertOutput(\n",
      "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (pooler): BertPooler(\n",
      "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (activation): Tanh()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (list_embedding_1): FlairEmbeddings(\n",
      "        (lm): LanguageModel(\n",
      "          (drop): Dropout(p=0.25)\n",
      "          (encoder): Embedding(275, 100)\n",
      "          (rnn): LSTM(100, 1024)\n",
      "          (decoder): Linear(in_features=1024, out_features=275, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (list_embedding_2): FlairEmbeddings(\n",
      "        (lm): LanguageModel(\n",
      "          (drop): Dropout(p=0.25)\n",
      "          (encoder): Embedding(275, 100)\n",
      "          (rnn): LSTM(100, 1024)\n",
      "          (decoder): Linear(in_features=1024, out_features=275, bias=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (word_reprojection_map): Linear(in_features=5120, out_features=256, bias=True)\n",
      "    (rnn): GRU(256, 512)\n",
      "    (dropout): Dropout(p=0.5)\n",
      "  )\n",
      "  (decoder): Linear(in_features=512, out_features=2, bias=True)\n",
      "  (loss_function): CrossEntropyLoss()\n",
      ")\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-02-05 12:12:44,552 ----------------------------------------------------------------------------------------------------\n",
      "2020-02-05 12:12:44,553 Corpus: \"Corpus: 4135 train + 517 dev + 517 test sentences\"\n",
      "2020-02-05 12:12:44,554 ----------------------------------------------------------------------------------------------------\n",
      "2020-02-05 12:12:44,555 Parameters:\n",
      "2020-02-05 12:12:44,556  - learning_rate: \"0.1\"\n",
      "2020-02-05 12:12:44,557  - mini_batch_size: \"32\"\n",
      "2020-02-05 12:12:44,558  - patience: \"3\"\n",
      "2020-02-05 12:12:44,559  - anneal_factor: \"0.5\"\n",
      "2020-02-05 12:12:44,560  - max_epochs: \"100\"\n",
      "2020-02-05 12:12:44,561  - shuffle: \"True\"\n",
      "2020-02-05 12:12:44,561  - train_with_dev: \"False\"\n",
      "2020-02-05 12:12:44,563 ----------------------------------------------------------------------------------------------------\n",
      "2020-02-05 12:12:44,563 Model training base path: \".\"\n",
      "2020-02-05 12:12:44,564 ----------------------------------------------------------------------------------------------------\n",
      "2020-02-05 12:12:44,565 Device: cuda:0\n",
      "2020-02-05 12:12:44,566 ----------------------------------------------------------------------------------------------------\n",
      "2020-02-05 12:12:44,568 Embeddings storage mode: cpu\n",
      "2020-02-05 12:12:44,571 ----------------------------------------------------------------------------------------------------\n",
      "2020-02-05 12:13:22,212 epoch 1 - iter 0/130 - loss 0.63973254 - samples/sec: 11.05\n",
      "2020-02-05 12:18:27,616 epoch 1 - iter 13/130 - loss 0.40433131 - samples/sec: 1.37\n",
      "2020-02-05 12:24:24,005 epoch 1 - iter 26/130 - loss 0.32967882 - samples/sec: 1.17\n",
      "2020-02-05 12:29:42,802 epoch 1 - iter 39/130 - loss 0.27520884 - samples/sec: 1.31\n",
      "2020-02-05 12:36:12,862 epoch 1 - iter 52/130 - loss 0.22661761 - samples/sec: 1.07\n",
      "2020-02-05 12:43:37,606 epoch 1 - iter 65/130 - loss 0.20529285 - samples/sec: 0.94\n",
      "2020-02-05 12:51:22,600 epoch 1 - iter 78/130 - loss 0.18585708 - samples/sec: 0.90\n",
      "2020-02-05 12:57:07,152 epoch 1 - iter 91/130 - loss 0.17225207 - samples/sec: 1.21\n",
      "2020-02-05 13:03:20,315 epoch 1 - iter 104/130 - loss 0.15867982 - samples/sec: 1.12\n",
      "2020-02-05 13:09:11,986 epoch 1 - iter 117/130 - loss 0.14982293 - samples/sec: 1.19\n",
      "2020-02-05 13:14:16,320 ----------------------------------------------------------------------------------------------------\n",
      "2020-02-05 13:14:16,321 EPOCH 1 done: loss 0.1410 - lr 0.1000\n",
      "2020-02-05 13:21:30,314 DEV : loss 0.04426131024956703 - score 0.9787\n",
      "2020-02-05 13:21:30,367 BAD EPOCHS (no improvement): 0\n",
      "2020-02-05 13:21:31,996 ----------------------------------------------------------------------------------------------------\n",
      "2020-02-05 13:21:32,433 epoch 2 - iter 0/130 - loss 0.00398427 - samples/sec: 958.57\n",
      "2020-02-05 13:21:35,849 epoch 2 - iter 13/130 - loss 0.05015692 - samples/sec: 176.58\n",
      "2020-02-05 13:21:39,163 epoch 2 - iter 26/130 - loss 0.06306360 - samples/sec: 181.59\n",
      "2020-02-05 13:21:42,261 epoch 2 - iter 39/130 - loss 0.06220027 - samples/sec: 199.24\n",
      "2020-02-05 13:21:45,531 epoch 2 - iter 52/130 - loss 0.06104612 - samples/sec: 184.16\n",
      "2020-02-05 13:21:49,736 epoch 2 - iter 65/130 - loss 0.06485906 - samples/sec: 193.68\n",
      "2020-02-05 13:21:52,714 epoch 2 - iter 78/130 - loss 0.05973320 - samples/sec: 215.33\n",
      "2020-02-05 13:21:55,754 epoch 2 - iter 91/130 - loss 0.05992873 - samples/sec: 223.54\n",
      "2020-02-05 13:21:58,571 epoch 2 - iter 104/130 - loss 0.05769643 - samples/sec: 233.19\n",
      "2020-02-05 13:22:01,615 epoch 2 - iter 117/130 - loss 0.05420680 - samples/sec: 212.58\n",
      "2020-02-05 13:22:04,661 ----------------------------------------------------------------------------------------------------\n",
      "2020-02-05 13:22:04,663 EPOCH 2 done: loss 0.0676 - lr 0.1000\n",
      "2020-02-05 13:22:07,171 DEV : loss 0.03448297455906868 - score 0.9884\n",
      "2020-02-05 13:22:07,224 BAD EPOCHS (no improvement): 0\n",
      "2020-02-05 13:22:08,862 ----------------------------------------------------------------------------------------------------\n",
      "2020-02-05 13:22:09,005 epoch 3 - iter 0/130 - loss 0.05822431 - samples/sec: 2971.56\n",
      "2020-02-05 13:22:13,807 epoch 3 - iter 13/130 - loss 0.04093640 - samples/sec: 201.95\n",
      "2020-02-05 13:22:17,243 epoch 3 - iter 26/130 - loss 0.06450772 - samples/sec: 177.56\n",
      "2020-02-05 13:22:20,527 epoch 3 - iter 39/130 - loss 0.06448243 - samples/sec: 182.70\n",
      "2020-02-05 13:22:23,622 epoch 3 - iter 52/130 - loss 0.06195039 - samples/sec: 200.20\n",
      "2020-02-05 13:22:26,771 epoch 3 - iter 65/130 - loss 0.05953893 - samples/sec: 194.04\n",
      "2020-02-05 13:22:30,000 epoch 3 - iter 78/130 - loss 0.05323364 - samples/sec: 191.59\n",
      "2020-02-05 13:22:33,289 epoch 3 - iter 91/130 - loss 0.04984887 - samples/sec: 184.81\n",
      "2020-02-05 13:22:36,233 epoch 3 - iter 104/130 - loss 0.04667223 - samples/sec: 210.96\n",
      "2020-02-05 13:22:39,200 epoch 3 - iter 117/130 - loss 0.04619105 - samples/sec: 209.58\n",
      "2020-02-05 13:22:42,187 ----------------------------------------------------------------------------------------------------\n",
      "2020-02-05 13:22:42,188 EPOCH 3 done: loss 0.0458 - lr 0.1000\n",
      "2020-02-05 13:22:44,652 DEV : loss 0.0319291315972805 - score 0.9903\n",
      "2020-02-05 13:22:44,704 BAD EPOCHS (no improvement): 0\n",
      "2020-02-05 13:22:46,655 ----------------------------------------------------------------------------------------------------\n",
      "2020-02-05 13:22:46,848 epoch 4 - iter 0/130 - loss 0.03007026 - samples/sec: 2178.10\n",
      "2020-02-05 13:22:50,156 epoch 4 - iter 13/130 - loss 0.03007645 - samples/sec: 185.97\n",
      "2020-02-05 13:22:53,801 epoch 4 - iter 26/130 - loss 0.02631526 - samples/sec: 158.42\n",
      "2020-02-05 13:22:56,965 epoch 4 - iter 39/130 - loss 0.03582374 - samples/sec: 193.05\n",
      "2020-02-05 13:23:00,144 epoch 4 - iter 52/130 - loss 0.04068153 - samples/sec: 192.42\n",
      "2020-02-05 13:23:04,120 epoch 4 - iter 65/130 - loss 0.04905018 - samples/sec: 206.36\n",
      "2020-02-05 13:23:07,376 epoch 4 - iter 78/130 - loss 0.04793455 - samples/sec: 188.24\n",
      "2020-02-05 13:23:10,506 epoch 4 - iter 91/130 - loss 0.04529718 - samples/sec: 202.84\n",
      "2020-02-05 13:23:13,344 epoch 4 - iter 104/130 - loss 0.04235666 - samples/sec: 225.36\n",
      "2020-02-05 13:23:16,294 epoch 4 - iter 117/130 - loss 0.04529386 - samples/sec: 213.34\n",
      "2020-02-05 13:23:19,377 ----------------------------------------------------------------------------------------------------\n",
      "2020-02-05 13:23:19,379 EPOCH 4 done: loss 0.0415 - lr 0.1000\n",
      "2020-02-05 13:23:21,790 DEV : loss 0.03912024572491646 - score 0.9865\n",
      "2020-02-05 13:23:21,843 BAD EPOCHS (no improvement): 1\n",
      "2020-02-05 13:23:21,845 ----------------------------------------------------------------------------------------------------\n",
      "2020-02-05 13:23:21,968 epoch 5 - iter 0/130 - loss 0.00105070 - samples/sec: 3438.20\n",
      "2020-02-05 13:23:25,087 epoch 5 - iter 13/130 - loss 0.01610229 - samples/sec: 202.44\n",
      "2020-02-05 13:23:28,337 epoch 5 - iter 26/130 - loss 0.01912551 - samples/sec: 186.72\n",
      "2020-02-05 13:23:31,950 epoch 5 - iter 39/130 - loss 0.02055335 - samples/sec: 159.21\n",
      "2020-02-05 13:23:35,132 epoch 5 - iter 52/130 - loss 0.02098653 - samples/sec: 195.31\n",
      "2020-02-05 13:23:38,091 epoch 5 - iter 65/130 - loss 0.02362517 - samples/sec: 215.89\n",
      "2020-02-05 13:23:40,995 epoch 5 - iter 78/130 - loss 0.02434033 - samples/sec: 218.50\n",
      "2020-02-05 13:23:44,010 epoch 5 - iter 91/130 - loss 0.02322546 - samples/sec: 213.78\n",
      "2020-02-05 13:23:47,374 epoch 5 - iter 104/130 - loss 0.02653853 - samples/sec: 179.78\n",
      "2020-02-05 13:23:50,579 epoch 5 - iter 117/130 - loss 0.02789383 - samples/sec: 188.16\n",
      "2020-02-05 13:23:53,251 ----------------------------------------------------------------------------------------------------\n",
      "2020-02-05 13:23:53,252 EPOCH 5 done: loss 0.0340 - lr 0.1000\n",
      "2020-02-05 13:23:55,769 DEV : loss 0.03320218622684479 - score 0.9903\n",
      "2020-02-05 13:23:55,822 BAD EPOCHS (no improvement): 2\n",
      "2020-02-05 13:23:57,071 ----------------------------------------------------------------------------------------------------\n",
      "2020-02-05 13:23:57,314 epoch 6 - iter 0/130 - loss 0.00266711 - samples/sec: 1733.41\n",
      "2020-02-05 13:24:01,088 epoch 6 - iter 13/130 - loss 0.03252829 - samples/sec: 191.89\n",
      "2020-02-05 13:24:04,039 epoch 6 - iter 26/130 - loss 0.02793389 - samples/sec: 216.34\n",
      "2020-02-05 13:24:07,111 epoch 6 - iter 39/130 - loss 0.02304976 - samples/sec: 201.95\n",
      "2020-02-05 13:24:10,290 epoch 6 - iter 52/130 - loss 0.03241253 - samples/sec: 194.76\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-02-05 13:24:14,552 epoch 6 - iter 65/130 - loss 0.02946567 - samples/sec: 165.94\n",
      "2020-02-05 13:24:17,693 epoch 6 - iter 78/130 - loss 0.02858129 - samples/sec: 197.63\n",
      "2020-02-05 13:24:20,924 epoch 6 - iter 91/130 - loss 0.02539814 - samples/sec: 186.81\n",
      "2020-02-05 13:24:23,934 epoch 6 - iter 104/130 - loss 0.02670084 - samples/sec: 211.71\n",
      "2020-02-05 13:24:27,804 epoch 6 - iter 117/130 - loss 0.02652813 - samples/sec: 172.84\n",
      "2020-02-05 13:24:30,590 ----------------------------------------------------------------------------------------------------\n",
      "2020-02-05 13:24:30,591 EPOCH 6 done: loss 0.0291 - lr 0.1000\n",
      "2020-02-05 13:24:33,019 DEV : loss 0.030898086726665497 - score 0.9884\n",
      "2020-02-05 13:24:33,072 BAD EPOCHS (no improvement): 3\n",
      "2020-02-05 13:24:33,075 ----------------------------------------------------------------------------------------------------\n",
      "2020-02-05 13:24:33,215 epoch 7 - iter 0/130 - loss 0.03034712 - samples/sec: 3036.63\n",
      "2020-02-05 13:24:36,146 epoch 7 - iter 13/130 - loss 0.03007791 - samples/sec: 215.22\n",
      "2020-02-05 13:24:39,442 epoch 7 - iter 26/130 - loss 0.02424228 - samples/sec: 188.93\n",
      "2020-02-05 13:24:42,784 epoch 7 - iter 39/130 - loss 0.02168190 - samples/sec: 182.70\n",
      "2020-02-05 13:24:45,552 epoch 7 - iter 52/130 - loss 0.02239117 - samples/sec: 235.17\n",
      "2020-02-05 13:24:48,884 epoch 7 - iter 65/130 - loss 0.02450946 - samples/sec: 176.28\n",
      "2020-02-05 13:24:51,848 epoch 7 - iter 78/130 - loss 0.02342706 - samples/sec: 215.33\n",
      "2020-02-05 13:24:54,766 epoch 7 - iter 91/130 - loss 0.02135840 - samples/sec: 230.86\n",
      "2020-02-05 13:24:58,792 epoch 7 - iter 104/130 - loss 0.02314570 - samples/sec: 152.11\n",
      "2020-02-05 13:25:01,731 epoch 7 - iter 117/130 - loss 0.02349184 - samples/sec: 218.38\n",
      "2020-02-05 13:25:04,567 ----------------------------------------------------------------------------------------------------\n",
      "2020-02-05 13:25:04,569 EPOCH 7 done: loss 0.0223 - lr 0.1000\n",
      "2020-02-05 13:25:07,013 DEV : loss 0.034008655697107315 - score 0.9903\n",
      "Epoch     6: reducing learning rate of group 0 to 5.0000e-02.\n",
      "2020-02-05 13:25:07,067 BAD EPOCHS (no improvement): 4\n",
      "2020-02-05 13:25:08,766 ----------------------------------------------------------------------------------------------------\n",
      "2020-02-05 13:25:08,900 epoch 8 - iter 0/130 - loss 0.02145964 - samples/sec: 3175.74\n",
      "2020-02-05 13:25:11,873 epoch 8 - iter 13/130 - loss 0.01293620 - samples/sec: 217.01\n",
      "2020-02-05 13:25:14,922 epoch 8 - iter 26/130 - loss 0.01783479 - samples/sec: 207.80\n",
      "2020-02-05 13:25:18,411 epoch 8 - iter 39/130 - loss 0.01643057 - samples/sec: 222.23\n",
      "2020-02-05 13:25:21,780 epoch 8 - iter 52/130 - loss 0.01685946 - samples/sec: 175.31\n",
      "2020-02-05 13:25:25,488 epoch 8 - iter 65/130 - loss 0.01505983 - samples/sec: 208.11\n",
      "2020-02-05 13:25:28,766 epoch 8 - iter 78/130 - loss 0.01392640 - samples/sec: 187.23\n",
      "2020-02-05 13:25:32,378 epoch 8 - iter 91/130 - loss 0.01243374 - samples/sec: 166.34\n",
      "2020-02-05 13:25:35,707 epoch 8 - iter 104/130 - loss 0.01307330 - samples/sec: 178.09\n",
      "2020-02-05 13:25:38,743 epoch 8 - iter 117/130 - loss 0.01412434 - samples/sec: 210.32\n",
      "2020-02-05 13:25:41,680 ----------------------------------------------------------------------------------------------------\n",
      "2020-02-05 13:25:41,681 EPOCH 8 done: loss 0.0138 - lr 0.0500\n",
      "2020-02-05 13:25:44,130 DEV : loss 0.032844994217157364 - score 0.9903\n",
      "2020-02-05 13:25:44,183 BAD EPOCHS (no improvement): 1\n",
      "2020-02-05 13:25:45,410 ----------------------------------------------------------------------------------------------------\n",
      "2020-02-05 13:25:45,633 epoch 9 - iter 0/130 - loss 0.10162590 - samples/sec: 1891.00\n",
      "2020-02-05 13:25:49,805 epoch 9 - iter 13/130 - loss 0.01459070 - samples/sec: 229.84\n",
      "2020-02-05 13:25:53,135 epoch 9 - iter 26/130 - loss 0.01218153 - samples/sec: 180.33\n",
      "2020-02-05 13:25:56,401 epoch 9 - iter 39/130 - loss 0.01436292 - samples/sec: 185.14\n",
      "2020-02-05 13:25:59,345 epoch 9 - iter 52/130 - loss 0.01586153 - samples/sec: 214.77\n",
      "2020-02-05 13:26:02,315 epoch 9 - iter 65/130 - loss 0.01389427 - samples/sec: 210.00\n",
      "2020-02-05 13:26:05,884 epoch 9 - iter 78/130 - loss 0.01215413 - samples/sec: 169.39\n",
      "2020-02-05 13:26:08,641 epoch 9 - iter 91/130 - loss 0.01106283 - samples/sec: 237.18\n",
      "2020-02-05 13:26:11,953 epoch 9 - iter 104/130 - loss 0.01040033 - samples/sec: 186.64\n",
      "2020-02-05 13:26:14,971 epoch 9 - iter 117/130 - loss 0.00989792 - samples/sec: 213.12\n",
      "2020-02-05 13:26:17,951 ----------------------------------------------------------------------------------------------------\n",
      "2020-02-05 13:26:17,953 EPOCH 9 done: loss 0.0116 - lr 0.0500\n",
      "2020-02-05 13:26:20,371 DEV : loss 0.03262094035744667 - score 0.9903\n",
      "2020-02-05 13:26:20,425 BAD EPOCHS (no improvement): 2\n",
      "2020-02-05 13:26:21,731 ----------------------------------------------------------------------------------------------------\n",
      "2020-02-05 13:26:21,866 epoch 10 - iter 0/130 - loss 0.00057620 - samples/sec: 3151.68\n",
      "2020-02-05 13:26:24,993 epoch 10 - iter 13/130 - loss 0.00536233 - samples/sec: 200.39\n",
      "2020-02-05 13:26:28,078 epoch 10 - iter 26/130 - loss 0.00358048 - samples/sec: 201.66\n",
      "2020-02-05 13:26:31,648 epoch 10 - iter 39/130 - loss 0.00497048 - samples/sec: 163.40\n",
      "2020-02-05 13:26:34,715 epoch 10 - iter 52/130 - loss 0.00741177 - samples/sec: 202.84\n",
      "2020-02-05 13:26:37,777 epoch 10 - iter 65/130 - loss 0.00745264 - samples/sec: 204.23\n",
      "2020-02-05 13:26:41,094 epoch 10 - iter 78/130 - loss 0.00678492 - samples/sec: 186.22\n",
      "2020-02-05 13:26:44,942 epoch 10 - iter 91/130 - loss 0.00649817 - samples/sec: 147.47\n",
      "2020-02-05 13:26:47,992 epoch 10 - iter 104/130 - loss 0.00722301 - samples/sec: 208.53\n",
      "2020-02-05 13:26:50,952 epoch 10 - iter 117/130 - loss 0.00786502 - samples/sec: 214.00\n",
      "2020-02-05 13:26:53,584 ----------------------------------------------------------------------------------------------------\n",
      "2020-02-05 13:26:53,585 EPOCH 10 done: loss 0.0081 - lr 0.0500\n",
      "2020-02-05 13:26:56,099 DEV : loss 0.03389938175678253 - score 0.9903\n",
      "2020-02-05 13:26:56,153 BAD EPOCHS (no improvement): 3\n",
      "2020-02-05 13:26:57,379 ----------------------------------------------------------------------------------------------------\n",
      "2020-02-05 13:26:57,498 epoch 11 - iter 0/130 - loss 0.00033169 - samples/sec: 3587.85\n",
      "2020-02-05 13:27:00,944 epoch 11 - iter 13/130 - loss 0.00479429 - samples/sec: 173.05\n",
      "2020-02-05 13:27:04,562 epoch 11 - iter 26/130 - loss 0.00395324 - samples/sec: 205.95\n",
      "2020-02-05 13:27:07,410 epoch 11 - iter 39/130 - loss 0.00438328 - samples/sec: 227.58\n",
      "2020-02-05 13:27:10,833 epoch 11 - iter 52/130 - loss 0.00476764 - samples/sec: 172.19\n",
      "2020-02-05 13:27:15,205 epoch 11 - iter 65/130 - loss 0.00793284 - samples/sec: 206.77\n",
      "2020-02-05 13:27:18,843 epoch 11 - iter 78/130 - loss 0.00844471 - samples/sec: 158.72\n",
      "2020-02-05 13:27:21,734 epoch 11 - iter 91/130 - loss 0.00790102 - samples/sec: 227.33\n",
      "2020-02-05 13:27:24,723 epoch 11 - iter 104/130 - loss 0.00745074 - samples/sec: 219.07\n",
      "2020-02-05 13:27:28,220 epoch 11 - iter 117/130 - loss 0.00689005 - samples/sec: 170.22\n",
      "2020-02-05 13:27:30,795 ----------------------------------------------------------------------------------------------------\n",
      "2020-02-05 13:27:30,796 EPOCH 11 done: loss 0.0072 - lr 0.0500\n",
      "2020-02-05 13:27:33,250 DEV : loss 0.03495383262634277 - score 0.9923\n",
      "2020-02-05 13:27:33,305 BAD EPOCHS (no improvement): 0\n",
      "2020-02-05 13:27:35,292 ----------------------------------------------------------------------------------------------------\n",
      "2020-02-05 13:27:35,409 epoch 12 - iter 0/130 - loss 0.00630938 - samples/sec: 3649.37\n",
      "2020-02-05 13:27:38,633 epoch 12 - iter 13/130 - loss 0.00619879 - samples/sec: 197.82\n",
      "2020-02-05 13:27:41,467 epoch 12 - iter 26/130 - loss 0.00822830 - samples/sec: 231.25\n",
      "2020-02-05 13:27:44,846 epoch 12 - iter 39/130 - loss 0.00605388 - samples/sec: 211.28\n",
      "2020-02-05 13:27:48,023 epoch 12 - iter 52/130 - loss 0.00638736 - samples/sec: 191.80\n",
      "2020-02-05 13:27:51,192 epoch 12 - iter 65/130 - loss 0.00671306 - samples/sec: 192.07\n",
      "2020-02-05 13:27:55,466 epoch 12 - iter 78/130 - loss 0.00678209 - samples/sec: 201.66\n",
      "2020-02-05 13:27:58,952 epoch 12 - iter 91/130 - loss 0.00621769 - samples/sec: 169.11\n",
      "2020-02-05 13:28:02,292 epoch 12 - iter 104/130 - loss 0.00587490 - samples/sec: 184.16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-02-05 13:28:05,676 epoch 12 - iter 117/130 - loss 0.00564355 - samples/sec: 174.57\n",
      "2020-02-05 13:28:08,285 ----------------------------------------------------------------------------------------------------\n",
      "2020-02-05 13:28:08,286 EPOCH 12 done: loss 0.0053 - lr 0.0500\n",
      "2020-02-05 13:28:10,774 DEV : loss 0.03522000089287758 - score 0.9923\n",
      "2020-02-05 13:28:10,827 BAD EPOCHS (no improvement): 1\n",
      "2020-02-05 13:28:12,107 ----------------------------------------------------------------------------------------------------\n",
      "2020-02-05 13:28:12,244 epoch 13 - iter 0/130 - loss 0.00019333 - samples/sec: 3081.60\n",
      "2020-02-05 13:28:16,628 epoch 13 - iter 13/130 - loss 0.00547391 - samples/sec: 189.27\n",
      "2020-02-05 13:28:19,973 epoch 13 - iter 26/130 - loss 0.00454156 - samples/sec: 178.35\n",
      "2020-02-05 13:28:23,165 epoch 13 - iter 39/130 - loss 0.00389808 - samples/sec: 192.33\n",
      "2020-02-05 13:28:26,203 epoch 13 - iter 52/130 - loss 0.00352896 - samples/sec: 206.77\n",
      "2020-02-05 13:28:30,025 epoch 13 - iter 65/130 - loss 0.00318504 - samples/sec: 201.74\n",
      "2020-02-05 13:28:33,063 epoch 13 - iter 78/130 - loss 0.00316349 - samples/sec: 212.58\n",
      "2020-02-05 13:28:36,047 epoch 13 - iter 91/130 - loss 0.00298603 - samples/sec: 215.33\n",
      "2020-02-05 13:28:39,399 epoch 13 - iter 104/130 - loss 0.00326081 - samples/sec: 181.04\n",
      "2020-02-05 13:28:42,467 epoch 13 - iter 117/130 - loss 0.00311550 - samples/sec: 201.37\n",
      "2020-02-05 13:28:45,760 ----------------------------------------------------------------------------------------------------\n",
      "2020-02-05 13:28:45,761 EPOCH 13 done: loss 0.0040 - lr 0.0500\n",
      "2020-02-05 13:28:48,200 DEV : loss 0.04029420018196106 - score 0.9903\n",
      "2020-02-05 13:28:48,253 BAD EPOCHS (no improvement): 2\n",
      "2020-02-05 13:28:48,255 ----------------------------------------------------------------------------------------------------\n",
      "2020-02-05 13:28:48,396 epoch 14 - iter 0/130 - loss 0.09296030 - samples/sec: 3014.63\n",
      "2020-02-05 13:28:51,443 epoch 14 - iter 13/130 - loss 0.01119183 - samples/sec: 205.85\n",
      "2020-02-05 13:28:54,892 epoch 14 - iter 26/130 - loss 0.00843427 - samples/sec: 169.73\n",
      "2020-02-05 13:28:58,175 epoch 14 - iter 39/130 - loss 0.00620284 - samples/sec: 184.81\n",
      "2020-02-05 13:29:01,104 epoch 14 - iter 52/130 - loss 0.00559706 - samples/sec: 217.24\n",
      "2020-02-05 13:29:04,502 epoch 14 - iter 65/130 - loss 0.00512641 - samples/sec: 172.55\n",
      "2020-02-05 13:29:07,815 epoch 14 - iter 78/130 - loss 0.00462461 - samples/sec: 181.11\n",
      "2020-02-05 13:29:10,968 epoch 14 - iter 91/130 - loss 0.00508473 - samples/sec: 194.22\n",
      "2020-02-05 13:29:14,114 epoch 14 - iter 104/130 - loss 0.00467413 - samples/sec: 191.35\n",
      "2020-02-05 13:29:16,983 epoch 14 - iter 117/130 - loss 0.00432139 - samples/sec: 226.34\n",
      "2020-02-05 13:29:19,742 ----------------------------------------------------------------------------------------------------\n",
      "2020-02-05 13:29:19,743 EPOCH 14 done: loss 0.0041 - lr 0.0500\n",
      "2020-02-05 13:29:22,224 DEV : loss 0.04196316748857498 - score 0.9923\n",
      "2020-02-05 13:29:22,277 BAD EPOCHS (no improvement): 3\n",
      "2020-02-05 13:29:24,172 ----------------------------------------------------------------------------------------------------\n",
      "2020-02-05 13:29:24,404 epoch 15 - iter 0/130 - loss 0.00035419 - samples/sec: 1816.67\n",
      "2020-02-05 13:29:27,688 epoch 15 - iter 13/130 - loss 0.00251501 - samples/sec: 189.10\n",
      "2020-02-05 13:29:30,806 epoch 15 - iter 26/130 - loss 0.00179327 - samples/sec: 198.39\n",
      "2020-02-05 13:29:34,298 epoch 15 - iter 39/130 - loss 0.00219638 - samples/sec: 169.25\n",
      "2020-02-05 13:29:38,629 epoch 15 - iter 52/130 - loss 0.00201392 - samples/sec: 156.69\n",
      "2020-02-05 13:29:42,328 epoch 15 - iter 65/130 - loss 0.00209144 - samples/sec: 164.43\n",
      "2020-02-05 13:29:45,476 epoch 15 - iter 78/130 - loss 0.00236081 - samples/sec: 194.77\n",
      "2020-02-05 13:29:48,288 epoch 15 - iter 91/130 - loss 0.00242839 - samples/sec: 237.45\n",
      "2020-02-05 13:29:51,542 epoch 15 - iter 104/130 - loss 0.00240251 - samples/sec: 190.48\n",
      "2020-02-05 13:29:54,332 epoch 15 - iter 117/130 - loss 0.00260862 - samples/sec: 235.29\n",
      "2020-02-05 13:29:57,182 ----------------------------------------------------------------------------------------------------\n",
      "2020-02-05 13:29:57,183 EPOCH 15 done: loss 0.0028 - lr 0.0500\n",
      "2020-02-05 13:29:59,641 DEV : loss 0.04252089932560921 - score 0.9923\n",
      "Epoch    14: reducing learning rate of group 0 to 2.5000e-02.\n",
      "2020-02-05 13:29:59,696 BAD EPOCHS (no improvement): 4\n",
      "2020-02-05 13:30:00,923 ----------------------------------------------------------------------------------------------------\n",
      "2020-02-05 13:30:01,073 epoch 16 - iter 0/130 - loss 0.00011379 - samples/sec: 2810.95\n",
      "2020-02-05 13:30:05,260 epoch 16 - iter 13/130 - loss 0.00098334 - samples/sec: 172.98\n",
      "2020-02-05 13:30:08,641 epoch 16 - iter 26/130 - loss 0.00123863 - samples/sec: 180.41\n",
      "2020-02-05 13:30:12,017 epoch 16 - iter 39/130 - loss 0.00211833 - samples/sec: 179.55\n",
      "2020-02-05 13:30:14,899 epoch 16 - iter 52/130 - loss 0.00207703 - samples/sec: 220.46\n",
      "2020-02-05 13:30:19,282 epoch 16 - iter 65/130 - loss 0.00208335 - samples/sec: 221.88\n",
      "2020-02-05 13:30:22,907 epoch 16 - iter 78/130 - loss 0.00193835 - samples/sec: 162.82\n",
      "2020-02-05 13:30:26,034 epoch 16 - iter 91/130 - loss 0.00199358 - samples/sec: 199.62\n",
      "2020-02-05 13:30:28,901 epoch 16 - iter 104/130 - loss 0.00191640 - samples/sec: 225.73\n",
      "2020-02-05 13:30:32,173 epoch 16 - iter 117/130 - loss 0.00194552 - samples/sec: 182.30\n",
      "2020-02-05 13:30:34,765 ----------------------------------------------------------------------------------------------------\n",
      "2020-02-05 13:30:34,767 EPOCH 16 done: loss 0.0019 - lr 0.0250\n",
      "2020-02-05 13:30:37,220 DEV : loss 0.04350689426064491 - score 0.9923\n",
      "2020-02-05 13:30:37,273 BAD EPOCHS (no improvement): 1\n",
      "2020-02-05 13:30:38,462 ----------------------------------------------------------------------------------------------------\n",
      "2020-02-05 13:30:38,628 epoch 17 - iter 0/130 - loss 0.00074431 - samples/sec: 2536.70\n",
      "2020-02-05 13:30:41,412 epoch 17 - iter 13/130 - loss 0.00165133 - samples/sec: 239.50\n",
      "2020-02-05 13:30:47,031 epoch 17 - iter 26/130 - loss 0.00140107 - samples/sec: 153.28\n",
      "2020-02-05 13:30:49,971 epoch 17 - iter 39/130 - loss 0.00135703 - samples/sec: 215.66\n",
      "2020-02-05 13:30:52,805 epoch 17 - iter 52/130 - loss 0.00133865 - samples/sec: 228.45\n",
      "2020-02-05 13:30:56,454 epoch 17 - iter 65/130 - loss 0.00243194 - samples/sec: 176.35\n",
      "2020-02-05 13:31:00,051 epoch 17 - iter 78/130 - loss 0.00220627 - samples/sec: 162.00\n",
      "2020-02-05 13:31:03,137 epoch 17 - iter 91/130 - loss 0.00204429 - samples/sec: 199.72\n",
      "2020-02-05 13:31:06,447 epoch 17 - iter 104/130 - loss 0.00189355 - samples/sec: 180.96\n",
      "2020-02-05 13:31:09,314 epoch 17 - iter 117/130 - loss 0.00175575 - samples/sec: 229.84\n",
      "2020-02-05 13:31:12,261 ----------------------------------------------------------------------------------------------------\n",
      "2020-02-05 13:31:12,263 EPOCH 17 done: loss 0.0018 - lr 0.0250\n",
      "2020-02-05 13:31:14,700 DEV : loss 0.043924733996391296 - score 0.9923\n",
      "2020-02-05 13:31:14,753 BAD EPOCHS (no improvement): 2\n",
      "2020-02-05 13:31:16,588 ----------------------------------------------------------------------------------------------------\n",
      "2020-02-05 13:31:16,732 epoch 18 - iter 0/130 - loss 0.00004356 - samples/sec: 2971.54\n",
      "2020-02-05 13:31:20,182 epoch 18 - iter 13/130 - loss 0.00126524 - samples/sec: 174.58\n",
      "2020-02-05 13:31:23,199 epoch 18 - iter 26/130 - loss 0.00093738 - samples/sec: 211.07\n",
      "2020-02-05 13:31:27,494 epoch 18 - iter 39/130 - loss 0.00128035 - samples/sec: 192.69\n",
      "2020-02-05 13:31:30,508 epoch 18 - iter 52/130 - loss 0.00116638 - samples/sec: 215.44\n",
      "2020-02-05 13:31:33,844 epoch 18 - iter 65/130 - loss 0.00130649 - samples/sec: 200.68\n",
      "2020-02-05 13:31:36,903 epoch 18 - iter 78/130 - loss 0.00204741 - samples/sec: 205.85\n",
      "2020-02-05 13:31:40,529 epoch 18 - iter 91/130 - loss 0.00222378 - samples/sec: 161.31\n",
      "2020-02-05 13:31:43,801 epoch 18 - iter 104/130 - loss 0.00211132 - samples/sec: 183.75\n",
      "2020-02-05 13:31:46,985 epoch 18 - iter 117/130 - loss 0.00190033 - samples/sec: 196.33\n",
      "2020-02-05 13:31:49,687 ----------------------------------------------------------------------------------------------------\n",
      "2020-02-05 13:31:49,689 EPOCH 18 done: loss 0.0022 - lr 0.0250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-02-05 13:31:52,113 DEV : loss 0.04422296583652496 - score 0.9923\n",
      "2020-02-05 13:31:52,165 BAD EPOCHS (no improvement): 3\n",
      "2020-02-05 13:31:54,536 ----------------------------------------------------------------------------------------------------\n",
      "2020-02-05 13:31:54,692 epoch 19 - iter 0/130 - loss 0.00067902 - samples/sec: 2719.10\n",
      "2020-02-05 13:31:58,001 epoch 19 - iter 13/130 - loss 0.00070256 - samples/sec: 197.44\n",
      "2020-02-05 13:32:01,035 epoch 19 - iter 26/130 - loss 0.00091576 - samples/sec: 211.07\n",
      "2020-02-05 13:32:04,250 epoch 19 - iter 39/130 - loss 0.00089156 - samples/sec: 190.57\n",
      "2020-02-05 13:32:07,812 epoch 19 - iter 52/130 - loss 0.00098588 - samples/sec: 162.70\n",
      "2020-02-05 13:32:11,421 epoch 19 - iter 65/130 - loss 0.00119559 - samples/sec: 159.88\n",
      "2020-02-05 13:32:14,554 epoch 19 - iter 78/130 - loss 0.00117425 - samples/sec: 199.82\n",
      "2020-02-05 13:32:17,516 epoch 19 - iter 91/130 - loss 0.00107266 - samples/sec: 212.36\n",
      "2020-02-05 13:32:20,623 epoch 19 - iter 104/130 - loss 0.00124377 - samples/sec: 221.17\n",
      "2020-02-05 13:32:23,878 epoch 19 - iter 117/130 - loss 0.00124458 - samples/sec: 185.56\n",
      "2020-02-05 13:32:26,515 ----------------------------------------------------------------------------------------------------\n",
      "2020-02-05 13:32:26,516 EPOCH 19 done: loss 0.0013 - lr 0.0250\n",
      "2020-02-05 13:32:28,916 DEV : loss 0.04508279263973236 - score 0.9923\n",
      "Epoch    18: reducing learning rate of group 0 to 1.2500e-02.\n",
      "2020-02-05 13:32:28,970 BAD EPOCHS (no improvement): 4\n",
      "2020-02-05 13:32:30,218 ----------------------------------------------------------------------------------------------------\n",
      "2020-02-05 13:32:30,348 epoch 20 - iter 0/130 - loss 0.00111536 - samples/sec: 3250.16\n",
      "2020-02-05 13:32:34,465 epoch 20 - iter 13/130 - loss 0.00289925 - samples/sec: 216.90\n",
      "2020-02-05 13:32:37,970 epoch 20 - iter 26/130 - loss 0.00197396 - samples/sec: 184.16\n",
      "2020-02-05 13:32:41,338 epoch 20 - iter 39/130 - loss 0.00189955 - samples/sec: 177.33\n",
      "2020-02-05 13:32:44,607 epoch 20 - iter 52/130 - loss 0.00162508 - samples/sec: 185.23\n",
      "2020-02-05 13:32:48,048 epoch 20 - iter 65/130 - loss 0.00143802 - samples/sec: 176.65\n",
      "2020-02-05 13:32:50,808 epoch 20 - iter 78/130 - loss 0.00176669 - samples/sec: 236.64\n",
      "2020-02-05 13:32:53,695 epoch 20 - iter 91/130 - loss 0.00187453 - samples/sec: 220.00\n",
      "2020-02-05 13:32:57,169 epoch 20 - iter 104/130 - loss 0.00187242 - samples/sec: 171.06\n",
      "2020-02-05 13:33:00,049 epoch 20 - iter 117/130 - loss 0.00177334 - samples/sec: 222.83\n",
      "2020-02-05 13:33:02,757 ----------------------------------------------------------------------------------------------------\n",
      "2020-02-05 13:33:02,758 EPOCH 20 done: loss 0.0017 - lr 0.0125\n",
      "2020-02-05 13:33:05,172 DEV : loss 0.04523756727576256 - score 0.9923\n",
      "2020-02-05 13:33:05,225 BAD EPOCHS (no improvement): 1\n",
      "2020-02-05 13:33:06,895 ----------------------------------------------------------------------------------------------------\n",
      "2020-02-05 13:33:07,049 epoch 21 - iter 0/130 - loss 0.00024457 - samples/sec: 2738.59\n",
      "2020-02-05 13:33:10,113 epoch 21 - iter 13/130 - loss 0.00035924 - samples/sec: 207.01\n",
      "2020-02-05 13:33:13,417 epoch 21 - iter 26/130 - loss 0.00086595 - samples/sec: 184.98\n",
      "2020-02-05 13:33:16,562 epoch 21 - iter 39/130 - loss 0.00121562 - samples/sec: 196.88\n",
      "2020-02-05 13:33:19,887 epoch 21 - iter 52/130 - loss 0.00123172 - samples/sec: 180.17\n",
      "2020-02-05 13:33:23,923 epoch 21 - iter 65/130 - loss 0.00112617 - samples/sec: 196.05\n",
      "2020-02-05 13:33:27,252 epoch 21 - iter 78/130 - loss 0.00114105 - samples/sec: 179.01\n",
      "2020-02-05 13:33:30,231 epoch 21 - iter 91/130 - loss 0.00107514 - samples/sec: 210.53\n",
      "2020-02-05 13:33:33,053 epoch 21 - iter 104/130 - loss 0.00104669 - samples/sec: 232.89\n",
      "2020-02-05 13:33:36,356 epoch 21 - iter 117/130 - loss 0.00128640 - samples/sec: 182.38\n",
      "2020-02-05 13:33:39,384 ----------------------------------------------------------------------------------------------------\n",
      "2020-02-05 13:33:39,385 EPOCH 21 done: loss 0.0014 - lr 0.0125\n",
      "2020-02-05 13:33:41,863 DEV : loss 0.04591798409819603 - score 0.9923\n",
      "2020-02-05 13:33:41,917 BAD EPOCHS (no improvement): 2\n",
      "2020-02-05 13:33:43,124 ----------------------------------------------------------------------------------------------------\n",
      "2020-02-05 13:33:43,273 epoch 22 - iter 0/130 - loss 0.00025697 - samples/sec: 2849.44\n",
      "2020-02-05 13:33:47,172 epoch 22 - iter 13/130 - loss 0.00142227 - samples/sec: 183.67\n",
      "2020-02-05 13:33:50,690 epoch 22 - iter 26/130 - loss 0.00129684 - samples/sec: 167.08\n",
      "2020-02-05 13:33:53,975 epoch 22 - iter 39/130 - loss 0.00111675 - samples/sec: 183.27\n",
      "2020-02-05 13:33:57,011 epoch 22 - iter 52/130 - loss 0.00110954 - samples/sec: 206.77\n",
      "2020-02-05 13:34:00,767 epoch 22 - iter 65/130 - loss 0.00135842 - samples/sec: 211.28\n",
      "2020-02-05 13:34:03,710 epoch 22 - iter 78/130 - loss 0.00121911 - samples/sec: 215.00\n",
      "2020-02-05 13:34:06,730 epoch 22 - iter 91/130 - loss 0.00126469 - samples/sec: 210.75\n",
      "2020-02-05 13:34:09,670 epoch 22 - iter 104/130 - loss 0.00128600 - samples/sec: 221.99\n",
      "2020-02-05 13:34:12,609 epoch 22 - iter 117/130 - loss 0.00139634 - samples/sec: 215.22\n",
      "2020-02-05 13:34:15,827 ----------------------------------------------------------------------------------------------------\n",
      "2020-02-05 13:34:15,828 EPOCH 22 done: loss 0.0013 - lr 0.0125\n",
      "2020-02-05 13:34:18,338 DEV : loss 0.04609553515911102 - score 0.9923\n",
      "2020-02-05 13:34:18,391 BAD EPOCHS (no improvement): 3\n",
      "2020-02-05 13:34:19,954 ----------------------------------------------------------------------------------------------------\n",
      "2020-02-05 13:34:20,415 epoch 23 - iter 0/130 - loss 0.00008318 - samples/sec: 908.70\n",
      "2020-02-05 13:34:23,888 epoch 23 - iter 13/130 - loss 0.00087065 - samples/sec: 171.13\n",
      "2020-02-05 13:34:27,367 epoch 23 - iter 26/130 - loss 0.00098446 - samples/sec: 170.94\n",
      "2020-02-05 13:34:30,107 epoch 23 - iter 39/130 - loss 0.00097873 - samples/sec: 242.72\n",
      "2020-02-05 13:34:36,767 epoch 23 - iter 52/130 - loss 0.00083674 - samples/sec: 193.41\n",
      "2020-02-05 13:34:39,617 epoch 23 - iter 65/130 - loss 0.00087613 - samples/sec: 225.73\n",
      "2020-02-05 13:34:42,835 epoch 23 - iter 78/130 - loss 0.00084226 - samples/sec: 188.16\n",
      "2020-02-05 13:34:46,328 epoch 23 - iter 91/130 - loss 0.00086559 - samples/sec: 169.11\n",
      "2020-02-05 13:34:49,217 epoch 23 - iter 104/130 - loss 0.00086058 - samples/sec: 227.21\n",
      "2020-02-05 13:34:52,180 epoch 23 - iter 117/130 - loss 0.00098640 - samples/sec: 211.18\n",
      "2020-02-05 13:34:55,022 ----------------------------------------------------------------------------------------------------\n",
      "2020-02-05 13:34:55,023 EPOCH 23 done: loss 0.0010 - lr 0.0125\n",
      "2020-02-05 13:34:57,460 DEV : loss 0.046424515545368195 - score 0.9923\n",
      "Epoch    22: reducing learning rate of group 0 to 6.2500e-03.\n",
      "2020-02-05 13:34:57,514 BAD EPOCHS (no improvement): 4\n",
      "2020-02-05 13:34:58,685 ----------------------------------------------------------------------------------------------------\n",
      "2020-02-05 13:34:58,826 epoch 24 - iter 0/130 - loss 0.00064169 - samples/sec: 3014.63\n",
      "2020-02-05 13:35:02,162 epoch 24 - iter 13/130 - loss 0.00039303 - samples/sec: 182.30\n",
      "2020-02-05 13:35:05,105 epoch 24 - iter 26/130 - loss 0.00091077 - samples/sec: 218.73\n",
      "2020-02-05 13:35:09,669 epoch 24 - iter 39/130 - loss 0.00095912 - samples/sec: 200.49\n",
      "2020-02-05 13:35:12,766 epoch 24 - iter 52/130 - loss 0.00100043 - samples/sec: 199.72\n",
      "2020-02-05 13:35:15,757 epoch 24 - iter 65/130 - loss 0.00113298 - samples/sec: 216.00\n",
      "2020-02-05 13:35:18,686 epoch 24 - iter 78/130 - loss 0.00112008 - samples/sec: 222.35\n",
      "2020-02-05 13:35:21,893 epoch 24 - iter 91/130 - loss 0.00106620 - samples/sec: 192.07\n",
      "2020-02-05 13:35:25,239 epoch 24 - iter 104/130 - loss 0.00105976 - samples/sec: 178.39\n",
      "2020-02-05 13:35:28,868 epoch 24 - iter 117/130 - loss 0.00105134 - samples/sec: 158.73\n",
      "2020-02-05 13:35:31,779 ----------------------------------------------------------------------------------------------------\n",
      "2020-02-05 13:35:31,780 EPOCH 24 done: loss 0.0010 - lr 0.0063\n",
      "2020-02-05 13:35:34,173 DEV : loss 0.04677234962582588 - score 0.9923\n",
      "2020-02-05 13:35:34,226 BAD EPOCHS (no improvement): 1\n",
      "2020-02-05 13:35:35,447 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-02-05 13:35:35,619 epoch 25 - iter 0/130 - loss 0.00120317 - samples/sec: 2461.66\n",
      "2020-02-05 13:35:38,972 epoch 25 - iter 13/130 - loss 0.00030946 - samples/sec: 181.35\n",
      "2020-02-05 13:35:42,570 epoch 25 - iter 26/130 - loss 0.00070059 - samples/sec: 163.72\n",
      "2020-02-05 13:35:45,409 epoch 25 - iter 39/130 - loss 0.00080749 - samples/sec: 235.04\n",
      "2020-02-05 13:35:48,486 epoch 25 - iter 52/130 - loss 0.00087338 - samples/sec: 199.05\n",
      "2020-02-05 13:35:51,378 epoch 25 - iter 65/130 - loss 0.00085638 - samples/sec: 221.40\n",
      "2020-02-05 13:35:54,635 epoch 25 - iter 78/130 - loss 0.00110601 - samples/sec: 192.42\n",
      "2020-02-05 13:35:57,611 epoch 25 - iter 91/130 - loss 0.00110712 - samples/sec: 215.33\n",
      "2020-02-05 13:36:00,882 epoch 25 - iter 104/130 - loss 0.00114664 - samples/sec: 186.55\n",
      "2020-02-05 13:36:04,083 epoch 25 - iter 117/130 - loss 0.00112733 - samples/sec: 189.44\n",
      "2020-02-05 13:36:06,884 ----------------------------------------------------------------------------------------------------\n",
      "2020-02-05 13:36:06,885 EPOCH 25 done: loss 0.0012 - lr 0.0063\n",
      "2020-02-05 13:36:09,295 DEV : loss 0.046867143362760544 - score 0.9923\n",
      "2020-02-05 13:36:09,347 BAD EPOCHS (no improvement): 2\n",
      "2020-02-05 13:36:10,924 ----------------------------------------------------------------------------------------------------\n",
      "2020-02-05 13:36:11,107 epoch 26 - iter 0/130 - loss 0.00006680 - samples/sec: 2298.45\n",
      "2020-02-05 13:36:14,402 epoch 26 - iter 13/130 - loss 0.00077981 - samples/sec: 227.83\n",
      "2020-02-05 13:36:17,378 epoch 26 - iter 26/130 - loss 0.00071046 - samples/sec: 216.90\n",
      "2020-02-05 13:36:21,306 epoch 26 - iter 39/130 - loss 0.00201505 - samples/sec: 180.72\n",
      "2020-02-05 13:36:24,622 epoch 26 - iter 52/130 - loss 0.00163411 - samples/sec: 180.88\n",
      "2020-02-05 13:36:28,773 epoch 26 - iter 65/130 - loss 0.00165867 - samples/sec: 173.56\n",
      "2020-02-05 13:36:31,787 epoch 26 - iter 78/130 - loss 0.00146572 - samples/sec: 214.55\n",
      "2020-02-05 13:36:35,253 epoch 26 - iter 91/130 - loss 0.00154106 - samples/sec: 173.27\n",
      "2020-02-05 13:36:38,177 epoch 26 - iter 104/130 - loss 0.00154396 - samples/sec: 224.63\n",
      "2020-02-05 13:36:41,283 epoch 26 - iter 117/130 - loss 0.00162484 - samples/sec: 200.88\n",
      "2020-02-05 13:36:43,937 ----------------------------------------------------------------------------------------------------\n",
      "2020-02-05 13:36:43,938 EPOCH 26 done: loss 0.0016 - lr 0.0063\n",
      "2020-02-05 13:36:46,368 DEV : loss 0.046814776957035065 - score 0.9923\n",
      "2020-02-05 13:36:46,417 BAD EPOCHS (no improvement): 3\n",
      "2020-02-05 13:36:47,589 ----------------------------------------------------------------------------------------------------\n",
      "2020-02-05 13:36:47,810 epoch 27 - iter 0/130 - loss 0.00408055 - samples/sec: 1908.34\n",
      "2020-02-05 13:36:51,750 epoch 27 - iter 13/130 - loss 0.00142611 - samples/sec: 200.39\n",
      "2020-02-05 13:36:55,055 epoch 27 - iter 26/130 - loss 0.00113153 - samples/sec: 179.39\n",
      "2020-02-05 13:36:58,149 epoch 27 - iter 39/130 - loss 0.00111410 - samples/sec: 199.72\n",
      "2020-02-05 13:37:01,453 epoch 27 - iter 52/130 - loss 0.00115596 - samples/sec: 182.22\n",
      "2020-02-05 13:37:04,993 epoch 27 - iter 65/130 - loss 0.00161526 - samples/sec: 200.01\n",
      "2020-02-05 13:37:08,251 epoch 27 - iter 78/130 - loss 0.00161131 - samples/sec: 185.56\n",
      "2020-02-05 13:37:11,436 epoch 27 - iter 91/130 - loss 0.00150148 - samples/sec: 194.13\n",
      "2020-02-05 13:37:14,533 epoch 27 - iter 104/130 - loss 0.00142585 - samples/sec: 207.28\n",
      "2020-02-05 13:37:17,646 epoch 27 - iter 117/130 - loss 0.00132557 - samples/sec: 199.43\n",
      "2020-02-05 13:37:20,400 ----------------------------------------------------------------------------------------------------\n",
      "2020-02-05 13:37:20,402 EPOCH 27 done: loss 0.0012 - lr 0.0063\n",
      "2020-02-05 13:37:22,848 DEV : loss 0.04700230807065964 - score 0.9923\n",
      "Epoch    26: reducing learning rate of group 0 to 3.1250e-03.\n",
      "2020-02-05 13:37:22,902 BAD EPOCHS (no improvement): 4\n",
      "2020-02-05 13:37:24,059 ----------------------------------------------------------------------------------------------------\n",
      "2020-02-05 13:37:24,189 epoch 28 - iter 0/130 - loss 0.00005314 - samples/sec: 3250.16\n",
      "2020-02-05 13:37:27,472 epoch 28 - iter 13/130 - loss 0.00078962 - samples/sec: 188.50\n",
      "2020-02-05 13:37:33,055 epoch 28 - iter 26/130 - loss 0.00122525 - samples/sec: 181.27\n",
      "2020-02-05 13:37:36,491 epoch 28 - iter 39/130 - loss 0.00135934 - samples/sec: 171.41\n",
      "2020-02-05 13:37:39,955 epoch 28 - iter 52/130 - loss 0.00140720 - samples/sec: 170.57\n",
      "2020-02-05 13:37:43,062 epoch 28 - iter 65/130 - loss 0.00136919 - samples/sec: 213.67\n",
      "2020-02-05 13:37:46,170 epoch 28 - iter 78/130 - loss 0.00135535 - samples/sec: 200.01\n",
      "2020-02-05 13:37:49,035 epoch 28 - iter 91/130 - loss 0.00132296 - samples/sec: 224.51\n",
      "2020-02-05 13:37:52,052 epoch 28 - iter 104/130 - loss 0.00131538 - samples/sec: 206.43\n",
      "2020-02-05 13:37:55,188 epoch 28 - iter 117/130 - loss 0.00132390 - samples/sec: 201.66\n",
      "2020-02-05 13:37:57,763 ----------------------------------------------------------------------------------------------------\n",
      "2020-02-05 13:37:57,764 EPOCH 28 done: loss 0.0012 - lr 0.0031\n",
      "2020-02-05 13:38:00,224 DEV : loss 0.0473409965634346 - score 0.9923\n",
      "2020-02-05 13:38:00,276 BAD EPOCHS (no improvement): 1\n",
      "2020-02-05 13:38:01,446 ----------------------------------------------------------------------------------------------------\n",
      "2020-02-05 13:38:01,830 epoch 29 - iter 0/130 - loss 0.00006623 - samples/sec: 1089.05\n",
      "2020-02-05 13:38:05,138 epoch 29 - iter 13/130 - loss 0.00141383 - samples/sec: 180.33\n",
      "2020-02-05 13:38:08,422 epoch 29 - iter 26/130 - loss 0.00113370 - samples/sec: 181.11\n",
      "2020-02-05 13:38:11,421 epoch 29 - iter 39/130 - loss 0.00085537 - samples/sec: 211.93\n",
      "2020-02-05 13:38:14,761 epoch 29 - iter 52/130 - loss 0.00087833 - samples/sec: 181.98\n",
      "2020-02-05 13:38:17,652 epoch 29 - iter 65/130 - loss 0.00087556 - samples/sec: 217.81\n",
      "2020-02-05 13:38:20,741 epoch 29 - iter 78/130 - loss 0.00086282 - samples/sec: 197.91\n",
      "2020-02-05 13:38:24,006 epoch 29 - iter 91/130 - loss 0.00080654 - samples/sec: 186.72\n",
      "2020-02-05 13:38:27,176 epoch 29 - iter 104/130 - loss 0.00075816 - samples/sec: 193.23\n",
      "2020-02-05 13:38:30,011 epoch 29 - iter 117/130 - loss 0.00084950 - samples/sec: 224.39\n",
      "2020-02-05 13:38:32,819 ----------------------------------------------------------------------------------------------------\n",
      "2020-02-05 13:38:32,820 EPOCH 29 done: loss 0.0009 - lr 0.0031\n",
      "2020-02-05 13:38:35,296 DEV : loss 0.0474054254591465 - score 0.9923\n",
      "2020-02-05 13:38:35,349 BAD EPOCHS (no improvement): 2\n",
      "2020-02-05 13:38:36,531 ----------------------------------------------------------------------------------------------------\n",
      "2020-02-05 13:38:36,682 epoch 30 - iter 0/130 - loss 0.00244600 - samples/sec: 2810.94\n",
      "2020-02-05 13:38:40,243 epoch 30 - iter 13/130 - loss 0.00136665 - samples/sec: 163.34\n",
      "2020-02-05 13:38:43,649 epoch 30 - iter 26/130 - loss 0.00266326 - samples/sec: 230.61\n",
      "2020-02-05 13:38:46,898 epoch 30 - iter 39/130 - loss 0.00206161 - samples/sec: 186.47\n",
      "2020-02-05 13:38:49,936 epoch 30 - iter 52/130 - loss 0.00174830 - samples/sec: 203.43\n",
      "2020-02-05 13:38:54,236 epoch 30 - iter 65/130 - loss 0.00151173 - samples/sec: 182.86\n",
      "2020-02-05 13:38:57,552 epoch 30 - iter 78/130 - loss 0.00150307 - samples/sec: 182.70\n",
      "2020-02-05 13:39:00,543 epoch 30 - iter 91/130 - loss 0.00138141 - samples/sec: 207.70\n",
      "2020-02-05 13:39:03,571 epoch 30 - iter 104/130 - loss 0.00158968 - samples/sec: 212.15\n",
      "2020-02-05 13:39:06,488 epoch 30 - iter 117/130 - loss 0.00147746 - samples/sec: 223.19\n",
      "2020-02-05 13:39:09,756 ----------------------------------------------------------------------------------------------------\n",
      "2020-02-05 13:39:09,757 EPOCH 30 done: loss 0.0014 - lr 0.0031\n",
      "2020-02-05 13:39:12,192 DEV : loss 0.0474383607506752 - score 0.9923\n",
      "2020-02-05 13:39:12,245 BAD EPOCHS (no improvement): 3\n",
      "2020-02-05 13:39:13,404 ----------------------------------------------------------------------------------------------------\n",
      "2020-02-05 13:39:13,577 epoch 31 - iter 0/130 - loss 0.00029870 - samples/sec: 2432.89\n",
      "2020-02-05 13:39:17,792 epoch 31 - iter 13/130 - loss 0.00142226 - samples/sec: 171.48\n",
      "2020-02-05 13:39:20,609 epoch 31 - iter 26/130 - loss 0.00090591 - samples/sec: 229.21\n",
      "2020-02-05 13:39:24,269 epoch 31 - iter 39/130 - loss 0.00104836 - samples/sec: 192.33\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-02-05 13:39:27,674 epoch 31 - iter 52/130 - loss 0.00112803 - samples/sec: 203.13\n",
      "2020-02-05 13:39:31,525 epoch 31 - iter 65/130 - loss 0.00096145 - samples/sec: 196.61\n",
      "2020-02-05 13:39:34,456 epoch 31 - iter 78/130 - loss 0.00089758 - samples/sec: 215.78\n",
      "2020-02-05 13:39:37,442 epoch 31 - iter 91/130 - loss 0.00100512 - samples/sec: 210.43\n",
      "2020-02-05 13:39:40,484 epoch 31 - iter 104/130 - loss 0.00100192 - samples/sec: 200.97\n",
      "2020-02-05 13:39:43,579 epoch 31 - iter 117/130 - loss 0.00096092 - samples/sec: 202.54\n",
      "2020-02-05 13:39:47,099 ----------------------------------------------------------------------------------------------------\n",
      "2020-02-05 13:39:47,101 EPOCH 31 done: loss 0.0009 - lr 0.0031\n",
      "2020-02-05 13:39:49,604 DEV : loss 0.04760785773396492 - score 0.9923\n",
      "Epoch    30: reducing learning rate of group 0 to 1.5625e-03.\n",
      "2020-02-05 13:39:49,659 BAD EPOCHS (no improvement): 4\n",
      "2020-02-05 13:39:50,822 ----------------------------------------------------------------------------------------------------\n",
      "2020-02-05 13:39:50,951 epoch 32 - iter 0/130 - loss 0.00010487 - samples/sec: 3301.75\n",
      "2020-02-05 13:39:53,946 epoch 32 - iter 13/130 - loss 0.00056643 - samples/sec: 208.95\n",
      "2020-02-05 13:39:57,311 epoch 32 - iter 26/130 - loss 0.00065307 - samples/sec: 174.65\n",
      "2020-02-05 13:40:01,560 epoch 32 - iter 39/130 - loss 0.00085855 - samples/sec: 200.30\n",
      "2020-02-05 13:40:05,186 epoch 32 - iter 52/130 - loss 0.00077737 - samples/sec: 156.93\n",
      "2020-02-05 13:40:08,488 epoch 32 - iter 65/130 - loss 0.00073896 - samples/sec: 190.22\n",
      "2020-02-05 13:40:11,383 epoch 32 - iter 78/130 - loss 0.00075287 - samples/sec: 223.91\n",
      "2020-02-05 13:40:14,627 epoch 32 - iter 91/130 - loss 0.00071371 - samples/sec: 187.40\n",
      "2020-02-05 13:40:17,823 epoch 32 - iter 104/130 - loss 0.00068274 - samples/sec: 192.24\n",
      "2020-02-05 13:40:20,799 epoch 32 - iter 117/130 - loss 0.00066412 - samples/sec: 220.93\n",
      "2020-02-05 13:40:23,512 ----------------------------------------------------------------------------------------------------\n",
      "2020-02-05 13:40:23,514 EPOCH 32 done: loss 0.0007 - lr 0.0016\n",
      "2020-02-05 13:40:26,041 DEV : loss 0.04764186963438988 - score 0.9923\n",
      "2020-02-05 13:40:26,128 BAD EPOCHS (no improvement): 1\n",
      "2020-02-05 13:40:27,521 ----------------------------------------------------------------------------------------------------\n",
      "2020-02-05 13:40:27,644 epoch 33 - iter 0/130 - loss 0.00010828 - samples/sec: 3466.82\n",
      "2020-02-05 13:40:32,203 epoch 33 - iter 13/130 - loss 0.00055299 - samples/sec: 194.76\n",
      "2020-02-05 13:40:35,098 epoch 33 - iter 26/130 - loss 0.00072763 - samples/sec: 220.70\n",
      "2020-02-05 13:40:38,503 epoch 33 - iter 39/130 - loss 0.00077455 - samples/sec: 174.07\n",
      "2020-02-05 13:40:42,140 epoch 33 - iter 52/130 - loss 0.00088790 - samples/sec: 180.80\n",
      "2020-02-05 13:40:45,319 epoch 33 - iter 65/130 - loss 0.00076409 - samples/sec: 192.78\n",
      "2020-02-05 13:40:48,492 epoch 33 - iter 78/130 - loss 0.00087735 - samples/sec: 193.14\n",
      "2020-02-05 13:40:51,166 epoch 33 - iter 91/130 - loss 0.00092291 - samples/sec: 261.81\n",
      "2020-02-05 13:40:54,542 epoch 33 - iter 104/130 - loss 0.00093036 - samples/sec: 178.55\n",
      "2020-02-05 13:40:57,738 epoch 33 - iter 117/130 - loss 0.00095974 - samples/sec: 188.33\n",
      "2020-02-05 13:41:00,662 ----------------------------------------------------------------------------------------------------\n",
      "2020-02-05 13:41:00,663 EPOCH 33 done: loss 0.0010 - lr 0.0016\n",
      "2020-02-05 13:41:03,073 DEV : loss 0.047793131321668625 - score 0.9923\n",
      "2020-02-05 13:41:03,126 BAD EPOCHS (no improvement): 2\n",
      "2020-02-05 13:41:04,276 ----------------------------------------------------------------------------------------------------\n",
      "2020-02-05 13:41:04,497 epoch 34 - iter 0/130 - loss 0.00112825 - samples/sec: 1908.33\n",
      "2020-02-05 13:41:07,483 epoch 34 - iter 13/130 - loss 0.00061724 - samples/sec: 209.58\n",
      "2020-02-05 13:41:10,895 epoch 34 - iter 26/130 - loss 0.00082496 - samples/sec: 172.19\n",
      "2020-02-05 13:41:13,787 epoch 34 - iter 39/130 - loss 0.00098622 - samples/sec: 220.82\n",
      "2020-02-05 13:41:17,381 epoch 34 - iter 52/130 - loss 0.00104643 - samples/sec: 159.52\n",
      "2020-02-05 13:41:21,411 epoch 34 - iter 65/130 - loss 0.00093293 - samples/sec: 178.62\n",
      "2020-02-05 13:41:24,561 epoch 34 - iter 78/130 - loss 0.00108037 - samples/sec: 208.53\n",
      "2020-02-05 13:41:27,578 epoch 34 - iter 91/130 - loss 0.00098653 - samples/sec: 212.80\n",
      "2020-02-05 13:41:30,747 epoch 34 - iter 104/130 - loss 0.00092740 - samples/sec: 194.13\n",
      "2020-02-05 13:41:33,625 epoch 34 - iter 117/130 - loss 0.00091763 - samples/sec: 229.34\n",
      "2020-02-05 13:41:36,509 ----------------------------------------------------------------------------------------------------\n",
      "2020-02-05 13:41:36,510 EPOCH 34 done: loss 0.0010 - lr 0.0016\n",
      "2020-02-05 13:41:38,996 DEV : loss 0.047800201922655106 - score 0.9923\n",
      "2020-02-05 13:41:39,052 BAD EPOCHS (no improvement): 3\n",
      "2020-02-05 13:41:40,244 ----------------------------------------------------------------------------------------------------\n",
      "2020-02-05 13:41:40,379 epoch 35 - iter 0/130 - loss 0.00021765 - samples/sec: 3151.68\n",
      "2020-02-05 13:41:44,712 epoch 35 - iter 13/130 - loss 0.00147184 - samples/sec: 197.82\n",
      "2020-02-05 13:41:47,506 epoch 35 - iter 26/130 - loss 0.00107115 - samples/sec: 230.73\n",
      "2020-02-05 13:41:50,633 epoch 35 - iter 39/130 - loss 0.00104923 - samples/sec: 195.22\n",
      "2020-02-05 13:41:54,299 epoch 35 - iter 52/130 - loss 0.00122297 - samples/sec: 217.92\n",
      "2020-02-05 13:41:58,070 epoch 35 - iter 65/130 - loss 0.00112910 - samples/sec: 203.93\n",
      "2020-02-05 13:42:01,021 epoch 35 - iter 78/130 - loss 0.00102018 - samples/sec: 212.25\n",
      "2020-02-05 13:42:04,584 epoch 35 - iter 91/130 - loss 0.00119643 - samples/sec: 163.46\n",
      "2020-02-05 13:42:07,716 epoch 35 - iter 104/130 - loss 0.00111996 - samples/sec: 192.69\n",
      "2020-02-05 13:42:11,443 epoch 35 - iter 117/130 - loss 0.00108139 - samples/sec: 158.42\n",
      "2020-02-05 13:42:14,176 ----------------------------------------------------------------------------------------------------\n",
      "2020-02-05 13:42:14,177 EPOCH 35 done: loss 0.0010 - lr 0.0016\n",
      "2020-02-05 13:42:16,619 DEV : loss 0.04787163808941841 - score 0.9923\n",
      "Epoch    34: reducing learning rate of group 0 to 7.8125e-04.\n",
      "2020-02-05 13:42:16,674 BAD EPOCHS (no improvement): 4\n",
      "2020-02-05 13:42:17,847 ----------------------------------------------------------------------------------------------------\n",
      "2020-02-05 13:42:17,978 epoch 36 - iter 0/130 - loss 0.00013940 - samples/sec: 3250.13\n",
      "2020-02-05 13:42:21,051 epoch 36 - iter 13/130 - loss 0.00162352 - samples/sec: 208.11\n",
      "2020-02-05 13:42:24,075 epoch 36 - iter 26/130 - loss 0.00148357 - samples/sec: 206.87\n",
      "2020-02-05 13:42:27,169 epoch 36 - iter 39/130 - loss 0.00127946 - samples/sec: 196.98\n",
      "2020-02-05 13:42:30,312 epoch 36 - iter 52/130 - loss 0.00122498 - samples/sec: 196.05\n",
      "2020-02-05 13:42:33,469 epoch 36 - iter 65/130 - loss 0.00122358 - samples/sec: 193.05\n",
      "2020-02-05 13:42:36,645 epoch 36 - iter 78/130 - loss 0.00112197 - samples/sec: 210.00\n",
      "2020-02-05 13:42:39,709 epoch 36 - iter 91/130 - loss 0.00111609 - samples/sec: 209.58\n",
      "2020-02-05 13:42:43,173 epoch 36 - iter 104/130 - loss 0.00106154 - samples/sec: 171.69\n",
      "2020-02-05 13:42:46,347 epoch 36 - iter 117/130 - loss 0.00100174 - samples/sec: 194.58\n",
      "2020-02-05 13:42:48,942 ----------------------------------------------------------------------------------------------------\n",
      "2020-02-05 13:42:48,944 EPOCH 36 done: loss 0.0010 - lr 0.0008\n",
      "2020-02-05 13:42:51,365 DEV : loss 0.047871798276901245 - score 0.9923\n",
      "2020-02-05 13:42:51,418 BAD EPOCHS (no improvement): 1\n",
      "2020-02-05 13:42:52,610 ----------------------------------------------------------------------------------------------------\n",
      "2020-02-05 13:42:52,805 epoch 37 - iter 0/130 - loss 0.00016088 - samples/sec: 2155.54\n",
      "2020-02-05 13:42:56,847 epoch 37 - iter 13/130 - loss 0.00161870 - samples/sec: 219.42\n",
      "2020-02-05 13:42:59,861 epoch 37 - iter 26/130 - loss 0.00125314 - samples/sec: 206.56\n",
      "2020-02-05 13:43:03,149 epoch 37 - iter 39/130 - loss 0.00127372 - samples/sec: 231.89\n",
      "2020-02-05 13:43:06,471 epoch 37 - iter 52/130 - loss 0.00107447 - samples/sec: 179.24\n",
      "2020-02-05 13:43:10,532 epoch 37 - iter 65/130 - loss 0.00093133 - samples/sec: 204.73\n",
      "2020-02-05 13:43:13,640 epoch 37 - iter 78/130 - loss 0.00084442 - samples/sec: 198.20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-02-05 13:43:16,851 epoch 37 - iter 91/130 - loss 0.00099564 - samples/sec: 186.64\n",
      "2020-02-05 13:43:19,981 epoch 37 - iter 104/130 - loss 0.00102099 - samples/sec: 201.95\n",
      "2020-02-05 13:43:23,145 epoch 37 - iter 117/130 - loss 0.00101857 - samples/sec: 195.22\n",
      "2020-02-05 13:43:26,525 ----------------------------------------------------------------------------------------------------\n",
      "2020-02-05 13:43:26,527 EPOCH 37 done: loss 0.0011 - lr 0.0008\n",
      "2020-02-05 13:43:28,947 DEV : loss 0.04785548523068428 - score 0.9923\n",
      "2020-02-05 13:43:29,000 BAD EPOCHS (no improvement): 2\n",
      "2020-02-05 13:43:30,568 ----------------------------------------------------------------------------------------------------\n",
      "2020-02-05 13:43:30,701 epoch 38 - iter 0/130 - loss 0.00005391 - samples/sec: 3200.84\n",
      "2020-02-05 13:43:35,394 epoch 38 - iter 13/130 - loss 0.00135510 - samples/sec: 187.34\n",
      "2020-02-05 13:43:39,010 epoch 38 - iter 26/130 - loss 0.00135449 - samples/sec: 158.87\n",
      "2020-02-05 13:43:44,267 epoch 38 - iter 39/130 - loss 0.00099027 - samples/sec: 163.61\n",
      "2020-02-05 13:43:47,710 epoch 38 - iter 52/130 - loss 0.00087057 - samples/sec: 203.31\n",
      "2020-02-05 13:43:50,961 epoch 38 - iter 65/130 - loss 0.00080579 - samples/sec: 184.96\n",
      "2020-02-05 13:43:54,026 epoch 38 - iter 78/130 - loss 0.00083948 - samples/sec: 206.24\n",
      "2020-02-05 13:43:56,755 epoch 38 - iter 91/130 - loss 0.00083621 - samples/sec: 248.80\n",
      "2020-02-05 13:43:59,984 epoch 38 - iter 104/130 - loss 0.00085113 - samples/sec: 189.95\n",
      "2020-02-05 13:44:02,688 epoch 38 - iter 117/130 - loss 0.00084657 - samples/sec: 244.70\n",
      "2020-02-05 13:44:05,500 ----------------------------------------------------------------------------------------------------\n",
      "2020-02-05 13:44:05,502 EPOCH 38 done: loss 0.0008 - lr 0.0008\n",
      "2020-02-05 13:44:07,951 DEV : loss 0.04786369949579239 - score 0.9923\n",
      "2020-02-05 13:44:08,004 BAD EPOCHS (no improvement): 3\n",
      "2020-02-05 13:44:09,396 ----------------------------------------------------------------------------------------------------\n",
      "2020-02-05 13:44:09,527 epoch 39 - iter 0/130 - loss 0.00010192 - samples/sec: 3250.03\n",
      "2020-02-05 13:44:12,539 epoch 39 - iter 13/130 - loss 0.00051596 - samples/sec: 211.60\n",
      "2020-02-05 13:44:18,191 epoch 39 - iter 26/130 - loss 0.00133414 - samples/sec: 192.15\n",
      "2020-02-05 13:44:21,235 epoch 39 - iter 39/130 - loss 0.00132247 - samples/sec: 204.83\n",
      "2020-02-05 13:44:24,156 epoch 39 - iter 52/130 - loss 0.00146048 - samples/sec: 217.58\n",
      "2020-02-05 13:44:28,074 epoch 39 - iter 65/130 - loss 0.00134049 - samples/sec: 185.14\n",
      "2020-02-05 13:44:31,642 epoch 39 - iter 78/130 - loss 0.00124219 - samples/sec: 162.44\n",
      "2020-02-05 13:44:34,632 epoch 39 - iter 91/130 - loss 0.00115323 - samples/sec: 210.53\n",
      "2020-02-05 13:44:38,250 epoch 39 - iter 104/130 - loss 0.00111694 - samples/sec: 159.82\n",
      "2020-02-05 13:44:41,160 epoch 39 - iter 117/130 - loss 0.00108915 - samples/sec: 226.83\n",
      "2020-02-05 13:44:44,115 ----------------------------------------------------------------------------------------------------\n",
      "2020-02-05 13:44:44,117 EPOCH 39 done: loss 0.0011 - lr 0.0008\n",
      "2020-02-05 13:44:46,558 DEV : loss 0.04786998778581619 - score 0.9923\n",
      "Epoch    38: reducing learning rate of group 0 to 3.9063e-04.\n",
      "2020-02-05 13:44:46,614 BAD EPOCHS (no improvement): 4\n",
      "2020-02-05 13:44:47,791 ----------------------------------------------------------------------------------------------------\n",
      "2020-02-05 13:44:47,931 epoch 40 - iter 0/130 - loss 0.00002579 - samples/sec: 3036.62\n",
      "2020-02-05 13:44:51,585 epoch 40 - iter 13/130 - loss 0.00062876 - samples/sec: 225.12\n",
      "2020-02-05 13:44:55,069 epoch 40 - iter 26/130 - loss 0.00077019 - samples/sec: 167.28\n",
      "2020-02-05 13:44:59,539 epoch 40 - iter 39/130 - loss 0.00117028 - samples/sec: 183.51\n",
      "2020-02-05 13:45:03,598 epoch 40 - iter 52/130 - loss 0.00125748 - samples/sec: 212.04\n",
      "2020-02-05 13:45:06,927 epoch 40 - iter 65/130 - loss 0.00132870 - samples/sec: 179.94\n",
      "2020-02-05 13:45:09,900 epoch 40 - iter 78/130 - loss 0.00121107 - samples/sec: 216.11\n",
      "2020-02-05 13:45:13,163 epoch 40 - iter 91/130 - loss 0.00120603 - samples/sec: 190.83\n",
      "2020-02-05 13:45:16,395 epoch 40 - iter 104/130 - loss 0.00136472 - samples/sec: 186.55\n",
      "2020-02-05 13:45:19,538 epoch 40 - iter 117/130 - loss 0.00128488 - samples/sec: 207.28\n",
      "2020-02-05 13:45:22,363 ----------------------------------------------------------------------------------------------------\n",
      "2020-02-05 13:45:22,364 EPOCH 40 done: loss 0.0012 - lr 0.0004\n",
      "2020-02-05 13:45:24,828 DEV : loss 0.04790547490119934 - score 0.9923\n",
      "2020-02-05 13:45:24,881 BAD EPOCHS (no improvement): 1\n",
      "2020-02-05 13:45:26,137 ----------------------------------------------------------------------------------------------------\n",
      "2020-02-05 13:45:26,368 epoch 41 - iter 0/130 - loss 0.00011984 - samples/sec: 1816.67\n",
      "2020-02-05 13:45:30,122 epoch 41 - iter 13/130 - loss 0.00112992 - samples/sec: 216.45\n",
      "2020-02-05 13:45:33,293 epoch 41 - iter 26/130 - loss 0.00139955 - samples/sec: 194.13\n",
      "2020-02-05 13:45:36,762 epoch 41 - iter 39/130 - loss 0.00139654 - samples/sec: 168.43\n",
      "2020-02-05 13:45:39,866 epoch 41 - iter 52/130 - loss 0.00112984 - samples/sec: 196.98\n",
      "2020-02-05 13:45:43,630 epoch 41 - iter 65/130 - loss 0.00103471 - samples/sec: 211.18\n",
      "2020-02-05 13:45:46,588 epoch 41 - iter 78/130 - loss 0.00102668 - samples/sec: 210.32\n",
      "2020-02-05 13:45:49,563 epoch 41 - iter 91/130 - loss 0.00102212 - samples/sec: 216.00\n",
      "2020-02-05 13:45:52,821 epoch 41 - iter 104/130 - loss 0.00097665 - samples/sec: 189.96\n",
      "2020-02-05 13:45:55,985 epoch 41 - iter 117/130 - loss 0.00091147 - samples/sec: 195.59\n",
      "2020-02-05 13:45:58,856 ----------------------------------------------------------------------------------------------------\n",
      "2020-02-05 13:45:58,857 EPOCH 41 done: loss 0.0009 - lr 0.0004\n",
      "2020-02-05 13:46:01,266 DEV : loss 0.04791580140590668 - score 0.9923\n",
      "2020-02-05 13:46:01,319 BAD EPOCHS (no improvement): 2\n",
      "2020-02-05 13:46:02,508 ----------------------------------------------------------------------------------------------------\n",
      "2020-02-05 13:46:02,644 epoch 42 - iter 0/130 - loss 0.00032116 - samples/sec: 3127.97\n",
      "2020-02-05 13:46:05,511 epoch 42 - iter 13/130 - loss 0.00058813 - samples/sec: 222.23\n",
      "2020-02-05 13:46:08,820 epoch 42 - iter 26/130 - loss 0.00087206 - samples/sec: 181.43\n",
      "2020-02-05 13:46:13,675 epoch 42 - iter 39/130 - loss 0.00119482 - samples/sec: 202.44\n",
      "2020-02-05 13:46:16,880 epoch 42 - iter 52/130 - loss 0.00137647 - samples/sec: 186.89\n",
      "2020-02-05 13:46:20,459 epoch 42 - iter 65/130 - loss 0.00118178 - samples/sec: 170.64\n",
      "2020-02-05 13:46:23,587 epoch 42 - iter 78/130 - loss 0.00107060 - samples/sec: 194.76\n",
      "2020-02-05 13:46:26,916 epoch 42 - iter 91/130 - loss 0.00105476 - samples/sec: 184.08\n",
      "2020-02-05 13:46:29,822 epoch 42 - iter 104/130 - loss 0.00107822 - samples/sec: 221.29\n",
      "2020-02-05 13:46:33,053 epoch 42 - iter 117/130 - loss 0.00111075 - samples/sec: 190.75\n",
      "2020-02-05 13:46:35,903 ----------------------------------------------------------------------------------------------------\n",
      "2020-02-05 13:46:35,904 EPOCH 42 done: loss 0.0010 - lr 0.0004\n",
      "2020-02-05 13:46:38,364 DEV : loss 0.04794752597808838 - score 0.9923\n",
      "2020-02-05 13:46:38,417 BAD EPOCHS (no improvement): 3\n",
      "2020-02-05 13:46:40,002 ----------------------------------------------------------------------------------------------------\n",
      "2020-02-05 13:46:40,148 epoch 43 - iter 0/130 - loss 0.00309720 - samples/sec: 2909.21\n",
      "2020-02-05 13:46:44,778 epoch 43 - iter 13/130 - loss 0.00108989 - samples/sec: 197.82\n",
      "2020-02-05 13:46:47,873 epoch 43 - iter 26/130 - loss 0.00098446 - samples/sec: 199.15\n",
      "2020-02-05 13:46:51,412 epoch 43 - iter 39/130 - loss 0.00107020 - samples/sec: 163.08\n",
      "2020-02-05 13:46:54,330 epoch 43 - iter 52/130 - loss 0.00097115 - samples/sec: 216.22\n",
      "2020-02-05 13:46:57,879 epoch 43 - iter 65/130 - loss 0.00097717 - samples/sec: 232.28\n",
      "2020-02-05 13:47:01,341 epoch 43 - iter 78/130 - loss 0.00088861 - samples/sec: 174.07\n",
      "2020-02-05 13:47:04,182 epoch 43 - iter 91/130 - loss 0.00085996 - samples/sec: 230.35\n",
      "2020-02-05 13:47:07,537 epoch 43 - iter 104/130 - loss 0.00097940 - samples/sec: 179.63\n",
      "2020-02-05 13:47:10,590 epoch 43 - iter 117/130 - loss 0.00103467 - samples/sec: 201.85\n",
      "2020-02-05 13:47:13,608 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-02-05 13:47:13,609 EPOCH 43 done: loss 0.0010 - lr 0.0004\n",
      "2020-02-05 13:47:16,016 DEV : loss 0.047963835299015045 - score 0.9923\n",
      "Epoch    42: reducing learning rate of group 0 to 1.9531e-04.\n",
      "2020-02-05 13:47:16,073 BAD EPOCHS (no improvement): 4\n",
      "2020-02-05 13:47:17,453 ----------------------------------------------------------------------------------------------------\n",
      "2020-02-05 13:47:17,641 epoch 44 - iter 0/130 - loss 0.00218877 - samples/sec: 2248.75\n",
      "2020-02-05 13:47:22,526 epoch 44 - iter 13/130 - loss 0.00077225 - samples/sec: 186.47\n",
      "2020-02-05 13:47:25,637 epoch 44 - iter 26/130 - loss 0.00096878 - samples/sec: 194.49\n",
      "2020-02-05 13:47:30,758 epoch 44 - iter 39/130 - loss 0.00115960 - samples/sec: 199.34\n",
      "2020-02-05 13:47:33,506 epoch 44 - iter 52/130 - loss 0.00108847 - samples/sec: 234.38\n",
      "2020-02-05 13:47:36,872 epoch 44 - iter 65/130 - loss 0.00106321 - samples/sec: 208.95\n",
      "2020-02-05 13:47:40,085 epoch 44 - iter 78/130 - loss 0.00107350 - samples/sec: 190.66\n",
      "2020-02-05 13:47:43,263 epoch 44 - iter 91/130 - loss 0.00101123 - samples/sec: 188.84\n",
      "2020-02-05 13:47:46,169 epoch 44 - iter 104/130 - loss 0.00099114 - samples/sec: 216.45\n",
      "2020-02-05 13:47:49,583 epoch 44 - iter 117/130 - loss 0.00101707 - samples/sec: 172.55\n",
      "2020-02-05 13:47:52,772 ----------------------------------------------------------------------------------------------------\n",
      "2020-02-05 13:47:52,774 EPOCH 44 done: loss 0.0010 - lr 0.0002\n",
      "2020-02-05 13:47:55,206 DEV : loss 0.04797077924013138 - score 0.9923\n",
      "2020-02-05 13:47:55,259 BAD EPOCHS (no improvement): 1\n",
      "2020-02-05 13:47:56,419 ----------------------------------------------------------------------------------------------------\n",
      "2020-02-05 13:47:56,621 epoch 45 - iter 0/130 - loss 0.00045478 - samples/sec: 2080.09\n",
      "2020-02-05 13:48:00,455 epoch 45 - iter 13/130 - loss 0.00084425 - samples/sec: 207.28\n",
      "2020-02-05 13:48:03,840 epoch 45 - iter 26/130 - loss 0.00089648 - samples/sec: 172.91\n",
      "2020-02-05 13:48:09,093 epoch 45 - iter 39/130 - loss 0.00112066 - samples/sec: 210.22\n",
      "2020-02-05 13:48:11,809 epoch 45 - iter 52/130 - loss 0.00097545 - samples/sec: 239.64\n",
      "2020-02-05 13:48:15,726 epoch 45 - iter 65/130 - loss 0.00129998 - samples/sec: 218.73\n",
      "2020-02-05 13:48:18,928 epoch 45 - iter 78/130 - loss 0.00117769 - samples/sec: 196.61\n",
      "2020-02-05 13:48:22,267 epoch 45 - iter 91/130 - loss 0.00108458 - samples/sec: 178.39\n",
      "2020-02-05 13:48:25,877 epoch 45 - iter 104/130 - loss 0.00102086 - samples/sec: 165.41\n",
      "2020-02-05 13:48:28,959 epoch 45 - iter 117/130 - loss 0.00104805 - samples/sec: 202.24\n",
      "2020-02-05 13:48:31,569 ----------------------------------------------------------------------------------------------------\n",
      "2020-02-05 13:48:31,570 EPOCH 45 done: loss 0.0011 - lr 0.0002\n",
      "2020-02-05 13:48:34,029 DEV : loss 0.047991793602705 - score 0.9923\n",
      "2020-02-05 13:48:34,082 BAD EPOCHS (no improvement): 2\n",
      "2020-02-05 13:48:35,248 ----------------------------------------------------------------------------------------------------\n",
      "2020-02-05 13:48:35,361 epoch 46 - iter 0/130 - loss 0.00001211 - samples/sec: 3747.89\n",
      "2020-02-05 13:48:38,838 epoch 46 - iter 13/130 - loss 0.00084649 - samples/sec: 213.12\n",
      "2020-02-05 13:48:42,092 epoch 46 - iter 26/130 - loss 0.00124763 - samples/sec: 183.27\n",
      "2020-02-05 13:48:46,039 epoch 46 - iter 39/130 - loss 0.00112445 - samples/sec: 229.46\n",
      "2020-02-05 13:48:49,367 epoch 46 - iter 52/130 - loss 0.00111890 - samples/sec: 177.41\n",
      "2020-02-05 13:48:52,993 epoch 46 - iter 65/130 - loss 0.00124065 - samples/sec: 191.98\n",
      "2020-02-05 13:48:55,978 epoch 46 - iter 78/130 - loss 0.00119413 - samples/sec: 213.78\n",
      "2020-02-05 13:48:59,746 epoch 46 - iter 91/130 - loss 0.00109641 - samples/sec: 152.67\n",
      "2020-02-05 13:49:02,754 epoch 46 - iter 104/130 - loss 0.00106470 - samples/sec: 211.28\n",
      "2020-02-05 13:49:05,794 epoch 46 - iter 117/130 - loss 0.00103350 - samples/sec: 204.53\n",
      "2020-02-05 13:49:08,466 ----------------------------------------------------------------------------------------------------\n",
      "2020-02-05 13:49:08,468 EPOCH 46 done: loss 0.0010 - lr 0.0002\n",
      "2020-02-05 13:49:10,903 DEV : loss 0.04799748212099075 - score 0.9923\n",
      "2020-02-05 13:49:10,956 BAD EPOCHS (no improvement): 3\n",
      "2020-02-05 13:49:12,131 ----------------------------------------------------------------------------------------------------\n",
      "2020-02-05 13:49:12,360 epoch 47 - iter 0/130 - loss 0.00073551 - samples/sec: 1832.69\n",
      "2020-02-05 13:49:16,373 epoch 47 - iter 13/130 - loss 0.00079644 - samples/sec: 233.32\n",
      "2020-02-05 13:49:19,341 epoch 47 - iter 26/130 - loss 0.00069157 - samples/sec: 212.47\n",
      "2020-02-05 13:49:22,270 epoch 47 - iter 39/130 - loss 0.00079732 - samples/sec: 216.34\n",
      "2020-02-05 13:49:26,132 epoch 47 - iter 52/130 - loss 0.00100357 - samples/sec: 220.58\n",
      "2020-02-05 13:49:30,936 epoch 47 - iter 65/130 - loss 0.00134663 - samples/sec: 164.24\n",
      "2020-02-05 13:49:34,151 epoch 47 - iter 78/130 - loss 0.00115828 - samples/sec: 193.86\n",
      "2020-02-05 13:49:37,817 epoch 47 - iter 91/130 - loss 0.00121505 - samples/sec: 160.75\n",
      "2020-02-05 13:49:40,955 epoch 47 - iter 104/130 - loss 0.00111454 - samples/sec: 197.82\n",
      "2020-02-05 13:49:44,056 epoch 47 - iter 117/130 - loss 0.00121475 - samples/sec: 204.73\n",
      "2020-02-05 13:49:46,751 ----------------------------------------------------------------------------------------------------\n",
      "2020-02-05 13:49:46,753 EPOCH 47 done: loss 0.0012 - lr 0.0002\n",
      "2020-02-05 13:49:49,235 DEV : loss 0.04800056666135788 - score 0.9923\n",
      "Epoch    46: reducing learning rate of group 0 to 9.7656e-05.\n",
      "2020-02-05 13:49:49,290 BAD EPOCHS (no improvement): 4\n",
      "2020-02-05 13:49:50,786 ----------------------------------------------------------------------------------------------------\n",
      "2020-02-05 13:49:50,788 ----------------------------------------------------------------------------------------------------\n",
      "2020-02-05 13:49:50,789 learning rate too small - quitting training!\n",
      "2020-02-05 13:49:50,790 ----------------------------------------------------------------------------------------------------\n",
      "2020-02-05 13:49:52,463 ----------------------------------------------------------------------------------------------------\n",
      "2020-02-05 13:49:52,465 Testing using best model ...\n",
      "2020-02-05 13:49:52,467 loading file best-model.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\serialization.py:574: DeprecationWarning: Call to deprecated class DocumentLSTMEmbeddings. (The functionality of this class is moved to 'DocumentRNNEmbeddings') -- Deprecated since version 0.4.\n",
      "  result = unpickler.load()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-02-05 13:56:26,060 0.9787\t0.9787\t0.9787\n",
      "2020-02-05 13:56:26,062 \n",
      "MICRO_AVG: acc 0.9583 - f1-score 0.9787\n",
      "MACRO_AVG: acc 0.9047 - f1-score 0.94855\n",
      "ham        tp: 451 - fp: 8 - fn: 3 - tn: 55 - precision: 0.9826 - recall: 0.9934 - accuracy: 0.9762 - f1-score: 0.9880\n",
      "spam       tp: 55 - fp: 3 - fn: 8 - tn: 451 - precision: 0.9483 - recall: 0.8730 - accuracy: 0.8333 - f1-score: 0.9091\n",
      "2020-02-05 13:56:26,063 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_score': 0.9787,\n",
       " 'dev_score_history': [0.9787,\n",
       "  0.9884,\n",
       "  0.9903,\n",
       "  0.9865,\n",
       "  0.9903,\n",
       "  0.9884,\n",
       "  0.9903,\n",
       "  0.9903,\n",
       "  0.9903,\n",
       "  0.9903,\n",
       "  0.9923,\n",
       "  0.9923,\n",
       "  0.9903,\n",
       "  0.9923,\n",
       "  0.9923,\n",
       "  0.9923,\n",
       "  0.9923,\n",
       "  0.9923,\n",
       "  0.9923,\n",
       "  0.9923,\n",
       "  0.9923,\n",
       "  0.9923,\n",
       "  0.9923,\n",
       "  0.9923,\n",
       "  0.9923,\n",
       "  0.9923,\n",
       "  0.9923,\n",
       "  0.9923,\n",
       "  0.9923,\n",
       "  0.9923,\n",
       "  0.9923,\n",
       "  0.9923,\n",
       "  0.9923,\n",
       "  0.9923,\n",
       "  0.9923,\n",
       "  0.9923,\n",
       "  0.9923,\n",
       "  0.9923,\n",
       "  0.9923,\n",
       "  0.9923,\n",
       "  0.9923,\n",
       "  0.9923,\n",
       "  0.9923,\n",
       "  0.9923,\n",
       "  0.9923,\n",
       "  0.9923,\n",
       "  0.9923],\n",
       " 'train_loss_history': [0.14099423999163824,\n",
       "  0.06762746933829755,\n",
       "  0.04583877539620376,\n",
       "  0.04146887439486678,\n",
       "  0.03401835021885255,\n",
       "  0.029118352060994276,\n",
       "  0.022270211470850673,\n",
       "  0.013809197267087606,\n",
       "  0.011601482939659036,\n",
       "  0.008063341164961458,\n",
       "  0.007215783825421778,\n",
       "  0.005273395067510697,\n",
       "  0.003954336989241151,\n",
       "  0.0041253711638721425,\n",
       "  0.0028007527158339283,\n",
       "  0.0018558785946180042,\n",
       "  0.001759871122025148,\n",
       "  0.002248157912883751,\n",
       "  0.0012722291891875033,\n",
       "  0.001669316499360845,\n",
       "  0.001436599010248056,\n",
       "  0.0013355974368935747,\n",
       "  0.0010087652009063348,\n",
       "  0.0010132898699374401,\n",
       "  0.0012050415964949934,\n",
       "  0.0015710418419600432,\n",
       "  0.0012435154191245182,\n",
       "  0.0012454405122508223,\n",
       "  0.0008696283122005228,\n",
       "  0.0014009509613970295,\n",
       "  0.0009131216311009037,\n",
       "  0.0006675364019779059,\n",
       "  0.0009573113800098117,\n",
       "  0.000977306756473039,\n",
       "  0.001043872884218462,\n",
       "  0.0010070339766501163,\n",
       "  0.0010593142763424951,\n",
       "  0.0008002700028345526,\n",
       "  0.0010709256138467865,\n",
       "  0.0012096870649167192,\n",
       "  0.0008816825901354045,\n",
       "  0.001041948371522057,\n",
       "  0.0009958937805025086,\n",
       "  0.0009507920459992209,\n",
       "  0.001093213983739798,\n",
       "  0.0010075872886808122,\n",
       "  0.0011603410826445234],\n",
       " 'dev_loss_history': [tensor(0.0443, device='cuda:0'),\n",
       "  tensor(0.0345, device='cuda:0'),\n",
       "  tensor(0.0319, device='cuda:0'),\n",
       "  tensor(0.0391, device='cuda:0'),\n",
       "  tensor(0.0332, device='cuda:0'),\n",
       "  tensor(0.0309, device='cuda:0'),\n",
       "  tensor(0.0340, device='cuda:0'),\n",
       "  tensor(0.0328, device='cuda:0'),\n",
       "  tensor(0.0326, device='cuda:0'),\n",
       "  tensor(0.0339, device='cuda:0'),\n",
       "  tensor(0.0350, device='cuda:0'),\n",
       "  tensor(0.0352, device='cuda:0'),\n",
       "  tensor(0.0403, device='cuda:0'),\n",
       "  tensor(0.0420, device='cuda:0'),\n",
       "  tensor(0.0425, device='cuda:0'),\n",
       "  tensor(0.0435, device='cuda:0'),\n",
       "  tensor(0.0439, device='cuda:0'),\n",
       "  tensor(0.0442, device='cuda:0'),\n",
       "  tensor(0.0451, device='cuda:0'),\n",
       "  tensor(0.0452, device='cuda:0'),\n",
       "  tensor(0.0459, device='cuda:0'),\n",
       "  tensor(0.0461, device='cuda:0'),\n",
       "  tensor(0.0464, device='cuda:0'),\n",
       "  tensor(0.0468, device='cuda:0'),\n",
       "  tensor(0.0469, device='cuda:0'),\n",
       "  tensor(0.0468, device='cuda:0'),\n",
       "  tensor(0.0470, device='cuda:0'),\n",
       "  tensor(0.0473, device='cuda:0'),\n",
       "  tensor(0.0474, device='cuda:0'),\n",
       "  tensor(0.0474, device='cuda:0'),\n",
       "  tensor(0.0476, device='cuda:0'),\n",
       "  tensor(0.0476, device='cuda:0'),\n",
       "  tensor(0.0478, device='cuda:0'),\n",
       "  tensor(0.0478, device='cuda:0'),\n",
       "  tensor(0.0479, device='cuda:0'),\n",
       "  tensor(0.0479, device='cuda:0'),\n",
       "  tensor(0.0479, device='cuda:0'),\n",
       "  tensor(0.0479, device='cuda:0'),\n",
       "  tensor(0.0479, device='cuda:0'),\n",
       "  tensor(0.0479, device='cuda:0'),\n",
       "  tensor(0.0479, device='cuda:0'),\n",
       "  tensor(0.0479, device='cuda:0'),\n",
       "  tensor(0.0480, device='cuda:0'),\n",
       "  tensor(0.0480, device='cuda:0'),\n",
       "  tensor(0.0480, device='cuda:0'),\n",
       "  tensor(0.0480, device='cuda:0'),\n",
       "  tensor(0.0480, device='cuda:0')]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = NLPTaskDataFetcher.load_classification_corpus(Path('./'), test_file='test.csv', dev_file='dev.csv', train_file='train.csv')\n",
    "#word_embeddings = [WordEmbeddings('glove'), FlairEmbeddings('news-forward-fast'), FlairEmbeddings('news-backward-fast')]\n",
    "word_embeddings = [BertEmbeddings(), FlairEmbeddings('news-forward-fast'), FlairEmbeddings('news-backward-fast')]\n",
    "document_embeddings = DocumentLSTMEmbeddings(word_embeddings, hidden_size=512, reproject_words=True, reproject_words_dimension=256)\n",
    "classifier = TextClassifier(document_embeddings, label_dictionary=corpus.make_label_dictionary(), multi_label=False)\n",
    "trainer = ModelTrainer(classifier, corpus)\n",
    "trainer.train('./', max_epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
